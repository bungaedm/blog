[{"content":"Intro ìƒí‚¤ ì°¨íŠ¸(Sankey Chart)ëŠ” íë¦„(Flow)ì„ ë³´ì—¬ì£¼ê¸°ì— ìµœì í™”ëœ ì°¨íŠ¸ í˜•íƒœì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì§€ì—­ì´ë‚˜ êµ­ê°€ ê°„ì˜ ì—ë„ˆì§€ë¥¼ í‘œí˜„í•˜ëŠ”ë°ì— ì í•©í•˜ë‹¤.\n  ê¸°ë³¸ ì „ì²˜ë¦¬ ì½”ë“œ(R)  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  library(tidyverse) library(xlsx) setwd(\u0026#39;C:/Users/bunga/Desktop/Tableau/data\u0026#39;) data \u0026lt;- read.table(\u0026#39;seoul_park_raw.txt\u0026#39;, header=TRUE, sep=\u0026#39;\\t\u0026#39;) data \u0026lt;- as.tibble(data) data \u0026lt;- data %\u0026gt;% mutate(ym = (ym*100)%%100) data \u0026lt;- data %\u0026gt;% select(-total) data \u0026lt;- data[data[\u0026#39;region\u0026#39;] != \u0026#39;í•©ê³„\u0026#39;,] data \u0026lt;- data %\u0026gt;% mutate(ord = as.numeric(gsub(\u0026#39;,\u0026#39;, \u0026#39;\u0026#39;, ord)), health = as.numeric(gsub(\u0026#39;,\u0026#39;, \u0026#39;\u0026#39;, health)), bicycle = as.numeric(gsub(\u0026#39;,\u0026#39;, \u0026#39;\u0026#39;, bicycle)), event = as.numeric(gsub(\u0026#39;,\u0026#39;, \u0026#39;\u0026#39;, event)), special = as.numeric(gsub(\u0026#39;,\u0026#39;, \u0026#39;\u0026#39;, special)), etc = as.numeric(gsub(\u0026#39;,\u0026#39;, \u0026#39;\u0026#39;, etc))) %\u0026gt;% mutate_all(~ifelse(is.na(.), 0, .)) write.table(data, file = \u0026#34;seoul_park.txt\u0026#34;, sep = \u0026#34;\\t\u0026#34;, row.names = FALSE) write.xlsx(data,file=\u0026#39;seoul_park.xlsx\u0026#39;, sheetName = \u0026#39;Sheet1\u0026#39;)      Reference [1] WeViz ìœ íŠœë¸Œ\n[2] https://qliksense.tistory.com/32\n[3] ì„œìš¸ì—´ë¦°ë°ì´í„°ê´‘ì¥\n","description":"","id":0,"section":"posts","tags":null,"title":"ìƒí‚¤ ì°¨íŠ¸","uri":"https://jiwooblog.netlify.app/posts/tableau/sankey_chart/"},{"content":"Intro ë³¸ í¬ìŠ¤íŒ…ì€ WeViz ìœ íŠœë¸Œë¥¼ ì ê·¹ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\nê²°ê³¼ë¬¼  1. íŒ”ë ˆíŠ¸ ì»¤ìŠ¤í…€ ì¶”ê°€ ë‚´ íƒœë¸”ë¡œ ë¦¬í¬ì§€í† ë¦¬ Preferences íŒŒì¼ì— ìƒ‰ìƒ ì»¤ìŠ¤í…€ ì¶”ê°€\në³¸ ê²°ê³¼ë¬¼ì—ëŠ” í•´ë‹¹ ì°¸ê³ ì‚¬ì´íŠ¸ì—ì„œ ì¶”ì²œí•œ ìƒ‰ìƒ ì¡°í•©ì„ ì ìš©í•˜ì˜€ë‹¤.\n2. ìƒ‰ìƒ ì°¸ê³  ì‚¬ì´íŠ¸ 2-1. UI gradients (ì¸¡ì •ê°’ ê·¸ë¼ë°ì´ì…˜) UI gradients\n2-2. Adobe Color (ì°¨ì› ìƒ‰ì¡°í•©) Adobe color\nReference [1] WeViz ìœ íŠœë¸Œ\n","description":"","id":1,"section":"posts","tags":null,"title":"í•œêµ­ í”½ì…€ë§µ","uri":"https://jiwooblog.netlify.app/posts/tableau/korea_pixel_map/"},{"content":"Intro ë³¸ í¬ìŠ¤íŒ…ì€ WeViz ìœ íŠœë¸Œë¥¼ ì ê·¹ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\nê²°ê³¼ë¬¼  1. ê¸°ë³¸ ìˆ˜ì •  [ë§µ] - [ë§µ ê³„ì¸µ] ìŠ¤íƒ€ì¼ ì–´ë‘¡ê²Œ ë³€ê²½ ê¸°ë³¸ë„, í† ì§€ í”¼ë³µë„ ì²´í¬ë°•ìŠ¤ í•´ì œ í•´ì•ˆì„  ì²´í¬  2. mapbox ì´ìš©í•˜ê¸°  mapbox í™ˆí˜ì´ì§€ Studio -\u0026gt; New Style -\u0026gt; Basic(ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì„ íƒí•´ë„ ë¬´ë°©)  2-1. ì˜ì—­ ìƒ‰ê¹” ë°”ê¾¸ê¸° íŠ¹ì • ì˜ì—­ í´ë¦­ í›„ ìƒ‰ê¹” ë³€ê²½\n2-2. í°íŠ¸ ë°”ê¾¸ê¸° STEP1. í…ìŠ¤íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìë¬¼ì‡  ì ê¸ˆ í•´ì œ(override) í´ë¦­ í›„ ë³€ê²½ ê°€ëŠ¥\nSTEP2. íŠ¹ì • ë ˆì´ë¸”ì„ ì„ íƒ -\u0026gt; Components -\u0026gt; Typography\nSTEP3. ì›í•˜ëŠ” ê¸€ê¼´ ê²€ìƒ‰ í›„ ì ìš©(Noto sans ì¶”ì²œ)\n2-3. ì˜ì–´ ë ˆì´ë¸”ì„ í•œê¸€ ë ˆì´ë¸”ë¡œ ë°”ê¾¸ê¸° STEP1. íŠ¹ì • ë ˆì´ë¸” í´ë¦­ -\u0026gt; Layers -\u0026gt; T-country label í´ë¦­\nSTEP2. overrideë¥¼ í´ë¦­í•˜ì—¬ name_enì„ name_koë¡œ ë°”ê¿”ì¤€ë‹¤.\n2-4. ë°°í¬í•˜ê¸° ì˜¤ë¥¸ìª½ ìƒë‹¨ Publish í´ë¦­ -\u0026gt; Publish as new\n2-5. Tableauë¡œ ê°€ì ¸ì˜¤ê¸° STEP1. mapbox preview only ë§í¬ ë³µì‚¬\nSTEP2. Tableau ë§µ ê´€ë¦¬ -\u0026gt; ì¶”ê°€\nSTEP3. ë‚´ë³´ë‚´ê¸° ê¼­ í•˜ê¸°! (ë‹¤ìŒì—ë„ í™œìš©í•˜ê¸° ìœ„í•´ì„œ!)\nReference [1] WeViz ìœ íŠœë¸Œ\n","description":"","id":2,"section":"posts","tags":null,"title":"ë§µ ì»¤ìŠ¤í…€","uri":"https://jiwooblog.netlify.app/posts/tableau/map_custom/"},{"content":"Intro ë³¸ í¬ìŠ¤íŒ…ì€ WeViz ìœ íŠœë¸Œë¥¼ ì ê·¹ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\nì‹œê°í™”ì— ê´€ì‹¬ì´ ìˆì—ˆëŠ”ë°, í•´ë‹¹ ì—°í•©ë™ì•„ë¦¬ ì†Œì†ì˜ ì¹œêµ¬ì—ê²Œ ì¶”ì²œì„ ë°›ì•„ì„œ ì°¸ê³ í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nê²°ê³¼ë¬¼  ë°°ìš´ì    êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ GEOCODE í™œìš©ë²•\n ê²½ë„(longitude), ìœ„ë„(latitude) ìë™ ì¶”ì¶œ ê¸°ëŠ¥    MAKELINE, MAKEPOINT í™œìš©ë²•\nMAKELINE(MAKEPOINT(30.602101,114.316826), MAKEPOINT([Latitude],[Longitude]))\n  ë§µ ê´€ë¦¬\n ì»¤ìŠ¤í…€ ë§µ ë””ìì¸ ì¶”ê°€    Reference [1] WeViz ìœ íŠœë¸Œ\n[2] ë°ì´í„° ì¶œì²˜\n","description":"","id":3,"section":"posts","tags":null,"title":"ì½”ë¡œë‚˜","uri":"https://jiwooblog.netlify.app/posts/tableau/corona_map/"},{"content":"esquisse esquisseëŠ” ë“œë˜ê·¸ ì•¤ ë“œë¡­(drag \u0026amp; drop)ìœ¼ë¡œ ggplotì„ ê°„ë‹¨í•˜ê²Œ ê·¸ë¦´ ìˆ˜ ìˆëŠ” íšê¸°ì ì¸ íŒ¨í‚¤ì§€ì´ë‹¤.\në³µì¡í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì€ ë””í…Œì¼í•œ ìˆ˜ì •ì´ ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”í•˜ê² ì§€ë§Œ, ê°„ë‹¨í•œ íŠ¹ì§•ë“¤ì„ ë°˜ë³µì ì¸ ì½”ë“œìˆ˜ì •ê³¼ í™•ì¸ê³¼ì •ì„ ê±°ì¹˜ê¸° ì•Šê³ ì„œë„ ì¦‰ê°ì ìœ¼ë¡œ ê·¸ë˜í”„ ëª¨ì–‘ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤ëŠ” í° ì¥ì ì´ ìˆë‹¤.\nê±°ì˜ Tableu ê°™ì€ ëŠë‚Œë„ ë“ ë‹¤. ê°„ë‹¨í•œ ggplot ê·¸ë¦´ ë•Œ ë˜ëŠ” ggplot ì…ë¬¸ìê°€ ë¨¼ì € ê±°ì³ê°€ë„ ì¢‹ì„ ê²ƒ ê°™ë‹¤.\n1 2 3  library(ggplot2) library(dplyr) library(esquisse)   STEP1. Addinsì„ í´ë¦­í•˜ê³ , ggplot2 builderë¥¼ ì´ì–´ì„œ í´ë¦­í•œë‹¤.\n\nSTEP2. validate imported dataë¥¼ í´ë¦­í•œë‹¤.\n\nSTEP3. ë“œë˜ê·¸ ì•¤ ë“œë¡­ìœ¼ë¡œ Xì¶•, Yì¶• ë“±ì„ ì„¤ì •í•œë‹¤.\n\nSTEP4-1. Labels \u0026amp; Titleì—ì„œëŠ” ì œëª©ê³¼ ì¶• ì´ë¦„ ë“±ì„ ì„¤ì •í•œë‹¤.\n\nSTEP4-2. Plot Optionsì—ì„œëŠ” ìƒ‰ê¹”ì„ í¬í•¨í•œ ì „ë°˜ì ì¸ í…Œë§ˆë¥¼ ì„¤ì •í•œë‹¤.\n\nSTEP4-4. Dataì—ì„œëŠ” í‘œí˜„í•˜ê³ í”ˆ ë˜ëŠ” í‘œí˜„í•˜ê³  ì‹¶ì§€ ì•Šì€ ë°ì´í„°ë¥¼ í•„í„°ë§í•œë‹¤.\n\nSTEP4-3. Export \u0026amp; Dataì—ì„œëŠ” Insert code in scriptë¥¼ í´ë¦­í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¥¼ ë°”ë¡œ scriptë¡œ ì˜®ê²¨ì¤€ë‹¤.\n\nSTEP5. ì¹œì ˆí•˜ê²Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê¹Œì§€ ì œì‹œëœ ì½”ë“œë¥¼ ì‹¤í–‰í•œë‹¤.\nSTEP6. ì¶”ê°€ì ìœ¼ë¡œ ë” ì† ë³´ê³  ì‹¶ì€ ë¶€ë¶„ì„ ê°œì„ í•œë‹¤.\n  ì½”ë“œ ì˜ˆì‹œ  1 2 3 4 5 6 7 8 9 10 11 12  library(dplyr) library(ggplot2) mpg %\u0026gt;% filter(displ \u0026gt;= 1.6 \u0026amp; displ \u0026lt;= 5.95) %\u0026gt;% filter(year \u0026gt;= 1999 \u0026amp; year \u0026lt;= 2005.2) %\u0026gt;% filter(hwy \u0026gt;= 12L \u0026amp; hwy \u0026lt;= 33L) %\u0026gt;% ggplot() + aes(x = manufacturer, y = cyl) + geom_boxplot(fill = \u0026#34;#18c975\u0026#34;) + scale_y_continuous(trans = \u0026#34;log10\u0026#34;) + theme_gray()     ì°¸ê³  [1] https://www.youtube.com/watch?v=FWLxE-ARuO8\n","description":"","id":4,"section":"posts","tags":null,"title":"esquisse","uri":"https://jiwooblog.netlify.app/posts/r/%EC%8B%9C%EA%B0%81%ED%99%94/esquisse/"},{"content":"naniar íŒ¨í‚¤ì§€ í›‘ì–´ë³´ê¸° NA ê´€ë ¨í•´ì„œ ì§ê´€ì ìœ¼ë¡œ ê¹”ë”í•œ ê·¸ë˜í”„ë¡œ í›‘ì–´ë³¼ ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŒ¨í‚¤ì§€ì´ë‹¤.\në³¸ í¬ìŠ¤íŒ…ì€ í•´ë‹¹ ì‚¬ì´íŠ¸ë¥¼ ì ê·¹ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì˜€ë‹¤.\n1 2  library(tidyverse) library(naniar)   vis_miss 1  vis_miss(airquality)   gg_miss_var 1  gg_miss_var(airquality)   1  gg_miss_var(airquality, show_pct = TRUE)   1  gg_miss_var(airquality, facet = Month)   gg_miss_case 1  gg_miss_case(airquality)   gg_miss_upset 1  gg_miss_upset(riskfactors)   1  n_var_miss(riskfactors)   ## [1] 24\r1  gg_miss_upset(riskfactors, nsets = n_var_miss(riskfactors))   1  gg_miss_upset(riskfactors, nsets = 4) #nset: ë³€ìˆ˜ ê°œìˆ˜   1  gg_miss_upset(riskfactors, nsets = 10, nintersects = 5) #nintersects: ë³€ìˆ˜ì¡°í•© ìˆ˜   geom_miss_point ggplotê³¼ ì‘ìš©\n1 2  ggplot(airquality, aes(x = Ozone, y = Solar.R)) + geom_point()   ## Warning: Removed 42 rows containing missing values (geom_point).\r1 2  ggplot(airquality, aes(x = Ozone, y = Solar.R)) + geom_miss_point()   gg_miss_fctfas 1  gg_miss_fct(oceanbuoys, year)   miss_var_summary 1 2 3  riskfactors %\u0026gt;% group_by(marital) %\u0026gt;% miss_var_summary()   ## # A tibble: 231 x 4\r## # Groups: marital [7]\r## marital variable n_miss pct_miss\r## \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 Married smoke_stop 120 91.6 ## 2 Married pregnant 117 89.3 ## 3 Married smoke_last 84 64.1 ## 4 Married smoke_days 73 55.7 ## 5 Married drink_average 68 51.9 ## 6 Married health_poor 67 51.1 ## 7 Married drink_days 67 51.1 ## 8 Married weight_lbs 6 4.58\r## 9 Married bmi 6 4.58\r## 10 Married diet_fruit 4 3.05\r## # ... with 221 more rows\rmiss_var_span, gg_miss_span 1  miss_var_span(pedestrian, hourly_counts, span_every = 3000)   ## # A tibble: 13 x 5\r## span_counter n_miss n_complete prop_miss prop_complete\r## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 1 0 3000 0 1 ## 2 2 0 3000 0 1 ## 3 3 1 2999 0.000333 1.00 ## 4 4 121 2879 0.0403 0.960\r## 5 5 503 2497 0.168 0.832\r## 6 6 555 2445 0.185 0.815\r## 7 7 190 2810 0.0633 0.937\r## 8 8 0 3000 0 1 ## 9 9 1 2999 0.000333 1.00 ## 10 10 0 3000 0 1 ## 11 11 0 3000 0 1 ## 12 12 745 2255 0.248 0.752\r## 13 13 432 2568 0.144 0.856\r1  gg_miss_span(pedestrian, hourly_counts, span_every = 3000)   1  gg_miss_span(pedestrian, hourly_counts, span_every = 3000, facet = sensor_name)   ê·¸ì™¸ ë‹¤ì–‘í•œ 1  gg_miss_case_cumsum(airquality)   1  gg_miss_var_cumsum(airquality)   1  gg_miss_which(airquality)   ","description":"","id":5,"section":"posts","tags":null,"title":"naniar","uri":"https://jiwooblog.netlify.app/posts/r/%EC%8B%9C%EA%B0%81%ED%99%94/naniar/"},{"content":"Machine Learning  ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í†µí•´ì„œ ì…ë ¥ë³€ìˆ˜ì™€ ì¶œë ¥ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜ $f$ë¥¼ ë§Œë“œëŠ” ê²ƒ ì£¼ì–´ì§„ ë°ì´í„° ì†ì—ì„œ ë°ì´í„°ì˜ íŠ¹ì§•ì„ ì°¾ì•„ë‚´ëŠ” í•¨ìˆ˜ $f$ë¥¼ ë§Œë“œëŠ” ê²ƒ  1. ê¸°ë³¸ ê°œë…êµ¬ë¶„  ì§€ë„ í•™ìŠµ: íšŒê·€(Regression), ë¶„ë¥˜(Classification) ë¹„ì§€ë„ í•™ìŠµ: PCA, êµ°ì§‘ë¶„ì„ ê°•í™” í•™ìŠµ: ìˆ˜ë§ì€ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ í˜„ì¬ì˜ ì„ íƒì´ ë¨¼ ë¯¸ë˜ì— ë³´ìƒì´ ìµœëŒ€ë¡œ í•˜ëŠ” actionì„ í•™ìŠµ  2. ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•  ì„ í˜•íšŒê·€ë¶„ì„: ì„ í˜•ê´€ê³„ë¥¼ ê°€ì •í•˜ì—¬, ë…ë¦½ë³€ìˆ˜ì˜ ì¤‘ìš”ë„ì™€ ì˜í–¥ë ¥ íŒŒì•… DT(Decision Tree): ë…ë¦½ë³€ìˆ˜ì˜ ì¡°ê±´ì— ë”°ë¼ ì¢…ì†ë³€ìˆ˜ë¥¼ ë¶„ë¦¬ KNN(K-Nearest Neighbor): ìƒˆë¡œ ë“¤ì–´ì˜¨ ë°ì´í„°ì˜ ì£¼ë³€ Kê°œì˜ ë°ì´í„°ì˜ classë¡œ ë¶„ë¥˜ NN(Neural Network): ì…ë ¥ì¸µ/ì€ë‹‰ì¸µ/ì¶œë ¥ì¸µ ìœ¼ë¡œ êµ¬ì„±ëœ ëª¨í˜•. ê° ì¸µì„ ì—°ê²°í•˜ëŠ” ë…¸ë“œì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ë©° í•™ìŠµ SVM(Support Vector Machine): class ê°„ ê±°ë¦¬ê°€ ìµœëŒ€ê°€ ë˜ë„ë¡ decision boundary ë§Œë“œëŠ” ë°©ë²• K-means Clustering: Label ì—†ì´ ë°ì´í„°ì˜ êµ°ì§‘ kê°œ ìƒì„± Ensemble Learning: ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ë¡œ, êµ¬ì²´ì ìœ¼ë¡œëŠ” ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ ì¢…ë¥˜ê°€ ìˆë‹¤.\n7-1. Bagging: ëª¨ë¸ì„ ë‹¤ì–‘í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ì¬êµ¬ì„±\n7-2. Random Forest: ëª¨ë¸ì„ ë‹¤ì–‘í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ ë°ì´í„°ë¿ë§Œ ì•„ë‹ˆë¼ ë³€ìˆ˜ë„ ì¬êµ¬ì„±\n7-3. Boosting: ë§ì¶”ê¸° ì–´ë ¤ìš´ ë°ì´í„°ì— ëŒ€í•´ ì¢€ ë” ê°€ì¤‘ì¹˜ë¥¼ ë‘ì–´ seqeuntialí•˜ê²Œ í•™ìŠµí•˜ëŠ” ê°œë… (ex. AdaBoost, Gradient Boosting(Xgboost, LightGBM, CatBoost)\n7-4. Stacking: ëª¨ë¸ì˜ outputê°’ì„ ìƒˆë¡œìš´ ë…ë¦½ë³€ìˆ˜ë¡œ í™œìš© Deep Learning: ë”¥ëŸ¬ë‹ì€ ì‚¬ì‹¤ ë¨¸ì‹ ëŸ¬ë‹ì˜ ë¶€ë¶„ì§‘í•©ì´ë‹¤. í•˜ì§€ë§Œ ì›Œë‚™ ê¹Šê³  ë‹¤ì–‘í•˜ê¸°ì— ë”°ë¡œ ë‹¤ë£¨ë„ë¡ í•˜ê² ë‹¤.  3. ëª¨í˜•ì˜ ì í•©ì„± í‰ê°€ ë° ì‹¤í—˜ì„¤ê³„ ë°ì´í„°ë¥¼ Training-Validation-Test, ì´ ì„¸ ê°€ì§€ ì„¸íŠ¸ë¡œ ë‚˜ëˆˆë‹¤.\nK-Fold Cross Validation ë°ì´í„°ë¥¼ kê°œ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ ë’¤, í•˜ë‚˜ë¥¼ ê²€ì¦ì§‘í•© ë‚˜ë¨¸ì§€ë¥¼ í•™ìŠµì§‘í•©ìœ¼ë¡œ í•œë‹¤. ì´ ê³¼ì •ì„ kë²ˆ ë°˜ë³µí•´ì„œ kê°œì˜ ì„±ëŠ¥ì§€í‘œë¥¼ êµ¬í•˜ê³  ê·¸ê²ƒë“¤ì˜ í‰ê· ì„ êµ¬í•œë‹¤.\nLOOCV(Leave One Out Cross Validation) ë°ì´í„°ë¥¼ kê°œì˜ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ê¸°ì— ë¶€ì¡±í•  ë•Œ, ë°ì´í„° í•œ ê°œì”©ì„ ë¹¼ê°€ë©´ì„œ K-fold CVë¥¼ í•˜ëŠ” ë°©ì‹ê³¼ ë˜‘ê°™ì´ í•œë‹¤.\n4. ê³¼ì í•©(Overfitting) ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ê°€ì¥ ì£¼ì˜í•´ì•¼ í•  ê²ƒ ì¤‘ í•˜ë‚˜ê°€ ë°”ë¡œ ê³¼ì í•©ì´ë‹¤. ì´ì™€ ê´€ë ¨í•´ì„œëŠ” Bias-Variance Tradeoffì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•˜ë‹¤. ê·¸ë¦¬ê³  ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ì•„ë˜ ë‘ ì‚¬ì§„ì„ ì°¸ê³ í•˜ë©´ ë  ê²ƒì´ë‹¤.\nì°¸ê³  [1] https://medium.com/@cs.sabaribalaji/overfitting-6c1cd9af589\n[2] https://www.researchgate.net/figure/The-overfitting-of-model-a-training-error-and-true-error-b-depiction-of-Eq-33_fig5_333505702\n","description":"ë¨¸ì‹ ëŸ¬ë‹ ê°œê´„","id":6,"section":"posts","tags":null,"title":"ML Intro","uri":"https://jiwooblog.netlify.app/posts/machinelearning/intro/"},{"content":"ì¤‘ì‹¬ê·¹í•œì •ë¦¬(Central Limit Theorem) $ X_1, ... X_n $ì„ í‰ê· ì´ $\\mu$ì´ê³ , ë¶„ì‚°ì´ $\\sigma^2$ì¸ ë¶„í¬ë¡œë¶€í„° ë¬´ì‘ìœ„ë¡œ ì–»ì€ ìƒ˜í”Œì´ë¼ê³  í•˜ì. (ë‹¨, $\\sigma^2 \u0026lt; \\infty$)\nê·¸ëŸ¬ë©´ $Y_n = \\frac{\\sqrt{n}(\\bar{X_n} - \\mu)}{\\sigma}$ì€ $N(0,1)$ì„ ê·¹í•œë¶„í¬ë¡œ ê°–ëŠ”ë‹¤.\nì¦ëª… mgfë¥¼ í™œìš©í•˜ì—¬ ì¦ëª…í•œë‹¤. (ì¶”í›„ ì¶”ê°€ ì˜ˆì •)\n","description":"","id":7,"section":"posts","tags":null,"title":"ì¤‘ì‹¬ê·¹í•œì •ë¦¬","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/central_limit_theorem/"},{"content":"í™•ë¥ ë¶„í¬(Probability Distribution) ì¶œì²˜: https://artificialnetworkforstarters.readthedocs.io/en/latest/_post/chap6.html  -- ì—°ì†í˜•(Continuous)  ì •ê·œ ë¶„í¬ T-ë¶„í¬ ê°ë§ˆ ë¶„í¬ ë² íƒ€ ë¶„í¬ ì¹´ì´ì œê³± ë¶„í¬ F-ë¶„í¬ ê· ì¼ ë¶„í¬ ë””ë¦¬í´ë ˆ ë¶„í¬ ìœ„ìƒ¤íŠ¸ ë¶„í¬\n\u0026hellip;  ì´ì‚°í˜•(Discrete)  ì´í•­ ë¶„í¬ ë‹¤í•­ ë¶„í¬ ë² ë¥´ëˆ„ì´ ë¶„í¬ í¬ì•„ì†¡ ë¶„í¬ ìŒì´í•­ ë¶„í¬ ê¸°í•˜ ë¶„í¬ ì´ˆê¸°í•˜ ë¶„í¬\n\u0026hellip;  ì •ê·œ ë¶„í¬(Normal Distribution)   ì •ê·œë¶„í¬  $$ \\text{X~} N(\\mu, \\sigma^2) \\rightarrow f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(x-\\mu)}{2\\sigma^2}^2) $$\n$$ E(X) = \\mu, Var(X) = \\sigma^2$$   ë‹¤ë³€ìˆ˜ ì •ê·œë¶„í¬(Multivariate Normal Distribution) ê´€ë ¨ í¬ìŠ¤íŒ… ì°¸ê³ \nT-ë¶„í¬(Student\u0026rsquo;s t-Distribution)   T-ë¶„í¬  $$ \\text{X~} t(n) \\rightarrow f(x) = \\frac{\\Gamma(\\frac{n+1}{2})}{\\Gamma(\\frac{n}{2})\\cdot\\sqrt{\\pi n}}(\\frac{n}{x^2+n})^\\frac{n+1}{2} \\ \\text{ for } -\\infty\u0026lt;x\u0026lt;\\infty$$\n$$ E(X) = 0, Var(X) = \\frac{n}{n-2} $$\nTë¶„í¬ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í†µê³„ê²€ì •ì„ í•˜ê¸° ìœ„í•´ì„œ ì‘ìœ„ì ìœ¼ë¡œ ê³ ì•ˆëœ ë¶„í¬ì´ë‹¤.\nTë¶„í¬ì˜ íƒ„ìƒ ê³¼ì •ì€ ì•„ë˜ì™€ ê°™ë‹¤.\n$$ T = \\frac{Z}{\\sqrt{\\frac{V}{\\nu}}} \\text{~ } t(df)$$\nwhere $Z\\text{~ }N(0,1), V\\text{~ } \\chi^2(\\nu)$\n  ì´í•­ ë¶„í¬(Binomial Distribution)   ì´í•­ë¶„í¬  $$ \\text{X~} Binom(n, p) \\rightarrow f(x) = \\binom{n}{x}p^x(1-p)^{n-x} $$\n$$ E(X) = np, Var(X) = np(1-p) $$   ìŒì´í•­ ë¶„í¬(Negative Binomial Distribution) në²ˆì§¸ ì‹œí–‰ì—ì„œ rë²ˆì§¸ ì„±ê³µì„ í™•ë¥ ì„ êµ¬í•˜ê³ ì í•  ë•Œ í™œìš©í•œë‹¤.\nìŒì´í•­ ë¶„í¬ì—ì„œëŠ” ì‹œí–‰ íšŸìˆ˜ nì´ í™•ë¥ ë³€ìˆ˜ì´ê³  ì„±ê³µ íšŸìˆ˜ rì´ ê³ ì •ë˜ì–´ ìˆëŠ” ë°˜ë©´, ì´í•­ë¶„í¬ì—ì„œëŠ” ì‹œí–‰ íšŸìˆ˜ nì´ ê³ ì •ë˜ì–´ ìˆê³  ì„±ê³µ íšŸìˆ˜ rì´ í™•ë¥ ë³€ìˆ˜ì´ë‹¤. ê·¸ë˜ì„œ ìŒì´í•­ë¶„í¬ë¼ê³  ì´ë¦„ì§€ì–´ì§„ ê²ƒì´ë‹¤.\n  ìŒì´í•­ ë¶„í¬(X : rë²ˆì§¸ ì„±ê³µì„ ì–»ì„ ë•Œê¹Œì§€ ì‹œí–‰íšŸìˆ˜)  $$\\text{X~} Negative \\ Binomial(r, p) $$\n$$\\rightarrow f(x) = \\binom{x-1}{r-1}p^r(1-p)^{x-r}, \\ x=r, r+1, \u0026hellip; $$\n$$ E(X) = \\frac{r}{p}, \\ Var(X) = r \\cdot\\frac{1-p}{p^2}$$  \nì—¬ê¸°ì„œ x = r+yë¡œ í•˜ì—¬, rë²ˆì§¸ ì„±ê³µì„ ì–»ì„ ë•Œê¹Œì§€ ì‹¤íŒ¨íšŸìˆ˜ë¥¼ ê³„ì‚°í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.\ní•´ë‹¹ í™•ë¥ ë¶„í¬ í˜•íƒœì— ë”°ë¼ ìŒì´í•­ë¶„í¬ë¼ê³  ì´ë¦„ì§€ì–´ì§„ ê²ƒì„ì„ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n  ìŒì´í•­ ë¶„í¬(Y : rë²ˆì§¸ ì„±ê³µì„ ì–»ì„ ë•Œê¹Œì§€ ì‹¤íŒ¨íšŸìˆ˜)  $$\\text{Y~} Negative \\ Binomial(r, p) $$\n$$\\rightarrow f(y) = \\binom{r+y-1}{r-1}p^r(1-p)^y, \\ y=0,1,2,\u0026hellip;$$\n$$\\rightarrow f(y) = (-1)^y\\binom{-r}{y}p^r(1-p)^y, \\ y=0,1,2,\u0026hellip; $$\n$$ E(Y) = r\\cdot\\frac{1-p}{p}, \\ Var(Y) = r \\cdot\\frac{1-p}{p^2}$$  \nê°ë§ˆ ë¶„í¬(Gamma Distribution)   ê°ë§ˆë¶„í¬ (ì•ŒíŒŒ: shape, ë² íƒ€: scale)  $$ \\text{X~} Gamma(\\alpha, \\beta) \\rightarrow f(x) = \\frac{1}{\\beta^\\alpha\\cdot\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\frac{x}{\\beta}}$$\n$\\text{for } x\u0026gt;0, \\ \\alpha\u0026gt;0, \\ \\beta\u0026gt;0 $\n$$ E(X)=\\alpha\\beta, \\ Var(X)=\\alpha\\beta^2 $$  --  Gamma Distribution: k=alpha, theta=betaë¡œ ìƒê°í•˜ê¸°  -- ì°¸ê³ ë¡œ, í¬ì•„ì†¡ë¶„í¬, ì§€ìˆ˜ë¶„í¬, ì¹´ì´ì œê³±ë¶„í¬ì™€ì˜ ì—°ê´€ì„±ì„ ìƒê°í•˜ë©´ ë² íƒ€ë¥¼ rate parameterë¡œ ë³´ëŠ” ê²ƒì´ ì¢‹ë‹¤.\në² íƒ€ë¥¼ scaleë¡œ ë³´ëŠ” ë°©ì‹ì€ ê°€ë ¤ë‘ë„ë¡ í•˜ê² ë‹¤.\n  ê°ë§ˆë¶„í¬ (ì•ŒíŒŒ: shape, ë² íƒ€: rate)  $$ \\text{X~} Gamma(\\alpha, \\beta) \\rightarrow f(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\beta x}$$\n$\\text{for } x\u0026gt;0, \\ \\alpha\u0026gt;0, \\ \\beta\u0026gt;0 $\n$$ E(X)=\\frac{\\alpha}{\\beta}, \\ Var(X)=\\frac{\\alpha}{\\beta^2} $$  \n  ì—­ê°ë§ˆ ë¶„í¬ (inverse-Gamma)  $$ \\text{X~} inv-Gamma(\\alpha, \\beta) \\rightarrow f(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\left(\\frac{1}{x}\\right)^{\\alpha+1}exp(-\\frac{\\beta}{x}) $$\n$\\text{for } x\u0026gt;0, \\ \\alpha\u0026gt;0, \\ \\beta\u0026gt;0 $\n$$ E(X)=\\frac{\\beta}{\\alpha-1}, \\ Var(X)=\\frac{\\beta^2}{(\\alpha-1)^2(\\alpha-2)} \\ \\text{for } \\alpha\u0026gt;1$$     ìŠ¤ì¼€ì¼ëœ ì—­ê°ë§ˆë¶„í¬ (scaled inverse-Gamma)  $$\\text{X~} \\chi^{-2}(\\nu, \\tau^2) = \\Gamma^{-1}(\\nu/2, \\nu\\tau^2/2) $$\n$$\\rightarrow f(x) = \\frac{(\\nu\\tau^2/2)^{\\nu/2}}{\\Gamma(\\nu/2)}\\left(\\frac{1}{x}\\right)^{\\nu/2+1}exp(-\\frac{\\nu\\tau^2}{2x}) $$   ë² íƒ€ ë¶„í¬(Beta Distribution)   ë² íƒ€ ë¶„í¬  $$ \\text{X~} Beta(\\alpha, \\beta) \\rightarrow f(x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1} $$\n$\\text{for } x\\in[0,1], \\ \\alpha\u0026gt;0, \\ \\beta\u0026gt;0 $\n$$ E(X) = \\frac{\\alpha}{\\alpha+\\beta}, \\ Var(X) = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}, \\ mode(X) = \\frac{\\alpha-1}{\\alpha+\\beta-2} (\\text{ë‹¨}, \\alpha\u0026gt;1, \\ \\beta\u0026gt;1) $$   ë””ë¦¬í´ë ˆ ë¶„í¬(Dirichlet Distribution) ë””ë¦¬í´ë ˆ ë¶„í¬ëŠ” ë² íƒ€ë¶„í¬ì˜ ë‹¤ë³€ëŸ‰ ë²„ì „ì´ë‹¤.\n  ë””ë¦¬í´ë ˆ ë¶„í¬  $$\\theta \\text{ ~ } Dirichlet(\\alpha) \\rightarrow p(\\theta) = \\frac{1}{B(\\alpha)}\\prod_{j=1}^{k}\\theta_j^{\\alpha_j-1} $$\n$$\\text{for } B(\\alpha) = \\frac{\\prod\\Gamma(\\alpha_j)}{\\Gamma(\\sum \\alpha_j)}, \\sum_{j=1}^{k}\\theta_j=1 $$  \ní¬ì•„ì†¡ ë¶„í¬(Poisson Distribution) ì •í•´ì§„ ì‹œê°„ ì•ˆì— ì–´ë–¤ ì‚¬ê±´ì´ ì¼ì–´ë‚  íšŸìˆ˜ì— ëŒ€í•œ ê¸°ëŒ“ê°’ì„ $\\lambda$ ë¼ê³  í–ˆì„ ë•Œ, ê·¸ ì‚¬ê±´ì´ níšŒ ì¼ì–´ë‚  í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n  í¬ì•„ì†¡ ë¶„í¬  $$ \\text{X~} Pois(\\lambda) \\rightarrow f(x) = \\frac{\\lambda^x e^\\lambda}{x!}$$\nfor $x$: 0ì´ìƒì˜ ì •ìˆ˜, $\\lambda\u0026gt;0$\n$$ E(X) = Var(X) = \\lambda $$  \n\nì§€ìˆ˜ ë¶„í¬(Exponential Distribution) ì‚¬ê±´ì´ ì„œë¡œ ë…ë¦½ì ì¼ ë•Œ, ì¼ì • ì‹œê°„ë™ì•ˆ ë°œìƒí•˜ëŠ” ì‚¬ê±´ì˜ íšŸìˆ˜ê°€ í‘¸ì•„ì†¡ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ë©´, ë‹¤ìŒ ì‚¬ê±´ì´ ì¼ì–´ë‚  ë•Œê¹Œì§€ ëŒ€ê¸° ì‹œê°„ ë˜ëŠ” ì‚¬ê±´ì´ í•œ ë²ˆ ì¼ì–´ë‚  ë•Œê¹Œì§€ ê±¸ë¦¬ëŠ” ì‹œê°„ì€ ì§€ìˆ˜ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤. ì§€ìˆ˜ë¶„í¬ëŠ” ê°ë§ˆë¶„í¬ì˜ íŠ¹ìˆ˜í•œ í˜•íƒœì´ë‹¤.\n  ì§€ìˆ˜ ë¶„í¬  $$\\text{X~} exp(\\lambda) \\rightarrow f(x) = \\lambda e^{\\lambda x} $$\n$exp(\\lambda) = \\Gamma(1,\\lambda) $ where $\\beta$ìœ„ì¹˜ì˜ ëª¨ìˆ˜ê°€ rate parameterë¥¼ ëœ»í•  ë•Œ!\n$$ E(X) = \\frac{1}{\\lambda}, \\ Var(X)=\\frac{1}{\\lambda^2} $$  \n\nì¹´ì´ì œê³± ë¶„í¬(Chi-squared Distribution) $\\nu$ê°œì˜ ì„œë¡œ ë…ë¦½ì ì¸ í‘œì¤€ì •ê·œë¶„í¬ í™•ë¥ ë³€ìˆ˜ë¥¼ ê°ê° ì œê³±í•œ ë‹¤ìŒ í•©í•´ì„œ ì–»ì–´ì§€ëŠ” ë¶„í¬ì´ë‹¤.\nì´ë•Œ $\\nu$ë¥¼ ììœ ë„ë¼ê³  í•˜ë©°, ì¹´ì´ì œê³± ë¶„í¬ì˜ ë§¤ê°œë³€ìˆ˜ê°€ ëœë‹¤.\n  ì¹´ì´ì œê³± ë¶„í¬  $$\\text{X~} \\chi^2(\\nu) \\rightarrow f(x) = \\frac{(\\frac{1}{2})^\\frac{\\nu}{2}}{\\Gamma(\\frac{\\nu}{2})}x^{\\frac{\\nu}{2}-1}e^{-x/2} $$\n$\\chi^2(\\nu) = \\Gamma(\\frac{\\nu}{2}, \\frac{1}{2}) $ where $\\beta$ìœ„ì¹˜ì˜ ëª¨ìˆ˜ê°€ rate parameterë¥¼ ëœ»í•  ë•Œ!\n$$ E(X) = \\nu, \\ Var(X) = 2\\nu$$  \n\n  ì—­ì¹´ì´ì œê³± ë¶„í¬ (inverse Chi-squared)  $$\\text{X~} \\chi^{-2}(\\nu) = \\Gamma^{-1}(\\nu/2, 1/2) $$\n$$\\rightarrow f(x) = \\frac{(1/2)^{\\nu/2}}{\\Gamma(\\nu/2)}\\left(\\frac{1}{x}\\right)^{\\nu/2+1}exp(-\\frac{1}{2x}) $$     ìŠ¤ì¼€ì¼ëœ ì—­ì¹´ì´ì œê³±ë¶„í¬ (scaled inverse chi-squard)  $$\\text{X~} \\chi^{-2}(\\nu, \\tau^2) = \\Gamma^{-1}(\\nu/2, \\nu\\tau^2/2) $$\n$$\\rightarrow f(x) = \\frac{(\\nu\\tau^2/2)^{\\nu/2}}{\\Gamma(\\nu/2)}\\left(\\frac{1}{x}\\right)^{\\nu/2+1}exp(-\\frac{\\nu\\tau^2}{2x}) $$   ë¼í”Œë¼ìŠ¤ ë¶„í¬(Laplace Distribution) ì§€ìˆ˜ë¶„í¬ë¥¼ ë‘ ê°œ ë¶™ì—¬ë†“ì€ ê²ƒ ê°™ë‹¤ê³  í•˜ì—¬ double-exponential distributionì´ë¼ê³ ë„ ë¶ˆë¦°ë‹¤.\n  ë¼í”Œë¼ìŠ¤ ë¶„í¬ (Laplcace Distribution)  $$\\text{X~} Laplace(\\mu, b) \\rightarrow f(x) = \\frac{1}{2b}exp(-\\frac{|x-\\mu|}{b}) $$\n$$ E(X) = \\mu, Var(X) = 2b^2 $$  \n\nì‚¬ì§„ ì¶œì²˜ [1] https://artificialnetworkforstarters.readthedocs.io/en/latest/_post/chap6.html\n[2] ìœ„í‚¤ë°±ê³¼\n","description":"","id":8,"section":"posts","tags":null,"title":"í™•ë¥ ë¶„í¬","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/probability_distribution/"},{"content":"Index  í†µê³„í•™ì´ë€?  í‘œë³¸ë¶„í¬ ëª¨ìˆ˜ ê²€ì • \u0026amp; ë¹„ëª¨ìˆ˜ ê²€ì •   ê¸°ìˆ í†µê³„  ë°ì´í„° ìœ í˜• ë¶„í¬ì˜ ì´í•´ CLT   ê°€ì„¤ê²€ì •  ì–‘ë°©í–¥ \u0026amp; ë‹¨ë°©í–¥   ì •ê·œì„± ê²€ì •  Kolmogorov-Smirnov test(í‘œë³¸ 50ê°œ ì´ìƒ) Shapiro-Wilk test(í‘œë³¸ 50ê°œ ì´í•˜) ëª¨ìˆ˜ì  ì ‘ê·¼ \u0026amp; ë¹„ëª¨ìˆ˜ì  ì ‘ê·¼   ë‹¨ì¼ì§‘ë‹¨ í‰ê·   ëª¨ìˆ˜ì  ì ‘ê·¼(one sample t-test) ë¹„ëª¨ìˆ˜ì  ì ‘ê·¼(Kolmogorov-Smirnov test, Runs ê²€ì •)   ë…ë¦½ ë‘ ì§‘ë‹¨ í‰ê·   ëª¨ìˆ˜ì  ì ‘ê·¼(independent t-test) ë¹„ëª¨ìˆ˜ì  ì ‘ê·¼(Mann-Whitney U-test, Wilcoxon rank-sum test, Kolmogorov-Smirnov test, ì¤‘ì•™ê°’ ê²€ì •)   ëŒ€ì‘ ë‘ ì§‘ë‹¨ í‰ê·   ëª¨ìˆ˜ì  ì ‘ê·¼(paired t-test) ë¹„ëª¨ìˆ˜ì  ì ‘ê·¼(sign test, Wilcoxon signed rank test)   ë…ë¦½ ì„¸ ì§‘ë‹¨ ì´ìƒ í‰ê·   ëª¨ìˆ˜ì  ì ‘ê·¼(ANOVA) ë¹„ëª¨ìˆ˜ì  ì ‘ê·¼(Kruskal-Wallis test) ì‚¬í›„ë¶„ì„(Bonferroni)   ì¢…ì† ì„¸ ì§‘ë‹¨ ì´ìƒ í‰ê·   ë¹„ëª¨ìˆ˜ì  ì ‘ê·¼(Cochran Q test, Friedman test)   ì¹´ì´ì œê³±ê²€ì •(ë²”ì£¼í˜• ë°ì´í„°)  ë…ë¦½ì„± ê²€ì • ì í•©ë„ ê²€ì • ë™ì§ˆì„± ê²€ì •   ìƒê´€ë¶„ì„  ëª¨ìˆ˜ì  ì ‘ê·¼ ë¹„ëª¨ìˆ˜ì  ì ‘ê·¼(Spearman ìƒê´€ê³„ìˆ˜, Kendall ìˆœìœ„ ìƒê´€ê³„ìˆ˜, Kendall í¸ ìˆœìœ„ ìƒê´€ê³„ìˆ˜, Kendall ì¼ì¹˜ë„ ê³„ìˆ˜)    ","description":"","id":9,"section":"posts","tags":null,"title":"ê°œìš”","uri":"https://jiwooblog.netlify.app/posts/spss/prologue/"},{"content":"ë¯¸ë¶„(Differentiation) 1. Chain Rule $$\\frac{dy}{dx} = \\frac{dy}{du} \\times \\frac{du}{dx}$$\n2. Product Rule $$\\frac{dy}{dx} = \\frac{du}{dx}v + u\\frac{dv}{dx}$$\nì´ë¥¼ ë‹¤ë¥´ê²Œ ì“°ë©´,\n$$y = f(x)g(x)$$\n$$\\rightarrow y'=f'(x)g(x)+f(x)g'(x)$$\n3. Quotient Rule $$y = \\frac{f(x)}{g(x)}$$\n$$\\rightarrow y' = \\frac{f'(x)g(x) - f(x)g'(x)}{g^2(x)}$$\n4. Implicit Differentiation $$\\frac{d}{dx}[f(y)] = \\frac{d}{dy}[f(y)] \\times \\frac{dy}{dx} $$\n","description":"","id":10,"section":"posts","tags":null,"title":"ë¯¸ë¶„","uri":"https://jiwooblog.netlify.app/posts/statistics/calculus/1_differentiation/"},{"content":"1. ì¶”ì²œ ì‚¬ì´íŠ¸  pandas_exercises  2. ì¶”ì²œ ì±…  Python for Data Analysis (Wes McKinney)  3. ê²€ìƒ‰ íŒ êµ¬ê¸€ë§ ì‹œ, ë’¤ì— \u0026lsquo;towards data science\u0026rsquo; ë˜ëŠ” \u0026lsquo;medium\u0026rsquo; ë¶™ì´ê¸°\ní•˜ë£¨ ì—´ëŒ ì œí•œì´ ìˆëŠ”ë°, ë” ì½ê³  ì‹¶ì€ ê²½ìš°ëŠ” Chrome ì‹œí¬ë¦¿ ëª¨ë“œë¥¼ í™œìš©í•˜ë©´ ì œí•œì´ í’€ë¦°ë‹¤.\n","description":"","id":11,"section":"posts","tags":null,"title":"Python ê¿€íŒ","uri":"https://jiwooblog.netlify.app/posts/python/python_tip/"},{"content":"To Do List 1. Want to Upload Posts   í”„ë¡œì íŠ¸ë“¤ ì •ë¦¬\n Rhino: ìˆ˜ì†Œì°¨ ì¶©ì „ì†Œ ì…ì§€ ì„ ì • [ESC 2020_SUMMER] ë¹…ì½˜í…ŒìŠ¤íŠ¸ NS Shop+ ì‹¬ë¦¬ì„±í–¥ ì˜ˆì¸¡ AI ê²½ì§„ëŒ€íšŒ [ESC 2020_FALL] NLP ë…¼ë¬¸ ë”°ë¼í•´ë³´ê¸° [ESC 2020_SPRING] í–‰ë³µì§€ìˆ˜ ì˜ˆì¸¡\n- ë°°ìš´ ì : í•´ì„ ì‹œ Domain Knowledgeì˜ ì¤‘ìš”ì„±, FAì˜ íš¨ê³¼    R ë‹¤ì–‘í•œ ê¸°ëŠ¥ë“¤ ì •ë¦¬\n dpylr: group_by, summarise, mutate, select, filter ì‹œê°í™”\n2-1. ggplot2\n2-2. plotly\n2-3. highcharter\n2-4. g2r\n2-5. rayshader\n2-6. ggmap\n2-7. r4issactoast\n2-8. naniar(gg_miss_upset)\n2-9. gganimate\n2-10. esquisse: ë“œë˜ê·¸\u0026amp;ë“œë¡­ìœ¼ë¡œ ggplot ê·¸ë¦¬ê¸° shiny NA imputation\n4-1. mice visNetwork(visNodes, visEdges) apriori(ì—°ê´€ì„±ë¶„ì„, ì¥ë°”êµ¬ë‹ˆë¶„ì„) xaringan(Rë¡œ PPT ë§Œë“¤ê¸°)\n7-1. ì°¸ê³ ì‚¬ì´íŠ¸1\n7-2. ì°¸ê³ ì‚¬ì´íŠ¸2 Rstudio Ligature ì ìš©í•˜ê¸° ì°¸ê³ ì‚¬ì´íŠ¸ latex2exp: expression ëŒ€ì‹  latexë¬¸ë²• í™œìš©í•˜ê¸°    SPSS\n ê¸°ìˆ í†µê³„(ë°ì´í„° ìœ í˜•, ë¶„í¬ì˜ ì´í•´) í‘œë³¸ë¶„í¬ì˜ ê°œë… ì •ê·œì„± ê²€ì •(ëª¨ìˆ˜ì  ì ‘ê·¼ \u0026amp; ë¹„ëª¨ìˆ˜ì  ì ‘ê·¼) ê°€ì„¤ê²€ì • ë‹¨ì¼ì§‘ë‹¨ í‰ê·  ë…ë¦½ ë‘ ì§‘ë‹¨ í‰ê·  ëŒ€ì‘ ë‘ ì§‘ë‹¨ í‰ê·  ë…ë¦½ ì„¸ ì§‘ë‹¨ ì´ìƒ í‰ê·  ì¹´ì´ì œê³±ê²€ì •(ë²”ì£¼í˜• ë°ì´í„°)    Statistics\n0. SPSS ë‚´ìš© ëŒ€ë¶€ë¶„\n ë¶„í¬ ê°„ ê´€ê³„ë„ ì •ë¦¬ mgf(moment generating function)\n2-1. í…Œì¼ëŸ¬ê¸‰ìˆ˜ normal sampling theory ì¦ëª…    Updates  ì£¼ì‹  gitignoreë‚˜ config.toml ignoreFilesì— ì¶”ê°€í•´ë‘ê¸° ë§¤ë‹¬ ì´ˆ ê¸°ë¡í•˜ê¸° ë§¤ ë§¤ë§¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•´ë³´ê¸° ì½”ìŠ¤í”¼, ì½”ìŠ¤ë‹¥, ë‚˜ìŠ¤ë‹¥, S\u0026amp;P500, ë‹¤ìš°ì¡´ìŠ¤, í™˜ìœ¨ ë“±ì˜ ì§€í‘œì™€ ì§€ìˆ˜ë“¤ì„ ì •ë¦¬í•˜ê¸° ìŠˆì¹´ì›”ë“œ ì •ë¦¬í•˜ê¸°(ë¯¸ì •)    Blog  Blogdownìœ¼ë¡œ ë¸”ë¡œê·¸ ë§Œë“¤ê¸°  blogdown ì„¤ì¹˜ ë° ì‚¬ì´íŠ¸ ê°œì„¤\n1-1. í…Œë§ˆ ì¶”ì²œ(ê°€ì¥ ìœ ëª…í•œ Academic, Rstudioì—ì„œ ê³µì‹ì ìœ¼ë¡œ ë°€ê³  ìˆëŠ” Apero, ê¹”ë”í•œ distill ) github ì—…ë¡œë“œ ë°©ì‹ (Terminal ì‚¬ìš©ë²•)\n2-1. ì„¸ë¶€ ì˜¤ë¥˜ ìˆ˜ì •(ìê²©ì¦ëª… ê´€ë¦¬ì-Windows ìê²©ì¦ëª…)ì°¸ê³ ì‚¬ì´íŠ¸\n2-2. git origin ìˆ˜ì •í•˜ê¸° ì°¸ê³ ì‚¬ì´íŠ¸\n2-3. .Rprofile ìˆ˜ì •í•˜ê¸° (blogdown.knit.on_save = TRUE) í…Œë§ˆ ì„ íƒí•˜ê¸° / Markdown ë¬¸ë²• ê¸°ë³¸ ì†Œê°œ ì„¸ë¶€ìˆ˜ì •í•˜ê¸° 1) baseURL ì„¸ë¶€ìˆ˜ì •í•˜ê¸° 2) (ex. config.tomlì˜ baseURL, ì´ë¯¸ì§€ ì‚½ì…) Comment ê¸°ëŠ¥ ì¶”ê°€í•˜ê¸°(disqus, gitalk) LaTex ìˆ˜ì‹ ë¦¬ìŠ¤íŠ¸ (mdì™€ RMD êµ¬ë¶„í•˜ê¸°) Netlifyë¡œ ë°°í¬í•˜ê¸° ë¸”ë¡œê·¸íƒ­ ë°”ê¾¸ê¸°(static-\u0026gt;favicon) favicon ë³€í™˜ì‚¬ì´íŠ¸ ì½”ë“œ ê²°ê³¼ë¬¼ ê¸€ì”¨ìƒ‰ê¹” ë°”ê¾¸ê¸° (assets / sass / themes / _lightcode.scss ì¤‘ì—ì„œ content-code-in-pre-color ë°”ê¿”ì£¼ê¸°) (ë‹¨, zdoc themeì— í•œì •ëœ ê²ƒì¼ ìˆ˜ë„!)\n10-1. ìœ„ì˜ ë°©ë²•ì´ ì•ˆëœë‹¤ë©´, config.toml ì¤‘ \u0026lsquo;markup.highlight\u0026rsquo;ì— \u0026lsquo;style=\u0026ldquo;fruity\u0026rdquo;\u0026lsquo;ì™€ ê°™ì€ style ì¶”ê°€í•˜ê¸° style ì°¸ê³ ì‚¬ì´íŠ¸    --- 2. Want to Know  Rmdë¡œ plot ê·¸ë¦´ ë•Œ, dataë¥¼ ì–´ë””ì— ë„£ì–´ë†”ì•¼ í•˜ëŠ”ì§€  ","description":"","id":12,"section":"updates","tags":null,"title":"To Do List","uri":"https://jiwooblog.netlify.app/updates/todo_list/"},{"content":"2021ë…„ 3ì›”    ì£¼ë¬¸ë‚ ì§œ ì œí’ˆëª… ë¸Œëœë“œ ê¸ˆì•¡ ì‡¼í•‘ëª° ë§í¬     3.12 ìº‰ê³¨ íŠ¸ë¡œí”½ í—ŒíŒ…ìº¡ 504 BEIGE (Sì‚¬ì´ì¦ˆ) ìº‰ê³¨ 39,647ì› SSGë‹·ì»´ ë§í¬   3.19 ì¸ì‚¬ì¼ëŸ°ìŠ¤ êµ¬ë¥´ì¹´ íŒ¬ì¸  Indigo (S ì‚¬ì´ì¦ˆ) ì¸ì‚¬ì¼ëŸ°ìŠ¤ 63,000ì› ê³µí™ˆ ë§í¬    2021ë…„ 2ì›”    ì£¼ë¬¸ë‚ ì§œ ì œí’ˆëª… ë¸Œëœë“œ ê¸ˆì•¡ ì‡¼í•‘ëª°     2.6 ë‰´ë°œë€ìŠ¤ 327 ì˜¤ë Œì§€ ë‰´ë°œë€ìŠ¤ 114,000ì› í¬ë¦¼   2.23 ìº‰ê³¨ íŠ¸ë¡œí”½ í—ŒíŒ…ìº¡ 504 BEIGE (Mì‚¬ì´ì¦ˆ, ë°˜í’ˆ) ìº‰ê³¨ 37,850ì› ì¸í„°íŒŒí¬   2.24 19ss easy pants brick ìœ ë‹ˆí¼ë¸Œë¦¿ì§€ 15,000ì› ì—ë”§ì—ë””ì…˜   2.24 19fw fisherman cardigan orange ìœ ë‹ˆí¼ ë¸Œë¦¿ì§€ 25,000ì› ì—ë”§ì—ë””ì…˜    ","description":"","id":13,"section":"updates","tags":null,"title":"ì‡¼í•‘ ë¦¬ìŠ¤íŠ¸","uri":"https://jiwooblog.netlify.app/updates/shopping_list/"},{"content":"Part 2-1. ë°ì´í„° ì—”ì§€ë‹ˆì–´ ê¸°ì´ˆ ë‹¤ì§€ê¸° ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. Unix í™˜ê²½ ë° ì»¤ë§¨ë“œ cd\nmkdir\nls\ncp\n./run.sh\nchmod +x run.sh: Permission denied ë˜ì—ˆì„ ë•Œ, ê¶Œí•œ ë¶€ì—¬í•˜ê¸°\nrun.sh ì½”ë“œ(ì°¸ê³ ìš©) #!/bin/bash\rpython examply.py 1 \u0026gt; example.txt\rpython examply.py 2 \u0026gt; example.txt\r*ì£¼ì˜ì‚¬í•­: python ëŒ€ì‹ ì— python3ë¥¼ ì“°ë©´ Windowsì—ì„œëŠ” ì˜¤ë¥˜ê°€ ë‚  ìˆ˜ë„ ìˆë‹¤.\n2. AWS ê¸°ì´ˆ ë° CLI ì„¸íŒ… AWS CLI (Command Line Interface) ë‹¤ìš´ë¡œë“œ\n IAMì—ì„œ ì‚¬ìš©ì ì¶”ê°€í•˜ê¸° Windows Powershellì—ë‹¤ê°€ aws configure ì…ë ¥í•˜ê¸° ì•¡ì„¸ìŠ¤ í‚¤ IDì™€ ë¹„ë°€ ì•¡ì„¸ìŠ¤ í‚¤ ì…ë ¥í•˜ê¸°  ì´ëŠ” ì•ìœ¼ë¡œ shellì—ì„œ aws commandë¥¼ ì³ë„ ê°€ëŠ¥í•˜ê²Œë” ì„¸íŒ…í•´ë†“ëŠ” ê²ƒì´ë‹¤.\n","description":"ë°ì´í„° ì—”ì§€ë‹ˆì–´ ê¸°ì´ˆ ë‹¤ì§€ê¸°","id":14,"section":"posts","tags":null,"title":"Unix \u0026 AWS","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part2_1/"},{"content":"1. Drawing MVN plots with ggplot2 1 2  mu = matrix(c(0,10), ncol=1) invSig = solve(matrix(c(4,10,10,100), ncol=2, byrow=TRUE))   1-1. Vectorize + Outer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  dmvlnorm = function(theta, mu, invSig){ (-nrow(mu)/2) * log(2*pi) + 0.5*log(det(invSig)) - 0.5*(t(theta-mu) %*% invSig %*% (theta-mu)) } calc.dens = Vectorize(function(a,b){ theta = c(a,b) exp(dmvlnorm(theta, mu, invSig)) }) A = seq(-5, 5, length=100) B = seq(-15, 40, length=100) dense = outer(A, B, FUN=calc.dens) rownames(dense) = A colnames(dense) = B dens = reshape2::melt(dense) colnames(dens) = c(\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;dens\u0026#39;) ggplot(data=dens, aes(x=a, y=b)) + geom_raster(aes(fill=dens, alpha=dens), interpolate=TRUE) + geom_contour(aes(z=dens), color=\u0026#39;black\u0026#39;, size=0.2) + scale_fill_gradient(low=\u0026#39;cornflowerblue\u0026#39;, high=\u0026#39;steelblue\u0026#39;, guide=FALSE) + scale_alpha(range=c(0,1), guide=FALSE) + labs(title=\u0026#39;MVN density\u0026#39;, x=\u0026#39;alpha\u0026#39;, y=\u0026#39;beta\u0026#39;)   2. Gibbs sampling for MVN draws 1 2 3  Y = dget(\u0026#39;https://www2.stat.duke.edu/~pdh10/FCBS/Inline/Y.reading\u0026#39;) ggplot(data.frame(Y)) + geom_point(aes(x=pretest, y=posttest))   Prior specification 1 2 3 4  Mu0 \u0026lt;- c(50,50) Lambda0 = matrix(c(625,312.5,312.5,625), ncol=2) nu0 = 4 S0 = (nu0-nrow(Lambda0)-1) * Lambda0   Gibbs Sampler 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  inv = solve n = nrow(Y) ybar = colMeans(Y) Sigma = cov(Y) #initials S = 5000 MU = matrix(NA, nrow=S, ncol=2) SIGMA = matrix(NA, nrow=S, ncol=4) for(s in 1:S){ # update Mu Lambdan = inv(inv(Lambda0) + n*inv(Sigma)) Mun = Lambdan %*% (inv(Lambda0) %*% Mu0 + n*inv(Sigma) %*% ybar) Mu = MASS::mvrnorm(n=1, Mun, Lambdan) # update Sigma Sn = S0 + (t(Y)-c(Mu)) %*% t((t(Y)-c(Mu))) Sigma = inv(rWishart(1, nu0+n, inv(Sn))[,,1]) MU[s,] = Mu SIGMA[s,] = c(Sigma) } disp = tail(1:S, S/2) p1 \u0026lt;- data.frame(mu1=MU[disp,1], mu2=MU[disp,2]) %\u0026gt;% ggplot(aes(x=mu1, y=mu2)) + geom_point(size=0.5, color=\u0026#39;steelblue\u0026#39;) + geom_abline(slope=1, intercept=0) + coord_fixed(ratio=1) + ggtitle(\u0026#39;Posterior darws of MU\u0026#39;) meandiff = MU[disp,2] - MU[disp,1] p2 \u0026lt;- data.frame(meandiff=meandiff) %\u0026gt;% ggplot(aes(x=meandiff)) + geom_histogram(color=\u0026#39;white\u0026#39;, fill=\u0026#39;steelblue\u0026#39;, bins=30) + geom_vline(xintercept=0) + ggtitle(\u0026#39;Posterior draws of Mu2 - Mu1\u0026#39;) grid.arrange(p1, p2, ncol=2)   3. Gibbs Sampling for NA imputation 1 2  Y = dget(\u0026#39;https://www2.stat.duke.edu/~pdh10/FCBS/Inline/Y.pima.miss\u0026#39;) head(Y)   ## glu bp skin bmi\r## 1 86 68 28 30.2\r## 2 195 70 33 NA\r## 3 77 82 NA 35.8\r## 4 NA 76 43 47.9\r## 5 107 60 NA NA\r## 6 97 76 27 NA\r1  psych::pairs.panels(Y, method=\u0026#39;pearson\u0026#39;, density=T, breaks=20, hist.col=\u0026#39;steelblue\u0026#39;)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  # priors n = nrow(Y) p = ncol(Y) Mu0 = c(120,64,26,26) sd0 = Mu0/2 L0 = matrix(0.1, p, p) diag(L0) = 1 L0 = L0*outer(sd0,sd0) nu0 = p+2 S0 = (nu0-p-1)*L0 Sigma = S0 Y.full = Y O = 1*(!is.na(Y)) for(j in 1:p){ Y.full[is.na(Y.full)[,j], j] = mean(Y.full[,j], na.rm=TRUE) #mean imputation } inv = solve S = 100 for(s in 1:S){ # update Mu ybar = colMeans(Y.full) Ln = inv(inv(L0) + n*inv(Sigma)) Mun = Ln %*% (inv(L0) %*% Mu0 + n*inv(Sigma) %*% ybar) Mu = MASS::mvrnorm(n=1, Mun, Ln) # update Sigma Sn = S0 + (t(Y.full) - c(Mu)) %*% t((t(Y.full) - c(Mu))) Sigma = inv(rWishart(1, nu0+n, inv(Sn))[,,1]) # update missing data for(i in 1:n){ #iterate over rows b = (O[i,] == 0) #missing at each row a = (O[i,] == 1) #observed at each row if(sum(b)==0) next iSa = inv(Sigma[a,a]) beta.j = Sigma[b,a] %*% iSa Sigma.j = Sigma[b,b] - Sigma[b,a] %*% iSa %*% Sigma[a,b] Mu.j = Mu[b] + beta.j %*% (t(Y.full[i,a]) - Mu[a]) Y.full[i,b] = MASS::mvrnorm(1, Mu.j, Sigma.j) } if(s%% 10 == 1) cat(s, \u0026#39;\\t\u0026#39;) }   ## 1 11 21 31 41 51 61 71 81 91 1  colSums(is.na(Y))   ## glu bp skin bmi ## 15 23 25 22\r1  colSums(is.na(Y.full))   ## glu bp skin bmi ## 0 0 0 0\r","description":"ë‹¤ë³€ëŸ‰ ì •ê·œë¶„í¬","id":15,"section":"posts","tags":null,"title":"MVN","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/mvn/"},{"content":"Vector Space  ë§ì…ˆì— ë‹«í˜€ìˆë‹¤. ìŠ¤ì¹¼ë¼ë°°ì— ë‹«í˜€ìˆë‹¤.  Subspace ë²¡í„°ê³µê°„ $V_n$ ì˜ ë¶€ë¶„ ì§‘í•© $W_n$ì´ ë²¡í„°ê³µê°„ì´ë©´, $W_n$ì„ $V_n$ì˜ ë¶€ë¶„ê³µê°„ì´ë¼ê³  í•œë‹¤. ì¦‰, $W_n$ì´ ë¶€ë¶„ê³µê°„ì´ë ¤ë©´, ë§ì…ˆê³¼ ìŠ¤ì¹¼ë¼ë°°ì— ë‹«í˜€ìˆìœ¼ë©´ ëœë‹¤.\nGauss-Jordan Elimination  í™•ì¥í–‰ë ¬ì„ ê¸°ì•½í–‰ì‚¬ë‹¤ë¦¬ê¼´(RREF, reduced row echelon form)ë¡œ ë°”ê¾¸ëŠ” ì•Œê³ ë¦¬ì¦˜ ê°€ìš°ìŠ¤ì¡°ë˜ ì†Œê±°ë²• = ê°€ê°ë²• + ëŒ€ì…ë²•  ì„ í˜•ì‚¬ìƒì˜ íŠ¹ì§•  ê°€ì‚°ì„± $f(x+y) = f(x) + f(y)$ ë™ì°¨ì„± $f(ax) = af(x)$  LU Decomposition $E_{k}...E_{2}E_{1}A = U$\n=\u0026gt; $A = E_{1}^{-1}E_{2}^{-1}...E_{k}^{-1}U = LU$  ì—¬ê¸°ì„œ $E_{k}...E_{2}E_{1}$ëŠ” í•˜ì‚¼ê°í–‰ë ¬ì´ë©°, $E_{1}^{-1}E_{2}^{-1}...E_{k}^{-1}$ë„ í•˜ì‚¼ê°í–‰ë ¬ì´ë‹¤.\n  ê·¼ê±°(1) ê°€ìš°ìŠ¤ ì†Œê±°ë²•ì„ ì‹œí–‰í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ëª¨ë“  ê¸°ë³¸í–‰ë ¬ì€ í•­ìƒ í•˜ì‚¼ê°í–‰ë ¬ì´ë‹¤. (ë‹¨, í–‰êµí™˜ ì œì™¸) ê·¼ê±°(2) í•˜ì‚¼ê°í–‰ë ¬ì¸ ê¸°ë³¸í–‰ë ¬ì˜ ì—­í–‰ë ¬ì€ ì—¬ì „íˆ í•˜ì‚¼ê°í–‰ë ¬ì´ë‹¤. ê·¼ê±°(3) í•˜ì‚¼ê°í–‰ë ¬ $\\times$ í•˜ì‚¼ê°í–‰ë ¬ = í•˜ì‚¼ê°í–‰ë ¬ PLU Decomposition í–‰êµí™˜ì´ í•„ìš”í•œ ê²½ìš°, í–‰êµí™˜ì„ ë¯¸ë¦¬ í•´ì£¼ê³  LU ë¶„í•´í•˜ëŠ” ë²• (P: permutation)\nìš©ì–´ ì •ë¦¬  consistent: í•´ê°€ ì ì–´ë„ í•œ ê°œëŠ” ìˆëŠ” ê²½ìš° homogeneous: ë™ì°¨ (ex. $A\\vec{x} = \\vec{0}$: ë™ì°¨ ì—°ë¦½ì„ í˜•ë°©ì •ì‹)  ","description":"Intro","id":16,"section":"posts","tags":null,"title":"Lecture 01","uri":"https://jiwooblog.netlify.app/posts/statistics/linearalgebra/l01/"},{"content":"Chapter 01. Introduction and Examples ë³¸ í¬ìŠ¤íŒ…ì€ First Course in Bayesian Statistical Methodsë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.\nì´ë²ˆ ì¥ì„ í†µí•´ì„œëŠ” Likelihood and Priorë¥¼ ì‚´í´ë³´ê³  Full probability modelì˜ ì˜ë¯¸ë¥¼ ë³´ëŠ” ë°ì— ì£¼ëª©í•´ë³´ìŸˆ.\në² ì´ì§€ì•ˆ ì¶”ë¡ ì˜ ëª©ì  ìš°ë¦¬ëŠ” ë°ì´í„° íšë“ì„ í†µí•´, ëª¨ì§‘ë‹¨ íŠ¹ì„±ì— ëŒ€í•œ ë¶ˆí™•ì‹¤ì„±ì„ ì¤„ì—¬ë‚˜ê°€ê³ ì í•œë‹¤. ì´ë•Œ, ë¶ˆí™•ì‹¤ì„± ì •ë„ì˜ ë³€í™” ìˆ˜ì¤€ì„ ê³„ëŸ‰í™”í•˜ëŠ” ê²ƒì´ ë² ì´ì§€ì•ˆ ì¶”ë¡ í†µê³„ì˜ ëª©ì ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.\ní•µì‹¬ ê°œë…  prior distribution $p(\\theta)$  ì‚¬ì „í™•ë¥  ëª¨ìˆ˜ì— ëŒ€í•´ ê¸°ì¡´ì— ê°–ê³  ìˆë˜ ë¯¿ìŒì˜ ì •ë„   sampling model $p(y|\\theta)$  ì¼ì¢…ì˜ ê°€ëŠ¥ë„ í•¨ìˆ˜(likelihood) ì‚¬ì „í™•ë¥ ì´ ì°¸ì´ë¼ëŠ” ê°€ì • í•˜ì—, íŠ¹ì • ë°ì´í„°ê°€ ê´€ì°°ëœ í™•ë¥    posterior distribution $p(\\theta|y)$  ë°ì´í„°ê°€ ê´€ì°°ë˜ì—ˆì„ ë•Œ, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìˆ˜ì •ëœ ëª¨ìˆ˜ì— ëŒ€í•œ ë¯¿ìŒì˜ ì •ë„    Bayes' Rule $$p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{\\int_{\\Theta}p(y|\\tilde{\\theta})p(\\tilde{\\theta})d\\tilde{\\theta}}$$\nì´ëŠ” ì‚¬í›„ë¶„í¬ê°€ ì‚¬ì „ë¶„í¬ì™€ ê°€ëŠ¥ë„ í•¨ìˆ˜ì— ì˜í•´ ì–´ë–»ê²Œ ì—…ë°ì´íŠ¸ ë˜ëŠ”ì§€ë¥¼ ìˆ˜ì‹ì ìœ¼ë¡œ ë‚˜íƒ€ë‚œ ê²ƒì´ë‹¤.\në² ì´ì¦ˆ í†µê³„ì˜ ì „ë¶€ë¼ê³  í•´ë„ ë¬´ë°©í•˜ë‹¤.\ní™œìš©ì˜ˆì‹œ  í¬ì†Œì‚¬ê±´ í™•ë¥  ì¶”ì •(Estimation)  ê°ì—¼ í™•ë¥ (infectious probability) í™•ë¥ ë¡ ì(frequentist)ëŠ” sampleì´ ì ì„ ë•Œ í™•ë¥ ì¶”ì •ì„ í•©ë¦¬ì ìœ¼ë¡œ í•˜ëŠ” ë°ì— ìˆì–´ì„œ ì·¨ì•½í•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 20ëª…ë§Œì„ ëŒ€ìƒìœ¼ë¡œ ê°ì—¼ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  ê°ì—¼ í™•ë¥ ì„ ì¶”ë¡ í•œë‹¤ë©´, ê°ì—¼í™•ë¥ ì„ 0%ë¼ê³  ì œì•ˆí•˜ëŠ” ê²ƒì€ í†µê³„ì ìœ¼ë¡œëŠ” ê·¸ëŸ´ ë“¯í•˜ê²Œ ê³„ì‚°ë  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ì´ëŠ” í˜„ì‹¤ê³¼ëŠ” ë‹¤ì†Œ ê±°ë¦¬ê°€ ìˆì„ ìˆ˜ ìˆë‹¤. ì´ì— ë°˜í•´, ë² ì´ì§€ì•ˆì€ ê°ì—¼ í™•ë¥ ì„ ë¶„í¬ë¡œì„œ ì œì‹œí•  ë¿ë”ëŸ¬ ê¸°ì¡´ì˜ ë¯¿ìŒì„ ì‚¬ì „í™•ë¥ ë¡œì„œ ì œì•ˆí•˜ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ë¶€ë¶„ì— ìˆì–´ì„œ ëœ ì·¨ì•½í•  ìˆ˜ ìˆë‹¤.   ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•(Prediction)  ë‹¹ë‡¨ë³‘(diabetes progression) 50% í™•ë¥ ë¡œ ë³€ìˆ˜ì˜ coefficientê°€ 0ë¼ê³  ì‚¬ì „í™•ë¥ ì„ ì œì•ˆí•œë‹¤ë©´, ë³€ìˆ˜ì„ íƒì˜ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ì´ì™€ ê´€ë ¨ëœ ìì„¸í•œ ë‚´ìš©ì€ FCB chapter 09ì„œ Bayesian Linear Regressionê³¼ ê´€ë ¨í•˜ì—¬ ì„¤ëª…ë  ì˜ˆì •ì´ë‹¤.    ETC  \u0026lsquo;Adjusted\u0026rsquo; Wald interval\ní”íˆ ì•Œë ¤ì§„ ì‹ ë¢°êµ¬ê°„ì„ ë² ì´ì§€ì•ˆì ìœ¼ë¡œ ë°”ê¾¼ í˜•íƒœì´ë‹¤.  `\\hat{\\theta} \\pm 1.96\\sqrt{\\hat{\\theta}(1-\\hat{\\theta})//n}` , where `\\hat{\\theta} = \\frac{n}{n+4}\\bar{y} + \\frac{4}{n+4}\\frac{1}{2}`\n Lasso\në³€ìˆ˜ ì„ íƒì˜ í•œ ë°©ë²•ì´ë‹¤. ì•„ë˜ ì œì‹œëœ SSRë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.\në² ì´ì§€ì•ˆì˜ ë§¥ë½ì—ì„œ ì²˜ìŒ ì—°êµ¬ëœ ë°©ë²•ë¡ ì€ ì•„ë‹ˆì§€ë§Œ, íŠ¹ì • ì‚¬ì „í™•ë¥ ì„ ì ìš©í•œë‹¤ë©´ ë² ì´ì§€ì•ˆì˜ ê´€ì ê³¼ ì¼ì¹˜í•œë‹¤.\nì—¬ê¸°ì„œ ë§í•˜ëŠ” ê·¸ íŠ¹ì • ì‚¬ì „í™•ë¥ ë¶„í¬ë€, $\\beta_j$ê°€ 0ì—ì„œ ì²¨ì ì„ ê°–ëŠ” ë¼í”Œë¼ìŠ¤ ë¶„í¬(ë˜ëŠ” double-exponential distribution)ë¥¼ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.\nê·¸ë¦¬ê³  ì´ë•Œ lasso estimateì€ $\\beta$ì˜ ì‚¬í›„ ìµœë¹ˆê°’(posterior mode)ê³¼ ê°™ë‹¤.\n$$SSR(\\beta:\\lambda) = \\sum_{i=1}^{n}(y_i-\\boldsymbol{x_i}^T\\boldsymbol{\\beta})^2 + \\lambda\\sum_{j=1}^{n}|\\beta_j|$$  Conclusion \"All models are wrong, but some are useful\" - Box and Draper, 1987 í˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"Introduction and Examples","id":17,"section":"posts","tags":null,"title":"What is Bayesian","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/fcb01/"},{"content":"ì‹¬ë¦¬í•™ ìˆ˜ê°• ê³¼ëª©  ì‹¬ë¦¬í•™ê°œë¡  ì¶©ë™ê³¼ìê¸°ê´€ë¦¬ ì‹¬ë¦¬í•™ì˜ ì‹¤í—˜ì—°êµ¬ë°©ë²• ë°œë‹¬ì‹¬ë¦¬í•™ í–‰ë³µì˜ ê³¼í•™ ì–¸ì–´ì‹¬ë¦¬í•™ ì´ë¡  ë° ì‹¤ìŠµ ì¸ì§€ì‹ ê²½ê³¼í•™ì˜ ê¸°ì´ˆ ì‹¬ë¦¬í†µê³„ í•™ìŠµê³¼ ê¸°ì–µì˜ ì‹¬ë¦¬í•™ UTì„¸ë¯¸ë‚˜(ì‹¤íŒ¨ì™€ ì¢Œì ˆì˜ ì‹¬ë¦¬í•™) ì„±ê²©ì‹¬ë¦¬í•™ ì¬ëŠ¥ê³¼ ê¸°ìˆ ì˜ ì‹¬ë¦¬í•™ ì¸ì§€ê³µí•™ì‹¬ë¦¬í•™ ì‚°ì—…ì‹¬ë¦¬í•™  ","description":"","id":18,"section":"posts","tags":null,"title":"ìˆ˜ê°•ê³¼ëª©","uri":"https://jiwooblog.netlify.app/posts/yonsei/psychology/lecture/"},{"content":"í†µê³„í•™ ìˆ˜ê°• ê³¼ëª©  í†µê³„í•™ì…ë¬¸ ë¯¸ë¶„ì ë¶„í•™ í†µê³„ë°©ë²•ë¡  ì„ í˜•ëŒ€ìˆ˜ ì»´í“¨í„°ìë£Œì²˜ë¦¬ ì‹¬ë¦¬í†µê³„ ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ë¥¼ ìœ„í•œ í™•ë¥ ê³¼ì • íšŒê·€ë¶„ì„ ìˆ˜ë¦¬í†µê³„í•™(1) ë² ì´ì¦ˆí†µê³„ ìˆ˜ë¦¬í†µê³„í•™ (2) ì‹œê³„ì—´ë¶„ì„ ê¸ˆìœµë¦¬ìŠ¤í¬ê´€ë¦¬ ì‹¤ë¬´ì™€ í†µê³„í•™ UTì„¸ë¯¸ë‚˜(ìƒë¬¼í†µê³„í•™) ë²”ì£¼í˜•ìë£Œë¶„ì„ ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ì…ë¬¸ ë°ì´í„°ë§ˆì´ë‹ ì´ë¡ í†µê³„í•™(1) ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤(2): ë„¤íŠ¸ì›Œí¬ ìë£Œë¶„ì„  ","description":"","id":19,"section":"posts","tags":null,"title":"ìˆ˜ê°•ê³¼ëª©","uri":"https://jiwooblog.netlify.app/posts/yonsei/statistics/lecture/"},{"content":"NHíˆ¬ìì¦ê¶Œ Y\u0026amp;Zì„¸ëŒ€ íˆ¬ìì í”„ë¡œíŒŒì¼ë§ ë³¸ ëŒ€íšŒëŠ” NHíˆ¬ìì¦ê¶Œì—ì„œ ì£¼ìµœí•œ ëŒ€íšŒë¡œ, 2020ë…„ ê¸‰ê²©í•˜ê²Œ ëŠ˜ì–´ë‚œ 20~30ëŒ€ íˆ¬ììë“¤ì— ëŒ€í•œ ë¶„ì„ì„ í•˜ê³  ì´ë¥¼ ì‹œê°í™”í•˜ëŠ” ê²ƒì´ ì£¼ëª©ì ì´ì—ˆë‹¤.\nì½”ë“œê°€ ìƒë‹¹íˆ ë³µì¡í•œ ê´€ê³„ë¡œ Daconì— ì½”ë“œê³µìœ í•œ ë§í¬ì™€ ì´ë¯¸ì§€ ì¼ë¶€ë¥¼ ì˜¬ë¦¬ëŠ” ê²ƒìœ¼ë¡œ í¬ìŠ¤íŒ…ì„ ëŒ€ì²´í•˜ê³ ì í•œë‹¤.\nDacon ì½”ë“œ ê³µìœ  Factor Analysis Word Cloud_êµ­ë‚´ Word Cloud_í•´ì™¸ Cluster Polygon Cluster Characteristics Idea Table Idea Sample Domain Knowledge 1. í•´ì™¸ì£¼ì‹ ì†Œìˆ˜ì  ê±°ë˜  í˜„ì¬ ì‹ í•œê¸ˆìœµíˆ¬ì, í•œêµ­íˆ¬ìì¦ê¶Œì—ì„œ ì‹¤í˜„ ì¤‘ ì˜ê²°ê¶Œ, ë°°ë‹¹ê¶Œì„ ë¹¼ê³  ì†Œìˆ˜ì  ê±°ë˜ ê°€ëŠ¥! (ex. í•œíˆ¬ ë¯¸ë‹ˆìŠ¤í†¡)  2. íœ´ë©´ ê³ ê°ì— ëŒ€í•œ ì´ë²¤íŠ¸ë„ ì£¼ê¸°ì ìœ¼ë¡œ í•œë‹¤. 3. ETP (= ETF + ETN) ê¸ˆìœµíˆ¬ìí˜‘íšŒ: í•œëˆˆì— ì•Œì•„ë³´ëŠ” ë ˆë²„ë¦¬ì§€ ETP Guide\n  ê´´ë¦¬ìœ¨\n ìˆœìì‚°ê°€ì¹˜(NAV) \u0026amp; ì§€í‘œê°€ì¹˜(IV)ì€ ì¥ì¤‘ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚°ì¶œí•œë‹¤.  ì „ì¼ ì¢…ê°€ë¡œ í™•ì •ëœ ìˆœìì‚° ê°€ì¹˜ + ë‹¹ì¼ì˜ ê°€ê²© ì›€ì§ì„   ê´´ë¦¬ìœ¨ì´ í”ŒëŸ¬ìŠ¤(+): ì¶”ì ëŒ€ìƒ ì§€ìˆ˜ë³´ë‹¤ ê³ í‰ê°€ë˜ì–´ ìˆë‹¤(=ë¹„ì‹¸ê²Œ ê±°ë˜ë˜ê³  ìˆë‹¤). ê´´ë¦¬ìœ¨ì´ ë§ˆì´ë„ˆìŠ¤(-): ì¶”ì ëŒ€ìƒ ì§€ìˆ˜ë³´ë‹¤ ì €í‰ê°€ë˜ì–´ ìˆë‹¤(=ì‹¸ê²Œ ê±°ë˜ë˜ê³  ìˆë‹¤.) ê´´ë¦¬ìœ¨ì´ ë„ˆë¬´ ì»¤ì§€ë©´, í•œêµ­ê±°ë˜ì†Œì—ì„œ ë‹¨ì¼ê°€ ë§¤ë§¤ ë˜ëŠ” ë§¤ë§¤ê±°ë˜ì •ì§€ë¥¼ ì‹œí‚¬ ìˆ˜ ìˆë‹¤. ìœ ë™ì„±ê³µê¸‰ì(Liquidity Provider, LP)  ê´´ë¦¬ìœ¨ì´ ê³¼ë„í•˜ê²Œ ë†’ì„ ê²½ìš°: ETPë¥¼ ë§¤ë„í•˜ê±°ë‚˜ ëŒ€ìƒìì‚°ì„ ë§¤ì…í•´ì•¼ê² ë‹¤! ê´´ë¦¬ìœ¨ì´ ê³¼ë„í•˜ê²Œ ë‚®ì„ ê²½ìš°: ETPë¥¼ ë§¤ìˆ˜í•˜ê±°ë‚˜ ëŒ€ìƒìì‚°ì„ ë§¤ë„í•´ì•¼ê² ë‹¤!      ë³µë¦¬ íš¨ê³¼\n ë ˆë²„ë¦¬ì§€ ETPì˜ ìš´ìš©ë°©ì‹: \u0026lsquo;ì¼ë³„\u0026rsquo; ìˆ˜ìµë¥ ì˜ Â±2ë°° ìƒìŠ¹ì¥ì¼ ê²½ìš°, 2Xì˜ ìƒìŠ¹ë¥  \u0026gt; ì¸ë²„ìŠ¤2X í•˜ë½ë¥  í•˜ë½ì¥ì¼ ê²½ìš°, 2Xì˜ í•˜ë½ë¥  \u0026lt; ì¸ë²„ìŠ¤2X ìƒìŠ¹ë¥  íš¡ë³´ì¥ì¼ ê²½ìš°, 2Xì™€ ì¸ë²„ìŠ¤2X ëª¨ë‘ ì†í•´ë³¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. ì¦‰, ì¥ê¸°íˆ¬ìì— ì í•©í•˜ì§€ ì•Šë‹¤. ìƒì‹: ë ˆë²„ë¦¬ì§€ ìƒí’ˆì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” íŒŒìƒìƒí’ˆì„ ì§‘ì–´ë„£ëŠ”ë‹¤.    ë¡¤ì˜¤ë²„(roll-over)\n íŒŒìƒìƒí’ˆì˜ ê±°ë˜ì›”ë¬¼ì„ êµì²´í•˜ëŠ” ê²ƒ(íŒŒìƒìƒí’ˆì˜ ë§Œê¸°ì— ë°œìƒ) ì¦‰, ë¡¤ì˜¤ë²„ ê³¼ì •ì—ì„œ ê±°ë˜ì›”ë¬¼ì˜ ê°€ê²¨ì°¨ì´ì— ë”°ë¼ ETPì˜ ìì‚°ê°€ì¹˜ ë³€ë™ì´ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆë‹¤. ì„ ë¬¼ \u0026lsquo;ë§¤ìˆ˜\u0026rsquo;í¬ì§€ì…˜ì„ ë³´ìœ í•˜ê³  ìˆëŠ” ë ˆë²„ë¦¬ì§€(2X) ETP  ê±°ë˜ì›”ë¬¼ì˜ ê°€ê²©ì°¨ì´ê°€ (+)ìƒíƒœì´ë©´ ì´ë“, (-)ìƒíƒœì´ë©´ ì†í•´   ì„ ë¬¼ \u0026lsquo;ë§¤ë„\u0026rsquo;í¬ì§€ì…˜ì„ ë³´ìœ í•˜ê³  ìˆëŠ” ë ˆë²„ë¦¬ì§€(2X) ETP  ê±°ë˜ì›”ë¬¼ì˜ ê°€ê²©ì°¨ì´ê°€ (+)ìƒíƒœì´ë©´ ì†í•´, (-)ìƒíƒœì´ë©´ ì´ë“      ì§€ìˆ˜ì˜ ë°©ë²•ë¡ \n ê´´ë¦¬ìœ¨, ë³µë¦¬íš¨ê³¼, ë¡¤ì˜¤ë²„ë§Œí¼ì˜ ì¤‘ìš”ì„±ì€ ì•„ë‹ˆì§€ë§Œ, ê°„ê³¼í•´ì„œëŠ” ì•ˆë˜ëŠ” POINT ex) 2020ë…„ 4ì›” ìœ ë¡€ ì—†ëŠ” ë§ˆì´ë„ˆìŠ¤ ìœ ê°€ í­ë½ìœ¼ë¡œ ì¸í•œ ì›ìœ ì„ ë¬¼ì˜ ê±°ë˜ì›”ë¬¼ í¸ì…ëŒ€ìƒê³¼ ë¡¤ì˜¤ë²„ ë°©ì‹ ë³€í™”    ë°°ìš´ ì  1. í¬ë¡¤ë§ ëŠ¥ë ¥  í¬ë¡¤ë§ì€ Pythonì„ í†µí•´ì„œ ì§„í–‰í•˜ì˜€ë‹¤. BeautifulSoup, seleniumì˜ webdriver ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì˜€ë‹¤. (1) í•´ì™¸ì‚¬ì´íŠ¸ í¬ë¡¤ë§ì˜ ì–´ë ¤ì›€  ëŠë¦¬ê³ , ìì˜í•œ ì˜¤ë¥˜ê°€ ìƒê¸´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ë‹¨ì–´ë¥¼ ê²€ìƒ‰ì„ í•´ë„ ë‚˜ì˜¤ì§€ ì•ŠëŠ”ë‹¤.   (2) í¬ë¡¤ë§ ê¶Œí•œ ì ‘ê·¼  ì ‘ê·¼ ê¶Œí•œì˜ ì œí•œìœ¼ë¡œ ë‹¨ìˆœ í¬ë¡¤ë§ì„ í•  ìˆ˜ ì—†ëŠ” ê²½ìš°\nNetwork-XHRì˜ Request Headers í™œìš©í•˜ê¸° ì—ëŸ¬ í•¸ë“¤ë§ ê´€ì ì—ì„œ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì˜ ì¤‘ìš”ì„± ì²´ê°    2. íŒŒìƒë³€ìˆ˜ ì œì‘ì˜ ì–´ë ¤ì›€  run_away_cd(íœ´ë©´ ì—¬ë¶€) ë¼ëŠ” ë³€ìˆ˜ë¥¼ ìƒˆë¡­ê²Œ ë§Œë“¤ì—ˆë‹¤. ì´ ì„¸ê°€ì§€ ê¸°ì¤€ì— ì˜í•´ ê° ê³ ê°ì˜ íœ´ë©´ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì˜€ëŠ”ë°, ê·¸ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.  (1) ê±°ë˜ì£¼ê¸°ì— ë¹„í•´ ê±°ë˜íœ´ì‹ê¸°ê°€ ì§€ë‚˜ì¹˜ê²Œ ê¸´ ê²½ìš° (2) ì˜ˆìƒ ê±°ë˜íšŸìˆ˜ì— ë¹„í•´ ì‹¤ì œ ê±°ë˜íšŸìˆ˜ê°€ ëˆˆì— ë„ê²Œ ì ì€ ê²½ìš° (3) ìµœê·¼ 2ë‹¬ ì´ë‚´ì— ê³„ì¢Œê°œì„¤í•œ ì‚¬ëŒë“¤ì€ ì œì™¸   í•´ë‹¹ ë³€ìˆ˜ë¥¼ ë§Œë“¤ê³  ìœ ì˜ì„±ì„ ê²€í† í•˜ëŠ” ë°ì— ì ì§€ ì•Šì€ ì‹œê°„ì„ íˆ¬ìí•˜ì˜€ë˜ ê²½í—˜ğŸ‘ í•´ë‹¹ ë³€ìˆ˜ë¥¼ ë§Œë“¤ê¸° ìœ„í•´, ì¤‘ê°„ê³¼ì •ì—ì„œ orr_prd, orr_cyl, orr_idx_1, orr_idx2ë¥¼ ë§Œë“¤ì—ˆë‹¤.  3. ìš”ì¸ë¶„ì„ Factor ì¡°í•© ë…¸í•˜ìš°  ì–´ë ¤ìš´ ë³€ìˆ˜ë³´ë‹¤ëŠ” ì§ê´€ì ìœ¼ë¡œ ê°„ë‹¨í•œ ë³€ìˆ˜ë“¤ì˜ ì¡°í•©ìœ¼ë¡œ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.. ì™œëƒí•˜ë©´ ìš”ì¸ë¶„ì„ ìì²´ê°€ í•´ì„ì„ ëª©ì ìœ¼ë¡œ í•˜ê¸° ë•Œë¬¸ì´ë‹¤.  ","description":"","id":20,"section":"posts","tags":null,"title":"YZ íˆ¬ìì í”„ë¡œíŒŒì¼ë§","uri":"https://jiwooblog.netlify.app/posts/dacon/nh_yz/"},{"content":"lubridate íŒ¨í‚¤ì§€ í›‘ì–´ë³´ê¸° lubridateëŠ” ë‚ ì§œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\n1  library(lubridate)    ëª©ì°¨  parse datetimes  1. parse datetimes   ë‹¤ì–‘í•œ í˜•íƒœ #1  1 2 3 4 5 6 7 8 9 10 11  # ë‹¤ì–‘í•œ í˜•íƒœê°€ ìˆë‹¤. # ymd_hms(), ymd_hm(), ymd_h() # ydm_hms(), ydm_hm(), ydm_h() # mdy_hms(), mdy_hm(), mdy_h() # dmy_hms(), dmy_hm(), dmy_h() # ymd(), ydm() # mdy(), myd() # dmy(), dym() # yq() Q for quarter ymd_hms(\u0026#34;2017-11-28T14:02:00\u0026#34;)   ## [1] \u0026quot;2017-11-28 14:02:00 UTC\u0026quot;\r1  ydm_hms(\u0026#34;2017-22-12 10:00:00\u0026#34;)   ## [1] \u0026quot;2017-12-22 10:00:00 UTC\u0026quot;\r1  mdy_hms(\u0026#34;11/28/2017 1:02:03\u0026#34;)   ## [1] \u0026quot;2017-11-28 01:02:03 UTC\u0026quot;\r1  dmy_hms(\u0026#34;1 Jan 2017 23:59:59\u0026#34;)   ## [1] \u0026quot;2017-01-01 23:59:59 UTC\u0026quot;\r1  ymd(20170131)   ## [1] \u0026quot;2017-01-31\u0026quot;\r1  mdy(\u0026#34;July 4th, 2000\u0026#34;)   ## [1] \u0026quot;2000-07-04\u0026quot;\r1  dmy(\u0026#34;4th of July \u0026#39;99\u0026#34;)   ## [1] \u0026quot;1999-07-04\u0026quot;\r1  yq(\u0026#34;2001: Q3\u0026#34;)   ## [1] \u0026quot;2001-07-01\u0026quot;\r     ë‹¤ì–‘í•œ í˜•íƒœ #2  1  today()   ## [1] \u0026quot;2021-03-23\u0026quot;\r1  now()   ## [1] \u0026quot;2021-03-23 11:24:45 KST\u0026quot;\r1  date_decimal(2021.5) #2021ë…„ 5ì›”ì´ ì•„ë‹ˆë¼, 2021ë…„ì˜ ì ˆë°˜   ## [1] \u0026quot;2021-07-02 12:00:00 UTC\u0026quot;\r1  fast_strptime(\u0026#39;9/1/01\u0026#39;, \u0026#39;%y/%m/%d\u0026#39;)   ## [1] \u0026quot;2009-01-01 UTC\u0026quot;\r1  parse_date_time(\u0026#34;9/1/01\u0026#34;, \u0026#34;ymd\u0026#34;) # fast_strptimeê³¼ ë‹¬ë¦¬, ì¡°ê¸ˆ ë” ë””í…Œì¼í•˜ê²Œ ì¨ì¤˜ì•¼í•œë‹¤.   ## Warning: All formats failed to parse. No formats found.\r## [1] NA\r1  parse_date_time(\u0026#34;2009/1/01\u0026#34;, \u0026#34;ymd\u0026#34;)   ## [1] \u0026quot;2009-01-01 UTC\u0026quot;\r   ","description":"","id":21,"section":"posts","tags":null,"title":"lubridate","uri":"https://jiwooblog.netlify.app/posts/r/lubridate/"},{"content":"Entropy ì •ë³´ëŸ‰ = ë¶ˆí™•ì‹¤ì„±\n$$H(p) = -\\sum_{i=1}p_i log(p_i) $$\nCross-Entropy pì— ëŒ€í•´, ì „ëµ Që¥¼ ì‚¬ìš©í–ˆì„ ë•Œì˜ ë¶ˆí™•ì‹¤ì„±\n$$H(p,q) = -\\sum_{i=1}p_i log(q_i) $$\nKL-Divergence $$\n\\begin{aligned}\nKL(p||q) \u0026amp;= \\sum_{i=1}p_i log\\frac{p_i}{q_i} \\\n\u0026amp;= H(p,q) - H(p)\n\\end{aligned}\n$$\n","description":"Entropy, Cross-Entropy, KL-Divergence","id":22,"section":"posts","tags":null,"title":"Entropy, KL-Divergence","uri":"https://jiwooblog.netlify.app/posts/machinelearning/entropy/"},{"content":"tidyr íŒ¨í‚¤ì§€ í›‘ì–´ë³´ê¸° tidyrì€ tidy dataë¥¼ í˜•ì„±í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤. tidy dataì—ì„œ 1) ì—´ì€ ë³€ìˆ˜ë¥¼ ì˜ë¯¸í•˜ê³ , 2) í–‰ì€ í•˜ë‚˜ì˜ ì¼€ì´ìŠ¤ë¥¼ ì˜ë¯¸í•˜ë©°, 3) í•˜ë‚˜ì˜ ì…€ì€ í•˜ë‚˜ì˜ ê°’ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n1  library(tidyverse)    ëª©ì°¨  nest  nest ì˜ˆì‹œë¥¼ í†µí•´, ë‹¨ìˆœíˆ group_byë¥¼ í•˜ëŠ” ê²ƒê³¼ group_by ì´í›„ nestë¥¼ í•œ í›„ì— ì–´ë–»ê²Œ ë°ì´í„°ê°€ ì •ë¦¬ë˜ëŠ”ì§€ í™•ì¸í•´ë³´ì.\n  nest ì˜ˆì‹œ  1 2  iris %\u0026gt;% group_by(Species)   ## # A tibble: 150 x 5\r## # Groups: Species [3]\r## Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # ... with 140 more rows\r1 2 3  iris %\u0026gt;% group_by(Species) %\u0026gt;% nest()   ## # A tibble: 3 x 2\r## # Groups: Species [3]\r## Species data ## \u0026lt;fct\u0026gt; \u0026lt;list\u0026gt; ## 1 setosa \u0026lt;tibble [50 x 4]\u0026gt;\r## 2 versicolor \u0026lt;tibble [50 x 4]\u0026gt;\r## 3 virginica \u0026lt;tibble [50 x 4]\u0026gt;\r  \nì°¸ê³  [1] https://gomguard.tistory.com/229\n","description":"","id":23,"section":"posts","tags":null,"title":"tidyr","uri":"https://jiwooblog.netlify.app/posts/r/tidyr/"},{"content":"2021.02.26  hugo theme ì¤‘ zzoì™€ zdocì€ ë‹¤ë¥¸ ê²ƒì´ë‹¤. zzo ì°¸ê³ ì‚¬ì´íŠ¸ zdoc ì°¸ê³ ì‚¬ì´íŠ¸  ","description":"","id":24,"section":"updates","tags":null,"title":"February 2021","uri":"https://jiwooblog.netlify.app/updates/diary/2021_02/"},{"content":"ëŒ€íšŒ ë¦¬ìŠ¤íŠ¸  ë¹…ì½˜í…ŒìŠ¤íŠ¸ ë°ì´ì½˜(Dacon) ì„œìš¸íŠ¹ë³„ì‹œ ë¹…ë°ì´í„° ìº í¼ìŠ¤ ê³µëª¨ì „ í•œêµ­ì •ë³´í™”ì§„í¥ì› ë°ì´í„° í¬ë¦¬ì—ì´í„° ìº í”„ ìƒê¶Œë¶„ì„ ë¹…ë°ì´í„° ê²½ì§„ëŒ€íšŒ KB êµ­ë¯¼ì€í–‰ Future Finance Ai Challenge ë¹…ë°ì´í„° í™œìš©ì •ì±… ì•„ì´ë””ì–´ ê³µëª¨ì „ Big Data Competition ë¯¸ë˜ì—ì…‹ëŒ€í•™ìƒë””ì§€í„¸ ê¸ˆìœµí˜ìŠ¤í‹°ë²Œ  ","description":"","id":25,"section":"updates","tags":null,"title":"ëŒ€íšŒ ë¦¬ìŠ¤íŠ¸","uri":"https://jiwooblog.netlify.app/updates/contest_list/"},{"content":"dplyr íŒ¨í‚¤ì§€ í›‘ì–´ë³´ê¸° 1 2  library(tidyverse) library(MASS)   ëª©ì°¨  rowwise\n1-1. pmax slice relocate lag, lead between, near coalsece recode first, last, nth rownames_to_column, column_to_rownames bind_rows, bind_cols mutate_all, mutate_if inner_join, left_join, right_join, full_join semi_join, anti_join  ë°ì´í„°   data  1 2 3 4  tmp \u0026lt;- tibble(x=round(rnorm(n=5, mean=5, sd=1)), y=round(rnorm(n=5, mean=5, sd=3)), z=round(rnorm(n=5, mean=5, sd=5))) tmp   ## # A tibble: 5 x 3\r## x y z\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 6 7 -1\r## 2 5 4 -2\r## 3 5 2 6\r## 4 6 2 12\r## 5 5 4 2\r1 2  data(survey) glimpse(survey)   ## Rows: 237\r## Columns: 12\r## $ Sex \u0026lt;fct\u0026gt; Female, Male, Male, Male, Male, Female, Male, Female, Male, ...\r## $ Wr.Hnd \u0026lt;dbl\u0026gt; 18.5, 19.5, 18.0, 18.8, 20.0, 18.0, 17.7, 17.0, 20.0, 18.5, ...\r## $ NW.Hnd \u0026lt;dbl\u0026gt; 18.0, 20.5, 13.3, 18.9, 20.0, 17.7, 17.7, 17.3, 19.5, 18.5, ...\r## $ W.Hnd \u0026lt;fct\u0026gt; Right, Left, Right, Right, Right, Right, Right, Right, Right...\r## $ Fold \u0026lt;fct\u0026gt; R on L, R on L, L on R, R on L, Neither, L on R, L on R, R o...\r## $ Pulse \u0026lt;int\u0026gt; 92, 104, 87, NA, 35, 64, 83, 74, 72, 90, 80, 68, NA, 66, 60,...\r## $ Clap \u0026lt;fct\u0026gt; Left, Left, Neither, Neither, Right, Right, Right, Right, Ri...\r## $ Exer \u0026lt;fct\u0026gt; Some, None, None, None, Some, Some, Freq, Freq, Some, Some, ...\r## $ Smoke \u0026lt;fct\u0026gt; Never, Regul, Occas, Never, Never, Never, Never, Never, Neve...\r## $ Height \u0026lt;dbl\u0026gt; 173.00, 177.80, NA, 160.00, 165.00, 172.72, 182.88, 157.00, ...\r## $ M.I \u0026lt;fct\u0026gt; Metric, Imperial, NA, Metric, Metric, Imperial, Imperial, Me...\r## $ Age \u0026lt;dbl\u0026gt; 18.250, 17.583, 16.917, 20.333, 23.667, 21.000, 18.833, 35.8...\r   1. rowwise() í–‰ë³„ë¡œ ìµœëŒ€ê°’ êµ¬í•˜ê¸°\n  rowwise ì˜ˆì‹œ  1 2 3 4  #ì˜¬ë°”ë¥¸ ë²„ì „ tmp %\u0026gt;% rowwise() %\u0026gt;% mutate(max = max(x,y,z))   ## # A tibble: 5 x 4\r## # Rowwise: ## x y z max\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 6 7 -1 7\r## 2 5 4 -2 5\r## 3 5 2 6 6\r## 4 6 2 12 12\r## 5 5 4 2 5\r1 2 3  #ì˜ëª»ëœ ë²„ì „ tmp %\u0026gt;% mutate(max = max(x,y,z))   ## # A tibble: 5 x 4\r## x y z max\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 6 7 -1 12\r## 2 5 4 -2 12\r## 3 5 2 6 12\r## 4 6 2 12 12\r## 5 5 4 2 12\r  \n1-1. pmax ê·¸ëŸ°ë° ì‚¬ì‹¤ì€ ì—¬ê¸°ì„œ rowwiseë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , pmaxë¥¼ ì‚¬ìš©í•˜ë©´ ë³´ë‹¤ ê°„ë‹¨í•˜ê²Œ êµ¬í•  ìˆ˜ ìˆê¸°ë„ í•˜ë‹¤.\n  pmax ì˜ˆì‹œ  1 2 3  #ê°„ë‹¨í•œ ë²„ì „ tmp %\u0026gt;% mutate(max = pmax(x,y,z))   ## # A tibble: 5 x 4\r## x y z max\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 6 7 -1 7\r## 2 5 4 -2 5\r## 3 5 2 6 6\r## 4 6 2 12 12\r## 5 5 4 2 5\r  \n2. slice() í–‰ ì„ íƒ\n  slice ì˜ˆì‹œ  1 2 3  # choose 10 rows with smallest 10 pulse values. survey %\u0026gt;% slice_min(Pulse, n = 10)   ## Sex Wr.Hnd NW.Hnd W.Hnd Fold Pulse Clap Exer Smoke Height M.I\r## 1 Male 20.0 20.0 Right Neither 35 Right Some Never 165.00 Metric\r## 2 Female 16.5 17.0 Right L on R 40 Left Freq Never 167.64 Imperial\r## 3 Female 18.0 17.5 Right R on L 48 Neither Freq Never 165.00 Metric\r## 4 Male 21.0 21.0 Right L on R 48 Neither Freq Never 174.00 Metric\r## 5 Female 18.0 17.9 Right R on L 50 Left None Never 165.00 Metric\r## 6 Female 15.5 15.5 Right Neither 50 Right Some Regul NA \u0026lt;NA\u0026gt;\r## 7 Male 18.0 19.0 Right L on R 54 Neither Some Regul NA \u0026lt;NA\u0026gt;\r## 8 Male 22.0 21.5 Left R on L 55 Left Freq Never 200.00 Metric\r## 9 Male 20.5 19.5 Right L on R 56 Right Freq Never 179.00 Metric\r## 10 Male 19.8 20.0 Left L on R 59 Right Freq Never 180.00 Metric\r## Age\r## 1 23.667\r## 2 17.417\r## 3 18.667\r## 4 21.333\r## 5 30.750\r## 6 18.500\r## 7 17.750\r## 8 18.500\r## 9 17.417\r## 10 17.417\r1 2 3  # choose 10 columns with greatest 10 pulses values. survey %\u0026gt;% slice_max(Pulse, n = 10)   ## Sex Wr.Hnd NW.Hnd W.Hnd Fold Pulse Clap Exer Smoke Height M.I\r## 1 Male 19.5 20.5 Left R on L 104 Left None Regul 177.8 Imperial\r## 2 Female 19.0 18.5 Left L on R 104 Left Freq Never 170.0 Metric\r## 3 Female 18.5 18.0 Left L on R 100 Neither Some Never 171.0 Metric\r## 4 Male 21.0 20.4 Right L on R 100 Right Freq Heavy 184.0 Metric\r## 5 Female 17.5 17.5 Right R on L 98 Left Freq Never NA \u0026lt;NA\u0026gt;\r## 6 Male 17.5 17.0 Left L on R 97 Neither None Never 165.0 Metric\r## 7 Male 22.5 23.0 Right R on L 96 Right None Never 170.0 Metric\r## 8 Male 21.4 21.0 Right L on R 96 Neither Some Never 180.0 Metric\r## 9 Female 17.5 17.8 Right R on L 96 Right Some Never NA \u0026lt;NA\u0026gt;\r## 10 Female 18.5 18.0 Right R on L 92 Left Some Never 173.0 Metric\r## 11 Female 18.0 17.7 Left R on L 92 Left Some Never NA \u0026lt;NA\u0026gt;\r## 12 Female 18.5 18.0 Right R on L 92 Right Freq Never 172.0 Metric\r## 13 Female 18.0 18.0 Right L on R 92 Neither Freq Never 165.0 Metric\r## 14 Female 16.3 16.2 Right L on R 92 Right Some Regul 152.4 Imperial\r## 15 Male 20.0 19.5 Right R on L 92 Right Some Never 179.1 Imperial\r## Age\r## 1 17.583\r## 2 17.250\r## 3 18.917\r## 4 20.083\r## 5 17.667\r## 6 19.500\r## 7 19.417\r## 8 19.000\r## 9 18.667\r## 10 18.250\r## 11 17.583\r## 12 17.500\r## 13 20.000\r## 14 23.500\r## 15 18.917\r1 2 3  # randomly select 10 rows. survey %\u0026gt;% slice_sample(n = 10)   ## Sex Wr.Hnd NW.Hnd W.Hnd Fold Pulse Clap Exer Smoke Height M.I\r## 1 Female 18.3 18.5 Right R on L 75 Left Freq Never 170.00 Metric\r## 2 Male 20.0 19.5 Right R on L 92 Right Some Never 179.10 Imperial\r## 3 Female 17.5 18.0 Right R on L 68 Neither Freq Never 157.48 Imperial\r## 4 Female 18.5 18.2 Right R on L 72 Neither Freq Never 167.64 Imperial\r## 5 Female 20.5 20.5 Right R on L NA Left Freq Regul NA \u0026lt;NA\u0026gt;\r## 6 Male 18.0 16.0 Right R on L NA Right Some Never 180.34 Imperial\r## 7 Female 17.7 17.0 Right R on L 76 Right Some Never 167.00 Metric\r## 8 Male 16.0 15.5 Right Neither 71 Right Freq Never 154.94 Imperial\r## 9 Male 18.5 18.5 Right L on R NA Neither Freq Never 171.00 Metric\r## 10 Male 20.5 19.5 Left L on R 80 Right Some Occas 182.88 Imperial\r## Age\r## 1 18.750\r## 2 18.917\r## 3 17.750\r## 4 17.333\r## 5 19.250\r## 6 20.750\r## 7 17.250\r## 8 17.167\r## 9 18.333\r## 10 18.667\r1 2 3  # randomly select 10% of the data observations. survey %\u0026gt;% slice_sample(prop = .05)   ## Sex Wr.Hnd NW.Hnd W.Hnd Fold Pulse Clap Exer Smoke Height M.I\r## 1 Female 17.0 17.0 Right L on R 79 Right Some Never 163.00 Metric\r## 2 Female 17.7 17.0 Right R on L 76 Right Some Never 167.00 Metric\r## 3 Female 16.7 15.1 Right Neither NA Right None Never 157.48 Imperial\r## 4 Male 19.5 20.5 Left R on L 104 Left None Regul 177.80 Imperial\r## 5 Male 19.5 20.2 Right R on L 60 Neither Freq Never 185.42 Imperial\r## 6 Female 13.0 13.0 \u0026lt;NA\u0026gt; L on R 70 Left Freq Never 180.34 Imperial\r## 7 Female 18.0 17.8 Right L on R 68 Right Some Never 168.90 Imperial\r## 8 Male 20.5 20.0 Right L on R 68 Right Freq Never 190.00 Metric\r## 9 Male 20.5 21.0 Right R on L 60 Right Freq Never 185.00 Metric\r## 10 Female 19.5 19.2 Right R on L 70 Right Some Never 170.00 Metric\r## 11 Female 16.2 16.4 Right R on L NA Right Freq Occas 172.00 Metric\r## Age\r## 1 24.667\r## 2 17.250\r## 3 18.167\r## 4 17.583\r## 5 32.667\r## 6 17.417\r## 7 17.083\r## 8 17.500\r## 9 17.917\r## 10 18.167\r## 11 17.000\r  \n3. relocate() relocate: changes the order of the columns.\n  relocate ì˜ˆì‹œ  1 2 3  # move columns with factor variables to the front survey %\u0026gt;% relocate(where(is.factor)) %\u0026gt;% colnames()   ## [1] \u0026quot;Sex\u0026quot; \u0026quot;W.Hnd\u0026quot; \u0026quot;Fold\u0026quot; \u0026quot;Clap\u0026quot; \u0026quot;Exer\u0026quot; \u0026quot;Smoke\u0026quot; \u0026quot;M.I\u0026quot; \u0026quot;Wr.Hnd\u0026quot;\r## [9] \u0026quot;NW.Hnd\u0026quot; \u0026quot;Pulse\u0026quot; \u0026quot;Height\u0026quot; \u0026quot;Age\u0026quot;\r1 2 3  # move Pulse before Height survey %\u0026gt;% relocate(Pulse, .before = Height) %\u0026gt;% colnames()   ## [1] \u0026quot;Sex\u0026quot; \u0026quot;Wr.Hnd\u0026quot; \u0026quot;NW.Hnd\u0026quot; \u0026quot;W.Hnd\u0026quot; \u0026quot;Fold\u0026quot; \u0026quot;Clap\u0026quot; \u0026quot;Exer\u0026quot; \u0026quot;Smoke\u0026quot; ## [9] \u0026quot;Pulse\u0026quot; \u0026quot;Height\u0026quot; \u0026quot;M.I\u0026quot; \u0026quot;Age\u0026quot;\r1 2 3  # move Pulse to the end survey %\u0026gt;% relocate(Pulse, .after = last_col()) %\u0026gt;% colnames()   ## [1] \u0026quot;Sex\u0026quot; \u0026quot;Wr.Hnd\u0026quot; \u0026quot;NW.Hnd\u0026quot; \u0026quot;W.Hnd\u0026quot; \u0026quot;Fold\u0026quot; \u0026quot;Clap\u0026quot; \u0026quot;Exer\u0026quot; \u0026quot;Smoke\u0026quot; ## [9] \u0026quot;Height\u0026quot; \u0026quot;M.I\u0026quot; \u0026quot;Age\u0026quot; \u0026quot;Pulse\u0026quot;\r  \n4. lag(), lead()   lag, lead ì˜ˆì‹œ  1  lag(1:5)   ## [1] NA 1 2 3 4\r1  lag(1:5, n = 2)   ## [1] NA NA 1 2 3\r1  lag(1:5, default = 0)   ## [1] 0 1 2 3 4\r1  lead(1:5)   ## [1] 2 3 4 5 NA\r1  lead(1:5, default = 6)   ## [1] 2 3 4 5 6\r   5. between(), near()   between, near ì˜ˆì‹œ  1 2  # between: \u0026gt;=, \u0026lt;= ì¡°ê±´ì„ í•œë²ˆì— ì‚¬ìš©í•˜ê¸° between(1:12, 7, 9)   ## [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE FALSE FALSE FALSE\r1 2  # near: ==ì˜ ì•ˆì „í•œ ë²„ì „(íŠ¹íˆ ì†Œìˆ˜ì  ê³„ì‚°ì‹œ) sqrt(2) ^ 2 == 2   ## [1] FALSE\r1  near(sqrt(2) ^ 2, 2)   ## [1] TRUE\r   6. coalesce() ê° ìœ„ì¹˜ë³„ë¡œ NAê°€ ì•„ë‹Œ ê°’ì„ ì²«ë²ˆì§¸ ê°’ì„ ë°˜í™˜\n  coalesce ì˜ˆì‹œ  1 2 3 4 5  library(tidyverse) a \u0026lt;- NA b \u0026lt;- 3 c \u0026lt;- 5 coalesce(a,b,c)   ## [1] 3\r1 2 3  # ì‘ìš©: coalesceë¥¼ NA imputationìœ¼ë¡œ í™œìš©í•˜ê¸° x \u0026lt;- sample(c(1:5, NA, NA, NA)) coalesce(x, 0)   ## [1] 0 2 0 3 1 4 0 5\r1 2 3  y \u0026lt;- c(1, 2, NA, NA, 5) z \u0026lt;- c(NA, NA, 3, 4, 5) coalesce(y, z)   ## [1] 1 2 3 4 5\r1 2 3 4 5  vecs \u0026lt;- list( c(1, 2, NA, NA, 5), c(NA, NA, 3, 4, 5) ) coalesce(!!!vecs)   ## [1] 1 2 3 4 5\r  \n7. recode() case_whenì˜ íŠ¹ìˆ˜í•œ í˜•íƒœë¡œì„œ ë°ì´í„°ë¥¼ êµì²´í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.\n  recode ì˜ˆì‹œ  1 2  tmp_char \u0026lt;- sample(c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;), 10, replace = TRUE) recode(tmp_char, a = \u0026#34;Apple\u0026#34;)   ## [1] \u0026quot;b\u0026quot; \u0026quot;b\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;b\u0026quot; \u0026quot;b\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;b\u0026quot; \u0026quot;Apple\u0026quot;\r## [10] \u0026quot;c\u0026quot;\r1  recode(tmp_char, a = \u0026#34;Apple\u0026#34;, b = \u0026#34;Banana\u0026#34;)   ## [1] \u0026quot;Banana\u0026quot; \u0026quot;Banana\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;Banana\u0026quot; \u0026quot;Banana\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;Banana\u0026quot;\r## [9] \u0026quot;Apple\u0026quot; \u0026quot;c\u0026quot;\r1  recode(tmp_char, a = \u0026#34;Apple\u0026#34;, b = \u0026#34;Banana\u0026#34;, .default = NA_character_)   ## [1] \u0026quot;Banana\u0026quot; \u0026quot;Banana\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;Banana\u0026quot; \u0026quot;Banana\u0026quot; \u0026quot;Apple\u0026quot; \u0026quot;Banana\u0026quot;\r## [9] \u0026quot;Apple\u0026quot; NA\r1 2 3  # ìˆ«ìí˜•ì€ ì•„ë˜ì™€ ê°™ì´ ``í‘œì‹œê°€ ë“¤ì–´ê°€ì•¼ í•œë‹¤. tmp_num \u0026lt;- sample(c(1,2,3), 10, replace=TRUE) recode(tmp_num, `1`=5)   ## [1] 3 5 3 5 2 3 3 2 5 3\r1 2 3  # !!!ì„ í™œìš©í•˜ë©´, pythonì—ì„œ dictionary í˜•íƒœë¡œ í™œìš©í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì“¸ ìˆ˜ ìˆë‹¤. level_key \u0026lt;- c(a = \u0026#34;apple\u0026#34;, b = \u0026#34;banana\u0026#34;, c = \u0026#34;carrot\u0026#34;) recode(tmp_char, !!!level_key)   ## [1] \u0026quot;banana\u0026quot; \u0026quot;banana\u0026quot; \u0026quot;apple\u0026quot; \u0026quot;apple\u0026quot; \u0026quot;banana\u0026quot; \u0026quot;banana\u0026quot; \u0026quot;apple\u0026quot; \u0026quot;banana\u0026quot;\r## [9] \u0026quot;apple\u0026quot; \u0026quot;carrot\u0026quot;\r  \n8. first(), last(), nth() ì²«ë²ˆì§¸, ë§ˆì§€ë§‰ ë˜ëŠ” íŠ¹ì • ìœ„ì¹˜ì— ìˆëŠ” ìš”ì†Œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.\n  first, last, nth ì˜ˆì‹œ  1 2 3 4  x \u0026lt;- 1:10 y \u0026lt;- 10:1 first(x)   ## [1] 1\r1  last(y)   ## [1] 1\r1  nth(x, 3)   ## [1] 3\r1  nth(y, 4)   ## [1] 7\r  \n9. rownames_to_column(), column_to_rownames()   rownames_to_column, column_to_rownames ì˜ˆì‹œ  1 2  a \u0026lt;- rownames_to_column(iris, var = \u0026#34;C\u0026#34;) head(a)   ## C Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## 1 1 5.1 3.5 1.4 0.2 setosa\r## 2 2 4.9 3.0 1.4 0.2 setosa\r## 3 3 4.7 3.2 1.3 0.2 setosa\r## 4 4 4.6 3.1 1.5 0.2 setosa\r## 5 5 5.0 3.6 1.4 0.2 setosa\r## 6 6 5.4 3.9 1.7 0.4 setosa\r1 2  b \u0026lt;- column_to_rownames(a, var = \u0026#34;C\u0026#34;) head(b)   ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## 1 5.1 3.5 1.4 0.2 setosa\r## 2 4.9 3.0 1.4 0.2 setosa\r## 3 4.7 3.2 1.3 0.2 setosa\r## 4 4.6 3.1 1.5 0.2 setosa\r## 5 5.0 3.6 1.4 0.2 setosa\r## 6 5.4 3.9 1.7 0.4 setosa\r   10. bind_rows(), bind_cols() ê¸°ì¡´ì˜ rbindë‘ cbind ëŒ€ì‹ ì— í™œìš©í•˜ë©´ ë  ê²ƒ ê°™ë‹¤.\n  bind_rows, bind_cols ì˜ˆì‹œ  1 2 3 4 5  # bind_rows one_r \u0026lt;- starwars[1:4, ] two_r \u0026lt;- starwars[9:12, ] three_r \u0026lt;- starwars[9:12, 3] bind_rows(one_r, two_r)   ## # A tibble: 8 x 14\r## name height mass hair_color skin_color eye_color birth_year sex gender\r## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Luke~ 172 77 blond fair blue 19 male mascu~\r## 2 C-3PO 167 75 \u0026lt;NA\u0026gt; gold yellow 112 none mascu~\r## 3 R2-D2 96 32 \u0026lt;NA\u0026gt; white, bl~ red 33 none mascu~\r## 4 Dart~ 202 136 none white yellow 41.9 male mascu~\r## 5 Bigg~ 183 84 black light brown 24 male mascu~\r## 6 Obi-~ 182 77 auburn, w~ fair blue-gray 57 male mascu~\r## 7 Anak~ 188 84 blond fair blue 41.9 male mascu~\r## 8 Wilh~ 180 NA auburn, g~ fair blue 64 male mascu~\r## # ... with 5 more variables: homeworld \u0026lt;chr\u0026gt;, species \u0026lt;chr\u0026gt;, films \u0026lt;list\u0026gt;,\r## # vehicles \u0026lt;list\u0026gt;, starships \u0026lt;list\u0026gt;\r1  bind_rows(one_r, three_r) # ì—ëŸ¬ ì•ˆ ëœ¸. NAë¡œ ì±„ì›€   ## # A tibble: 8 x 14\r## name height mass hair_color skin_color eye_color birth_year sex gender\r## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Luke~ 172 77 blond fair blue 19 male mascu~\r## 2 C-3PO 167 75 \u0026lt;NA\u0026gt; gold yellow 112 none mascu~\r## 3 R2-D2 96 32 \u0026lt;NA\u0026gt; white, bl~ red 33 none mascu~\r## 4 Dart~ 202 136 none white yellow 41.9 male mascu~\r## 5 \u0026lt;NA\u0026gt; NA 84 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 6 \u0026lt;NA\u0026gt; NA 77 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 7 \u0026lt;NA\u0026gt; NA 84 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 8 \u0026lt;NA\u0026gt; NA NA \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## # ... with 5 more variables: homeworld \u0026lt;chr\u0026gt;, species \u0026lt;chr\u0026gt;, films \u0026lt;list\u0026gt;,\r## # vehicles \u0026lt;list\u0026gt;, starships \u0026lt;list\u0026gt;\r1 2 3 4 5  # bind_cols one_c \u0026lt;- starwars[,1:4] two_c \u0026lt;- starwars[,7:9] three_c \u0026lt;- starwars[10:50,7:9] bind_cols(one_c, two_c)   ## # A tibble: 87 x 7\r## name height mass hair_color birth_year sex gender ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Luke Skywalker 172 77 blond 19 male masculine\r## 2 C-3PO 167 75 \u0026lt;NA\u0026gt; 112 none masculine\r## 3 R2-D2 96 32 \u0026lt;NA\u0026gt; 33 none masculine\r## 4 Darth Vader 202 136 none 41.9 male masculine\r## 5 Leia Organa 150 49 brown 19 female feminine ## 6 Owen Lars 178 120 brown, grey 52 male masculine\r## 7 Beru Whitesun lars 165 75 brown 47 female feminine ## 8 R5-D4 97 32 \u0026lt;NA\u0026gt; NA none masculine\r## 9 Biggs Darklighter 183 84 black 24 male masculine\r## 10 Obi-Wan Kenobi 182 77 auburn, white 57 male masculine\r## # ... with 77 more rows\r1  # bind_cols(one_c, three_c) # ì—ëŸ¬ ëœ¸, bind_rowsì™€ ì°¨ì´ì      \n11. mutate_all, mutate_if ëª¨ë“  ë³€ìˆ˜ë¥¼ ë‹¤ íŠ¹ì • í•¨ìˆ˜ë¥¼ ê±°ì¹œ í˜•íƒœë¡œ ë°”ê¾¸ê±°ë‚˜, ì¡°ê±´ì„ ì£¼ì–´ì„œ íŠ¹ì • í•¨ìˆ˜ë¥¼ ê±°ì¹œ í˜•íƒœë¡œ ë°”ê¾¸ëŠ” í•¨ìˆ˜ì´ë‹¤.\n  mutate_all, mutate_if ì˜ˆì‹œ  1  iris %\u0026gt;% mutate_all(as.integer) %\u0026gt;% head() # Speciesê¹Œì§€ integerë¡œ ë°”ê¿”ë²„ë¦¼   ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## 1 5 3 1 0 1\r## 2 4 3 1 0 1\r## 3 4 3 1 0 1\r## 4 4 3 1 0 1\r## 5 5 3 1 0 1\r## 6 5 3 1 0 1\r1  iris %\u0026gt;% mutate_if(is.double, as.integer) %\u0026gt;% head()   ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## 1 5 3 1 0 setosa\r## 2 4 3 1 0 setosa\r## 3 4 3 1 0 setosa\r## 4 4 3 1 0 setosa\r## 5 5 3 1 0 setosa\r## 6 5 3 1 0 setosa\r  \n12. inner_join, left_join, right_join, full_join SQLì—ì„œ ë´¤ë˜ join í•¨ìˆ˜ê°€ ì—­ì‹œë‚˜ ê·¸ëŒ€ë¡œ ìˆë‹¤. ê·¸ëŸ°ë° ì¹œì ˆí•˜ê²Œ ë¬´ì—‡ì„ ê¸°ì¤€ìœ¼ë¡œ join í–ˆëŠ”ì§€ë„ ìœ„ì— ì•Œë ¤ì¤˜ì„œ ì¢‹ì€ ê²ƒ ê°™ë‹¤.\n  join ì˜ˆì‹œ  1  band_members   ## # A tibble: 3 x 2\r## name band ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Mick Stones ## 2 John Beatles\r## 3 Paul Beatles\r1  band_instruments   ## # A tibble: 3 x 2\r## name plays ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 John guitar\r## 2 Paul bass ## 3 Keith guitar\r1  band_members %\u0026gt;% inner_join(band_instruments)   ## Joining, by = \u0026quot;name\u0026quot;\r## # A tibble: 2 x 3\r## name band plays ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 John Beatles guitar\r## 2 Paul Beatles bass\r1  band_members %\u0026gt;% left_join(band_instruments)   ## Joining, by = \u0026quot;name\u0026quot;\r## # A tibble: 3 x 3\r## name band plays ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Mick Stones \u0026lt;NA\u0026gt; ## 2 John Beatles guitar\r## 3 Paul Beatles bass\r1  band_members %\u0026gt;% right_join(band_instruments)   ## Joining, by = \u0026quot;name\u0026quot;\r## # A tibble: 3 x 3\r## name band plays ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 John Beatles guitar\r## 2 Paul Beatles bass ## 3 Keith \u0026lt;NA\u0026gt; guitar\r1  band_members %\u0026gt;% full_join(band_instruments)   ## Joining, by = \u0026quot;name\u0026quot;\r## # A tibble: 4 x 3\r## name band plays ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Mick Stones \u0026lt;NA\u0026gt; ## 2 John Beatles guitar\r## 3 Paul Beatles bass ## 4 Keith \u0026lt;NA\u0026gt; guitar\r  \n13. semi_join, anti_join   semi_join, anti_join ì˜ˆì‹œ  1 2  #ì´ë¯¸ ì¡°ì¸ëœ ê²°ê³¼ê°’ band_members %\u0026gt;% inner_join(band_instruments)   ## Joining, by = \u0026quot;name\u0026quot;\r## # A tibble: 2 x 3\r## name band plays ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 John Beatles guitar\r## 2 Paul Beatles bass\r1 2  #band_members ì¤‘ joinë  ê°’ í™•ì¸ band_members %\u0026gt;% semi_join(band_instruments)   ## Joining, by = \u0026quot;name\u0026quot;\r## # A tibble: 2 x 2\r## name band ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 John Beatles\r## 2 Paul Beatles\r1 2  #band_members ì¤‘ joinë˜ì§€ ì•Šì„ ê°’ í™•ì¸ band_members %\u0026gt;% anti_join(band_instruments)   ## Joining, by = \u0026quot;name\u0026quot;\r## # A tibble: 1 x 2\r## name band ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Mick Stones\r   ì°¸ê³  [1] sliceì™€ relocate ì˜ˆì‹œëŠ” slack ìŠ¬ê¸°ë¡œìš´í†µê³„ìƒí™œì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n","description":"","id":26,"section":"posts","tags":null,"title":"dplyr","uri":"https://jiwooblog.netlify.app/posts/r/dplyr/"},{"content":"purrr íŒ¨í‚¤ì§€ í›‘ì–´ë³´ê¸° purrrëŠ” Rì—ì„œ ê¹”ë”í•˜ê²Œ ë°˜ë³µ ì‘ì—… ì²˜ë¦¬í•˜ëŠ” íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤. Purrr ì„ ì´ìš©í•˜ë©´ ë°˜ë³µì‘ì—…ì„ Apply family ì— ë¹„í•´ ë”ìš± ì§ê´€ì ì´ê³  ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. purrrëŠ” ê³ ì–‘ì´ ìš¸ìŒì†Œë¦¬ì™€ Rì˜ í•©ì„±ì–´ë¡œ, ë¡œê³ ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n1  library(tidyverse)   ëª©ì°¨  map, map2 pmap, invoke_map rerun every, some, none reduce, accumulate  map, map2   map, map2 ì˜ˆì‹œ  1 2 3 4 5  num \u0026lt;- c(1,2,4,5,7) num2 \u0026lt;- c(3,5,6,8,9) #list map(num, function(x){x^2})   ## [[1]]\r## [1] 1\r## ## [[2]]\r## [1] 4\r## ## [[3]]\r## [1] 16\r## ## [[4]]\r## [1] 25\r## ## [[5]]\r## [1] 49\r1  map2(num, num2, sum)   ## [[1]]\r## [1] 4\r## ## [[2]]\r## [1] 7\r## ## [[3]]\r## [1] 10\r## ## [[4]]\r## [1] 13\r## ## [[5]]\r## [1] 16\r1 2  #numeric vector map_dbl(num, function(x){x^2})   ## [1] 1 4 16 25 49\r1  map2_dbl(num, num2, sum)   ## [1] 4 7 10 13 16\r     map ì‹¤ì „í™œìš©- iris data  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  n_iris \u0026lt;- iris %\u0026gt;% group_by(Species) %\u0026gt;% nest() mod_fun \u0026lt;- function(df){ lm(Sepal.Length ~ ., data = df) } m_iris \u0026lt;- n_iris %\u0026gt;% mutate(model = map(data, mod_fun)) b_fun \u0026lt;- function(mod){ coefficients(mod)[[1]] } m_iris %\u0026gt;% transmute(Species, beta = map_dbl(model, b_fun))   ## # A tibble: 3 x 2\r## # Groups: Species [3]\r## Species beta\r## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 setosa 2.35 ## 2 versicolor 1.90 ## 3 virginica 0.700\r  \npmap, invoke_map   pmap, invoke_map ì˜ˆì‹œ  1 2 3 4 5 6  x \u0026lt;- list(3, 6, 9) y \u0026lt;- list(10, 21, 30) z \u0026lt;- list(100, 200, 300) # pmapì€ 3ê°œ ì´ìƒì˜ ë¦¬ìŠ¤íŠ¸ì¼ ë•Œ ì‚¬ìš©í•œë‹¤. pmap(list(x, y, z), sum)   ## [[1]]\r## [1] 113\r## ## [[2]]\r## [1] 227\r## ## [[3]]\r## [1] 339\r1 2  # invoke_mapì€ ê°ê°ì˜ ë¦¬ìŠ¤íŠ¸ì— ë‹¤ë¥¸ í•¨ìˆ˜ë¥¼ ì ìš©ì‹œí‚¤ê³  ì‹¶ì„ ë•Œ í™œìš©í•œë‹¤. invoke_map(list(runif, rnorm), list(list(n = 10), list(n = 5)))   ## [[1]]\r## [1] 0.07250356 0.88643385 0.53457501 0.45493290 0.95970419 0.57638199\r## [7] 0.62800763 0.63266467 0.64451000 0.77471082\r## ## [[2]]\r## [1] 0.1348207 -0.5144428 -0.8763132 0.8955774 0.3386345\r   rerun rerunì€ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í˜•ì„±í•˜ëŠ” ë°ì— íš¨ìœ¨ì ì¸ ë°©ë²•ì´ë‹¤.\n  rerun ì˜ˆì‹œ  1 2 3 4 5  # ì˜ˆì‹œ set.seed(2021) a \u0026lt;- 10 %\u0026gt;% rerun(rnorm(5)) a   ## [[1]]\r## [1] -0.1224600 0.5524566 0.3486495 0.3596322 0.8980537\r## ## [[2]]\r## [1] -1.92256952 0.26174436 0.91556637 0.01377194 1.72996316\r## ## [[3]]\r## [1] -1.0822049 -0.2728252 0.1819954 1.5085418 1.6044701\r## ## [[4]]\r## [1] -1.841476 1.623310 0.131389 1.481122 1.513318\r## ## [[5]]\r## [1] -0.9424433 -0.1856850 -1.1011246 1.2081153 -1.6249385\r## ## [[6]]\r## [1] 0.10537833 -1.45544335 -0.35401614 -0.09370004 1.10066863\r## ## [[7]]\r## [1] -1.9638251 -1.4479444 1.0194434 -1.4214171 -0.6045321\r## ## [[8]]\r## [1] -1.58347390 -1.28593235 -1.45468488 -0.08707112 0.50473644\r## ## [[9]]\r## [1] 0.11638871 1.76021373 -0.34511646 2.12000016 -0.03437749\r## ## [[10]]\r## [1] -0.7921541 1.4755152 -0.7255572 0.3123790 0.6919641\r1 2 3 4 5 6 7  # ìœ„ í•¨ìˆ˜ëŠ” ì•„ë˜ì˜ í•¨ìˆ˜ì™€ ê°™ì€ ê²°ê³¼ë¥¼ ì‚°ì¶œí•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤. set.seed(2021) b \u0026lt;- list() for(i in 1:10){ b[[i]] \u0026lt;- rnorm(5) print(b[i]) }   ## [[1]]\r## [1] -0.1224600 0.5524566 0.3486495 0.3596322 0.8980537\r## ## [[1]]\r## [1] -1.92256952 0.26174436 0.91556637 0.01377194 1.72996316\r## ## [[1]]\r## [1] -1.0822049 -0.2728252 0.1819954 1.5085418 1.6044701\r## ## [[1]]\r## [1] -1.841476 1.623310 0.131389 1.481122 1.513318\r## ## [[1]]\r## [1] -0.9424433 -0.1856850 -1.1011246 1.2081153 -1.6249385\r## ## [[1]]\r## [1] 0.10537833 -1.45544335 -0.35401614 -0.09370004 1.10066863\r## ## [[1]]\r## [1] -1.9638251 -1.4479444 1.0194434 -1.4214171 -0.6045321\r## ## [[1]]\r## [1] -1.58347390 -1.28593235 -1.45468488 -0.08707112 0.50473644\r## ## [[1]]\r## [1] 0.11638871 1.76021373 -0.34511646 2.12000016 -0.03437749\r## ## [[1]]\r## [1] -0.7921541 1.4755152 -0.7255572 0.3123790 0.6919641\r1 2 3  for(i in 1:10){ print(a[[i]] == b[[i]]) }   ## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r## [1] TRUE TRUE TRUE TRUE TRUE\r1 2  # ì°¸ê³ ë¡œ, baseì— ìˆëŠ” replicateì™€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ í•œë²ˆ ì‚´í´ë³´ì! replicate(10, rnorm(5))   ## [,1] [,2] [,3] [,4] [,5] [,6]\r## [1,] -0.50029080 0.1037663 0.01604353 -0.9836134 -0.34823176 -0.2369450\r## [2,] -2.25586935 0.4272891 -0.18536431 0.5650808 -0.04298997 -0.9991415\r## [3,] 0.04374133 -0.1704815 0.39193326 1.6167519 -1.39755396 -1.3925426\r## [4,] -0.36881809 -1.5491403 -0.75671092 -0.2519641 1.49021633 0.9820053\r## [5,] -0.96022240 -1.5055999 0.23141761 -1.0558786 -1.03938712 0.3609409\r## [,7] [,8] [,9] [,10]\r## [1,] -0.3375092 -1.2400271 0.81061837 -0.1220018\r## [2,] -0.6433876 0.5339593 -0.29366457 -0.6467737\r## [3,] -2.1668853 -1.5882648 -0.05345832 -0.8678583\r## [4,] 0.6332890 -0.9909645 0.73518450 -0.5087003\r## [5,] -0.1449141 0.4832608 0.01498499 -2.0775844\r1  typeof(a)   ## [1] \u0026quot;list\u0026quot;\r1  typeof(replicate(10, rnorm(5)))   ## [1] \u0026quot;double\u0026quot;\r  \nevery, some, none ë¦¬ìŠ¤íŠ¸í˜•ì‹ì„ summariseí•˜ëŠ” ë°ì— íš¨ìœ¨ì ì¸ ë°©ë²•ì´ë‹¤.\n  every, some, none ì˜ˆì‹œ  1 2  y \u0026lt;- list(0:10, 5.5) y   ## [[1]]\r## [1] 0 1 2 3 4 5 6 7 8 9 10\r## ## [[2]]\r## [1] 5.5\r1  y %\u0026gt;% every(is.numeric)   ## [1] TRUE\r1  y %\u0026gt;% every(is.integer)   ## [1] FALSE\r1  y %\u0026gt;% some(is.integer)   ## [1] TRUE\r1  y %\u0026gt;% none(is.character)   ## [1] TRUE\r  \nreduce, accumulate í•¨ìˆ˜ë¥¼ ì¬ê·€ì ìœ¼ë¡œ(recursively) ì ìš©ì‹œí‚¤ëŠ” íš¨ìœ¨ì ì¸ ë°©ë²•ì´ë‹¤.\n  reduce, accumulate ì˜ˆì‹œ  1 2  #1. reduce: reduce(1:10, sum)   ## [1] 55\r1 2  #2. accumulate accumulate(1:10, sum)   ## [1] 1 3 6 10 15 21 28 36 45 55\r1 2 3  #reduce ì‘ìš© ë²„ì „ paste2 \u0026lt;- function(x, y, sep = \u0026#34;.\u0026#34;) paste(x, y, sep = sep) letters[1:4] %\u0026gt;% reduce(paste2)   ## [1] \u0026quot;a.b.c.d\u0026quot;\r  \n","description":"","id":27,"section":"posts","tags":null,"title":"purrr","uri":"https://jiwooblog.netlify.app/posts/r/purrr/"},{"content":"1. ì¶”ì²œ ì‚¬ì´íŠ¸  R for data science  2. ê²€ìƒ‰ íŒ êµ¬ê¸€ë§ ì‹œ, ë’¤ì— \u0026lsquo;Rpubs\u0026rsquo; ë¶™ì´ê¸°\n3. blogdown Auto-Knit ë„ê¸° Ctrl+S ë‹¨ì¶•í‚¤ë¡œ ìˆ˜ì‹œë¡œ ì €ì¥í•˜ëŠ” ìŠµê´€ ë•Œë¬¸ì—, Rmd íŒŒì¼ì„ ì‘ì—…í•  ë•Œ knitê°€ ìˆ˜ì‹œë¡œ ë˜ì–´ ì‘ì—…ì†ë„ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤.\nì´ëŸ´ ë•ŒëŠ” .Rprofileì´ë¼ëŠ” ì´ë¦„ì˜ íŒŒì¼ì„ ì°¾ì•„ì„œ\n blogdown.knit.on_save = TRUE\n ë¼ëŠ” ì½”ë“œì—ì„œ TRUEë¥¼ FALSEë¡œ ë°”ê¿”ì£¼ì–´ì•¼ í•œë‹¤.\n4. ìë™ì •ë ¬ ë‹¨ì¶•í‚¤ ctrl + I\n5. pythonì˜ dictionaryì²˜ëŸ¼ ì‚¬ìš©í•˜ê¸° 1 2 3 4 5  # recode: case_whenì˜ íŠ¹ìˆ˜í•œ í˜•íƒœë¡œì„œ ë°ì´í„°ë¥¼ êµì²´í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. tmp_char \u0026lt;- sample(c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;), 10, replace = TRUE) # !!!ì„ í™œìš©í•˜ë©´, pythonì—ì„œ dictionary í˜•íƒœë¡œ í™œìš©í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì“¸ ìˆ˜ ìˆë‹¤. level_key \u0026lt;- c(a = \u0026#34;apple\u0026#34;, b = \u0026#34;banana\u0026#34;, c = \u0026#34;carrot\u0026#34;) recode(tmp_char, !!!level_key)   ","description":"","id":28,"section":"posts","tags":null,"title":"R ê¿€íŒ","uri":"https://jiwooblog.netlify.app/posts/r/r_tip/"},{"content":"\r\rë°ì´í„° ì„¤ëª…\rdataset containing demographic data and laboratory data of 857 patients with acute coronary syndrome(ACS).\n# ë³€ìˆ˜ë³„ NAê°’ í™•ì¸\rcolSums(is.na(acs))\r## age sex cardiogenicShock entry ## 0 0 0 0 ## Dx EF height weight ## 0 134 93 91 ## BMI obesity TC LDLC ## 93 0 23 24 ## HDLC TG DM HBP ## 23 15 0 0 ## smoking ## 0\rcolSums(is.na(acs))[colSums(is.na(acs))\u0026gt;0]\r## EF height weight BMI TC LDLC HDLC TG ## 134 93 91 93 23 24 23 15\rna.var \u0026lt;- names(colSums(is.na(acs))[colSums(is.na(acs))\u0026gt;0])\r# ê·¸ë˜í”„ë¡œ ë³´ê¸°\raggr(acs, prop=FALSE) \r# ìƒê´€ê´€ê³„\racs.na \u0026lt;- is.na(acs[,na.var])\rround(cor(acs.na),2)\r## EF height weight BMI TC LDLC HDLC TG\r## EF 1.00 0.46 0.45 0.46 0.13 0.12 0.13 0.11\r## height 0.46 1.00 0.99 1.00 0.20 0.19 0.20 0.21\r## weight 0.45 0.99 1.00 0.99 0.20 0.19 0.20 0.21\r## BMI 0.46 1.00 0.99 1.00 0.20 0.19 0.20 0.21\r## TC 0.13 0.20 0.20 0.20 1.00 0.98 1.00 0.75\r## LDLC 0.12 0.19 0.19 0.19 0.98 1.00 0.98 0.73\r## HDLC 0.13 0.20 0.20 0.20 1.00 0.98 1.00 0.75\r## TG 0.11 0.21 0.21 0.21 0.75 0.73 0.75 1.00\r\rMissing Data ì¢…ë¥˜\rMCAR (missing completely at random): ë³€ìˆ˜ì˜ ì¢…ë¥˜ì™€ ê°’ ëª¨ë‘ì™€ ë¬´ê´€í•œ ê²½ìš°\rMAR (missing at random): ëˆ„ë½ì´ ë³€ìˆ˜ì™€ëŠ” ê´€ë ¨ìˆì§€ë§Œ ê·¸ ê°’ê³¼ëŠ” ê´€ê³„ ì—†ëŠ” ê²½ìš°\rMNAR (missing at not random): ëˆ„ë½ì˜ ì›ì¸ì´ ìˆëŠ” ê²½ìš°\r\r# na.omitê³¼ complete.casesëŠ” ê°™ì€ ì—­í• ì„ í•œë‹¤.\rnrow(na.omit(acs)) == nrow(acs[complete.cases(acs),])\r## [1] TRUE\r\rì¶”ê°€ë¡œ ì•Œì•„ë³¼ ë§Œí•œ ì£¼ì œ\rNA imputation with Gibbs Sampler\rNA imputation with GAN(Generative Adversarial Network)\r\r\n\r\nì°¸ê³ ì‚¬ì´íŠ¸: https://rstudio-pubs-static.s3.amazonaws.com/192402_012091b9adac42dbbd22c4d07cb00d36.html\n\r\r","description":"","id":29,"section":"posts","tags":null,"title":"NA Imputation","uri":"https://jiwooblog.netlify.app/posts/r/na_imputation/"},{"content":"2021.1.30  ë˜ ë‹¤ì‹œ ë³´ë‹ˆ 11.18ë‹¬ëŸ¬ ê³¼ê¸ˆìœ¼ë¡œ ê³„ì† ì¦ê°€í•˜ê³  ìˆì–´ì„œ ì´ê²ƒì €ê²ƒ ìµœëŒ€í•œ ì‚­ì œí•˜ê³  ê³„ì •ë„ í•´ì§€í–ˆë‹¤. 90ì¼ ë™ì•ˆ ë˜ ë‹¤ì‹œ ê³¼ê¸ˆì´ ë˜ëŠ”ì§€ ì§€ì†ì ìœ¼ë¡œ ì‚´í´ë´ì•¼ê² ë‹¤. ê·¸ë¦¬ê³  í•´ì§€í•œ ë©”ì¼ ê³„ì •ìœ¼ë¡œëŠ” ë‹¤ì‹œ ê³„ì • ê°œì„¤ì´ ì•ˆëœë‹¤ê¸¸ë˜ hanmail.netìœ¼ë¡œ ìˆ˜ì •í•œ í›„ ì‚­ì œí–ˆë‹¤. ì°¸ê³ ì‚¬ì´íŠ¸ëŠ” ë‘ ê³³ì„ ì°¸ê³ í–ˆë‹¤. ì°¸ê³ ì‚¬ì´íŠ¸1, ì°¸ê³ ì‚¬ì´íŠ¸2 ì œë°œ ë‹¤ìŒì—ëŠ” ê³¼ê¸ˆ ì•ˆ ë˜ê¸¸\u0026hellip;AWSëŠ” ë„ˆë¬´ ì–´ë ¤ìš´ ê²ƒ ê°™ë‹¤. ë‚˜ì¤‘ì— AWSì— ì¡°ê¸ˆ ë” ê´€ì‹¬ì´ ìƒê¸°ë©´ ì°¸ê³ ì‚¬ì´íŠ¸2ì˜ ë‹¤ì–‘í•œ í¬ìŠ¤íŠ¸ë“¤ì„ ì°¸ê³ í•´ë„ ì¢‹ì„ ê²ƒ ê°™ë‹¤.  2021.1.15  ë‹¤ì‹œ ë³´ë‹ˆ 10.68ë‹¬ëŸ¬ ê³¼ê¸ˆìœ¼ë¡œ ì¦ê°€í•´ìˆì–´ì„œ ì–¼ë¥¸ RDSë¥¼ ì‚­ì œí–ˆë‹¤. êµí›ˆ: ëŒë‹¤ë¦¬ë„\u0026hellip; ë‹¤ìŒì£¼ë¶€í„°ëŠ” ì£¼ì‹ ê´€ë ¨í•´ì„œë„ update í•´ì•¼ê² ë‹¤.  2021.1.14  FastCampus ë”°ë¼í•˜ë‹¤ê°€ AWS ê³¼ê¸ˆ 4.13ë‹¬ëŸ¬ ë°œìƒí–ˆë‹¤\u0026hellip; Free Tierë¼ê³  ëª¨ë“ ê²Œ ë‹¤ ê³µì§œëŠ” ì•„ë‹ˆì—ˆë‹¤\u0026hellip;  2021.1.11  Data Engineeringì— ê´€ì‹¬ì´ ìƒê²¼ë‹¤.  2021.1.8  First Course in Bayesian Statistical Methods(ì´í•˜ FCB) 1ì¥ì„ ì •ë¦¬í•´ì„œ ì˜¬ë ¸ë‹¤. ì˜¤ë˜ëœ Github Repositoryë¥¼ ì •ë¦¬í–ˆëŠ”ë°\u0026hellip;ì´ë“¤ì„ ì‚­ì œí•˜ë©´ ê° repositoryì™€ ì—°ê´€ëœ commit ê¸°ë¡ë“¤ë„ ì‚¬ë¼ì§€ê¸° ë•Œë¬¸ì— ì”ë”” ì‹¬ì–´ë‘” ê²ƒë“¤ì´ ì‚¬ë¼ì ¸ë²„ë¦¬ëŠ” ì‚¬íƒœê°€ ë°œìƒí–ˆë‹¤\u0026hellip;ì•„ê¹ë‹¤\u0026hellip; êµí›ˆ: repositoryëŠ” ì‹ ì¤‘í•˜ê²Œ ë§Œë“¤ê³ , ê°€ëŠ¥í•˜ë©´ ì§€ìš°ì§€ ë§ì\u0026hellip;  2021.1.7  LaTex ìˆ˜ì‹ ì‚½ì…ê¸°ëŠ¥ ì¶”ê°€ ( ì°¸ê³ ì‚¬ì´íŠ¸ )  2021.1.4  baseURL ìˆ˜ì • ëŒ“ê¸€ ê¸°ëŠ¥ í™•ì¸  ë¸”ë¡œê·¸ ì œì‘ì¼: 2021ë…„ 1ì›” 2ì¼ í† ìš”ì¼  ","description":"","id":30,"section":"updates","tags":null,"title":"January 2021","uri":"https://jiwooblog.netlify.app/updates/diary/2021_01/"},{"content":"Part 2-2. ë°ì´í„° ì—”ì§€ë‹ˆì–´ ê¸°ì´ˆ ë‹¤ì§€ê¸° ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n3. SQLite Studio SQLite Studio ë‹¤ìš´ë¡œë“œ\në°ì´í„° ë‹¤ìš´ë¡œë“œ  editor ì—¬ëŠ” ë²•: Tools \u0026gt; Open SQL Editor (or Alt + E) SQLiteê³¼ MySQLì„ í¬í•¨í•œ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ë“¤ê³¼ ì½”ë“œê°€ ë‹¤ë¥¸ ê²ƒë“¤ì´ ì‚¬ì†Œí•˜ê²Œ ìˆì„ ìˆ˜ ìˆë‹¤.  SQL ê¸°ë³¸ ë¬¸ë²• (1) SELECT 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  SELECT * FROM Salaries LIMIT 10; SELECT * FROM Salaries ORDER BY salary DESC LIMIT 10; SELECT * FROM Salaries WHERE yearID = \u0026#39;2010\u0026#39; AND lgID = \u0026#39;AL\u0026#39; ORDER BY salary DESC LIMIT 20; --SUM, AVG SELECT SUM(salary) FROM Salaries WHERE playerID = \u0026#39;rodrial01\u0026#39;; --Concat, Count, Group By SELECT nameFirst || \u0026#39; \u0026#39; || nameLast AS name FROM People Limit 10; SELECT nameFirst || \u0026#39; \u0026#39; || nameLast AS name FROM People Where playerID = \u0026#39;rodrial01\u0026#39;; SELECT COUNT(DISTINCT(nameFirst || \u0026#39; \u0026#39; || nameLast)) FROM People; SELECT nameFirst || \u0026#39; \u0026#39; || nameLast AS name, COUNT(*) FROM People GROUP BY name HAVING COUNT(*) \u0026gt; 1; SELECT teamID, SUM(Salary) as total_salary FROM Salaries GROUP BY teamID ORDER BY total_salary DESC;   SQL ê¸°ë³¸ ë¬¸ë²• (2) JOIN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  --Join SELECT t2.nameFirst ||\u0026#39; \u0026#39;||t2.nameLast AS name, t1.salary FROM Salaries t1 JOIN People t2 ON t2.playerID = t1.playerID ORDER BY salary DESC LIMIT 20; --Quiz. Top paid player for each team in 2010 SELECT t1.teamID, t2.nameFirst||\u0026#39; \u0026#39;||t2.nameLast AS name, t1.salary --using MAX(salary) instead of ORDER BY would be more efficient FROM Salaries t1 JOIN People t2 ON t2.playerID = t1.playerID WHERE t1.yearID = \u0026#39;2010\u0026#39; GROUP BY teamID ORDER BY salary DESC; -- Left Join, Right Join SELECT t1.playerID, COUNT(*) FROM People t1 LEFT JOIN AllstarFull t2 ON t2.playerID = t1.playerID GROUP BY 1 ORDER BY COUNT(*) DESC LIMIT 20;   SQL ê¸°ë³¸ (3) ë°ì´í„° íƒ€ì…ë“¤ ë° í‚¤ ê°’ë“¤, í…Œì´ë¸” ìƒì„± Primary Key: ë¹ ë¥¸ ì²˜ë¦¬, ì¤‘ë³µ ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œ ì„¤ì •í•˜ê¸°ë„ í•¨!\nForeign Key: ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ ì˜¨ ì¹¼ëŸ¼ ì²˜ë¦¬\nUnique: ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  -- ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± CREATE TABLE mytable (id INT, name VARCHAR(255), debut DATE); CREATE TABLE mytable2 (id INTEGER PRIMARY KEY AUTOINCREMENT, name VARCHAR(255), debut DATE); INSERT INTO mytable2 (name, debut) VALUES (\u0026#39;jiwoo\u0026#39;, \u0026#39; 2000-09-01\u0026#39;); SELECT * FROM mytable2; --INSERT INSERT INTO mytable2 (name, debut) VALUES (\u0026#39;jiwoo\u0026#39;, \u0026#39;2000-09-05\u0026#39;); SELECT * FROM mytable2; --Update UPDATE mytable2 SET debut = \u0026#39;2010-09-01\u0026#39; WHERE id = 1; --Replace REPLACE INTO mytable2 (id, name, debut) VALUES (5, \u0026#39;jiwoo2\u0026#39;, \u0026#39;2015-09-01\u0026#39;); -- UpdateëŠ” ê¸°ì¡´ì˜ ê°’ì´ ì—†ë‹¤ë©´ ì•„ë¬´ëŸ° í–‰ë™ë„ í•˜ì§€ ì•Šì§€ë§Œ, ReplaceëŠ” ê¸°ì¡´ì˜ ê°’ì´ ì—†ë‹¤ë©´ ìƒˆë¡œ ë§Œë“¤ì–´ë²„ë¦°ë‹¤ëŠ” ì°¨ì´ì ì´ ìˆë‹¤.  --Insert Or Ignore INSERT OR IGNORE INTO mytable2 (id, name, debut) VALUES (1, \u0026#39;jiwoo3\u0026#39;, \u0026#39;2010-09-11\u0026#39;); --ì´ë¯¸ idê°€ 1ì¸ í–‰ì´ ìˆì„ ê²½ìš°, ê·¸ëƒ¥ insert intoë§Œ í•˜ë©´ \u0026#39;unique constraint failed\u0026#39;ê°€ ëœ¨ì§€ë§Œ or ignoreì„ ì¶”ê°€í•´ì£¼ë©´ ê´œì°®ë‹¤.  -- Delete, ALter, Drop -- ì•„ì£¼ì•„ì£¼ ì‹ ì¤‘í•˜ê²Œ ì¨ì•¼í•˜ëŠ” ì»¤ë§¨ë“œë“¤ì´ë‹¤! SELECT * FROM mytable2; Delete FROM mytable2 WHERE id=1; ALTER TABLE mytalbe2 RENAME TO players; ALTER TABLE players ADD COLUMN DOB date; SELECT * FROM players; DROP TABLE mytable;  \nSQL ê¸°ë³¸ (4) Functions 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  -- Functions(1) ê¸°ë³¸ì²˜ë¦¬ ë° ì—°ì‚° SELECT * FROM players; SELECT SUBSTR(name, 1, 3) FROM players; SELECT UPPER(name) FROM players; SELECT AVG(LENGTH(name)) FROM players; --MAX, AVG, COUNT, SUM  -- Functions(2) ë‚ ì§œë°ì´í„°, Case When SELECT CURRENT_TIMESTAMP; --UTCê¸°ì¤€ SELECT DATE(\u0026#39;NOW\u0026#39;); SELECT DATETIME(CURRENT_TIMESTAMP, \u0026#39;+1 DAY\u0026#39;); SELECT id, name, CASE WHEN name = \u0026#39;jiwoo\u0026#39; THEN \u0026#39;OK\u0026#39; WHEN name = \u0026#39;jiwoo2\u0026#39; THEN \u0026#39;OK2\u0026#39; ELSE \u0026#39;No OK\u0026#39; END AS ok_name, --CASE WHENë¶€í„° ì—¬ê¸°ê¹Œì§€ê°€ variable í•˜ë‚˜!  debut FROM players;   ","description":"ë°ì´í„° ì—”ì§€ë‹ˆì–´ ê¸°ì´ˆ ë‹¤ì§€ê¸°","id":31,"section":"posts","tags":null,"title":"SQL ê¸°ì´ˆ (SQLite)","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part2_2/"},{"content":"\r\rChapter 02. Belief, Probability and Exchangeability\rë³¸ í¬ìŠ¤íŒ…ì€ First Course in Bayesian Statistical Methodsë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.\rì´ë²ˆ ì¥ì˜ ëª©í‘œëŠ” independenceì™€ exchangeabilityë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ de Finettiâ€™s theoremì´ Bayesianì— ê°–ëŠ” ì˜ì˜ë¥¼ ì´í•´í•œë‹¤ë©´, ë² ì´ì¦ˆ í†µê³„ë¥¼ ê³µë¶€í•  ì¤€ë¹„ê°€ ëœ ê²ƒì´ë‹¤.\nBelief functions and Probabilities\r$Be()$ëŠ” belief functionì´ë¼ê³  í•˜ì. ì˜ˆë¥¼ ë“¤ì–´, $Be(F) \u0026gt; Be(G)$ëŠ” Gë³´ë‹¤ Fë¥¼ ë” ë¯¿ëŠ”ë‹¤ê³  í•´ì„í•˜ë©´ ëœë‹¤. F, G, Hë¥¼ ì•„ë˜ì™€ ê°™ì€ ê°ê°ì˜ ìƒí™©ì´ë¼ê³  ê°€ì •í•´ë³´ì.\n\rF : ì¢ŒíŒŒ í›„ë³´ìë¥¼ íˆ¬í‘œí•˜ëŠ” ê²½ìš° G : ì†Œë“ì´ í•˜ìœ„ 10%ì— ì†í•˜ëŠ” ê²½ìš° H : ëŒ€ë„ì‹œì— ê±°ì£¼í•˜ëŠ” ê²½ìš°\n\rAxioms of beliefs\r$Be($not $H|H) \\le Be(F|H) \\le Be(H|H)$\r$Be(F $ or $G|H) \\ge max(Be(F|H), Be(G|H))$\r$Be(F $ and $G|H)$ can be drvied from $Be(G|H)$ and $Be(F|G $ and $H)$\r\r\rAxioms of probability\r$0 = Pr($not $H|H) \\le Pr(F|H) \\le Pr(H|H) \\le = 1$\r$Pr(F \\cup G|H) = Pr(F|H) + Pr(G|H)$ if $F \\cap G = \\emptyset$\r$Pr(F \\cap G|H) = Pr(G|H)Pr(F|g \\cap H)$\r\rbeliefì™€ probabilityì— ëŒ€í•œ ê°ê°ì˜ ê³µë¦¬ë“¤ì´ ë§¤ì¹­ë˜ë¯€ë¡œ, ìš°ë¦¬ëŠ” ë¯¿ìŒì˜ ì •ë„ë¥¼ ê³„ì‚°í•  ë•Œ í™•ë¥ í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë‹¤ë¤„ë„ ë¬´ë°©í•˜ë‹¤ê³  ê²°ë¡ ë‚¼ ìˆ˜ ìˆë‹¤.\n\r\rConditional Independence\rì‚¬ê±´ Fì™€ GëŠ” ì•„ë˜ì™€ ê°™ì€ ìƒí™©ì—ì„œ ì¡°ê±´ë¶€ ë…ë¦½(conditional independence)ì´ë¼ê³  í•œë‹¤.\r\\[Pr(F \\cap G|H) = Pr(F|H)Pr(G|H)\\]\rì´ë¥¼ í’€ì–´ì„œ í•´ì„í•´ë³´ìë©´, Hë¥¼ ì•Œê³  ìˆëŠ” ìƒí™©ì—ì„œ, ì¶”ê°€ì ìœ¼ë¡œ Gì— ëŒ€í•´ì„œ ì•Œê²Œ ë˜ëŠ” ê²ƒì€ Fì— ëŒ€í•œ ë¯¿ìŒì„ ë³€í™”ì‹œí‚¤ëŠ” ë°ì— ì˜í–¥ì´ ì—†ë‹¤ëŠ” ê²ƒì´ë‹¤. ìœ„ë¥¼ í†µí•´ì„œ ì•„ë˜ë¥¼ ì•Œ ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤.\r\\[Pr(F|H \\cap G) = Pr(F|H) \\]\n\rExchangeability\r$Y_1, ..., Y_n$ì´ ìˆì„ ë•Œ, ì´ ìˆœì„œë¥¼ ì–´ë–»ê²Œ ì„ë”ë¼ë„ ê²°í•©í™•ë¥ ì€ ë°”ê¾¸ì§€ ì•Šì„ ë•Œ exchangeableí•˜ë‹¤ê³  í•œë‹¤. ì´ëŠ” ì§ê´€ì ìœ¼ë¡œ í’€ì–´ì“´ ê²ƒì´ë©°, ë‹¤ì‹œ í•œ ë²ˆ ìˆ˜í•™ì  ì •ì˜ë¡œ ìì„¸íˆ ì¨ë³´ìë©´ ì•„ë˜ì™€ ê°™ë‹¤.\rLet $p(y_1, ... y_n)$ be the joint density of $Y_1, ..., Y_n$. If $p(y_1, ..., y_n) = p(y_{\\pi_1}, ..., y_{\\pi_n})$ for all permutations $\\pi$ of {1, â€¦, n}, then $Y_1, ..., Y_n$ are exchangeable.\n\\[\\begin{equation}\r\\left.\\begin{aligned}\rY_1, ..., Y_n|\\theta \\text{ i.i.d} \\\\ \\theta \\sim p(\\theta)\r\\end{aligned}\\right\\} \\Rightarrow Y_1, ... Y_n \\text{ are exchangeable}\r\\end{equation}\\]\n\rde Finettiâ€™s Theorem\rë§Œì•½ $Y_1, ..., Y_n$ì´ exchangeabilityë¥¼ ë§Œì¡±í•œë‹¤ë©´, ì•„ë˜ì™€ ê°™ì´ ë§í•  ìˆ˜ ìˆë‹¤.\n\\[p(y_1, ..., y_n) = \\int{\\Bigg\\{\\prod_{1}^{n}p(y_i|\\theta)\\Bigg\\} \\:p(\\theta)d\\theta} \\\\\r\\text{for some parameter} \\: \\theta\\]\nì´ëŠ” í™•ë¥ ë³€ìˆ˜ $Y_1, ..., Y_n$ì— ëŒ€í•´ì„œ exchangeabilityë¥¼ ë§Œì¡±í•œë‹¤ë©´, $p(y_1, ..., y_n)$ì— ëŒ€í•´ $\\theta$ë¼ëŠ” parameterë¥¼ í™œìš©í•˜ì—¬ ìœ„ì™€ ê°™ì€ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ê·¸ë ‡ë‹¤ë©´ ì´ ì •ë¦¬ê°€ ë² ì´ì§€ì•ˆì—ê²Œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°–ëŠ” ê²ƒì¼ê¹Œ? ì´ëŠ” ì‚¬ì „í™•ë¥ ë¶„í¬(prior model)ì™€ ê°€ëŠ¥ë„í•¨ìˆ˜(sampling model)ê°€ belief model $p(y_1, ..., y_n)$ì— ì˜ì¡´í•¨ì„ ì˜ë¯¸í•œë‹¤. í’€ì–´ì„œ ì´ì•¼ê¸°í•˜ìë©´, parameter $\\theta$ê°€ í™•ë¥ ë¡ ìê°€ ì£¼ì¥í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë¯¸ì§€ì˜ ê³ ì •ëœ ê°’ì´ ì•„ë‹ˆë¼, ì–´ë–¤ ë¶„í¬ë¥¼ ê°–ëŠ” í™•ë¥ ë³€ìˆ˜ë¡œ ë³¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. (ê·¸ë¦¬ê³  ê·¸ê²ƒì„ ìš°ë¦¬ëŠ” ì‚¬ì „í™•ë¥ ë¶„í¬ prior distributionì´ë¼ê³  ë¶€ë¥¸ë‹¤.)\n\rì£¼ì˜ì‚¬í•­\rBayesâ€™ ruleì€ ë°ì´í„°ë¥¼ ì ‘í•œ ì´í›„, ìš°ë¦¬ì˜ ë¯¿ìŒì´ ì–´ë–»ê²Œ ì—…ë°ì´íŠ¸ë˜ëŠ”ì§€ì— ëŒ€í•œ ìˆ˜ì‹ì´ë‹¤.\rì—¬ê¸°ì„œ í—·ê°ˆë¦¬ë©´ ì•ˆë˜ëŠ” ê²ƒì´ ìˆë‹¤. Bayesâ€™ ruleì€ ìš°ë¦¬ì˜ ë¯¿ìŒì´ ì–´ë•Œì•¼ í•˜ëŠ”ì§€(should be)ì— ëŒ€í•´ì„œ ì´ì•¼ê¸°í•˜ê³  ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì–´ë–»ê²Œ ë³€í•´ì•¼ í•˜ëŠ”ì§€(should change)ì— ëŒ€í•´ì„œ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒì´ë‹¤.\n\rConclusion\rë¯¿ìŒ(Belief)ë„ í™•ë¥ (Probability)ë¡œì¨ ì´ì•¼ê¸°í•  ìˆ˜ ìˆë‹¤.\rparamter $\\theta$ëŠ” ë¶„í¬ë¥¼ ê°–ëŠ” í™•ë¥ ë³€ìˆ˜ì´ë‹¤.\r\ní˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\r\n\r\r","description":"Belief, Probability and Exchangeability","id":32,"section":"posts","tags":null,"title":"Exchangeability","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/fcb02/"},{"content":"Exponential Family í•œêµ­ì–´ë¡œëŠ” ì§€ìˆ˜ì¡± ë˜ëŠ” ì§€ìˆ˜ë¥˜ë¼ê³ ë„ í•˜ì§€ë§Œ, ì˜ì–´ë¡œ ë³´ëŠ” í¸ì´ ì§ê´€ì ìœ¼ë¡œ ë°›ì•„ë“¤ì´ëŠ” ë°ì— í¸í•  ê²ƒì´ë‹¤.\n$f(x;\\theta) = \\begin{cases}\rexp\\big[p(\\theta)K(x) + s(x) + q(\\theta)\\big] \u0026amp; x \\in S \\\\\r0 \u0026amp; o.w\r\\end{cases} $\n S does not depend on $\\theta$ $p(\\theta)$ is a nontrivial continuous function of $\\theta \\in \\Omega$\n3-1. If X is continuous, $K'(x) \\neq 0$ and $s(x)$ is continuous function.\n3-2. If X is discrete, $K(x)$ is nontrivial function.  ë˜ëŠ”\n$ f(y|\\phi) = \\begin{cases}\rh(y)c(\\phi)exp\\big[\\phi K(y)\\big] \u0026amp; y \\in S \\\\\r0 \u0026amp; o.w\r\\end{cases} $\n S does not depend on $\\phi$ $\\phi$ is a nontrivial continuous function of $\\theta \\in \\Omega$\n3-1. If X is continuous, $K'(y) \\neq 0$ and $h(y)$ is continuous function.\n3-2. If X is discrete, $K(y)$ is nontrivial function.  ì²«ë²ˆì§¸ëŠ” Hogg ì±…ì„ ê¸°ì¤€ìœ¼ë¡œ ì„œìˆ í•œ ê²ƒì´ë©°, ë‘ë²ˆì§¸ëŠ” FCB ê¸°ì¤€ìœ¼ë¡œ ì„œìˆ í•œ ê²ƒì´ë‹¤.\nì¦‰ ìœ„ëŠ” Frequentist ì…ì¥, ì•„ë˜ëŠ” Bayesian ì…ì¥ì´ë¼ê³  ë³´ë©´ ëœë‹¤. ìˆ˜ì‹ì— ìˆì–´ì„œ í° ì°¨ì´ëŠ” ì—†ì§€ë§Œ, parameterê°€ givenì¸ì§€ ì•„ë‹Œì§€ê°€ ì°¨ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.\nSufficient Statistic ìš°ì„ ì€ Hoggì±… ì„œìˆ ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ì•¼ê¸°í•´ë³´ì.\n$X_1, ..., X_n \\text{ ~ iid } f(x;\\theta)$ì´ê³  $f(x;\\theta)$ê°€ exponential familyë¼ê³  í•œë‹¤ë©´,\n$Y_1 = \\sum_{i=1}^{n}K(X_i)$ëŠ” $\\theta$ì— ëŒ€í•œ ì™„ì „ì¶©ë¶„í†µê³„ëŸ‰(complete sufficient statistic)ì´ë‹¤.\nê·¸ë ‡ë‹¤ë©´ Sufficient í•˜ë‹¤ëŠ” ê²ƒì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¼ê¹Œ? Defintion: $p(X_1, ..., X_n|Y_1=y_1)$ê°€ $\\theta$ì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ”ë‹¤.\nì¦‰ $\\frac{p(X_1, ..., X_n, Y_1=y_1;\\theta)}{p(Y_1=y_1; \\theta)}$ë¥¼ ê³„ì‚°í•  ë•Œ, $\\theta$ì— ì˜í•´ ê°’ì´ ì¢Œì§€ìš°ì§€ ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì´ë‹¤.\nì´ë¥¼ í’€ì–´ì„œ ë§í•˜ìë©´, ê°ê° $X_1,...,X_n$ ë°ì´í„°ë¥¼ ì§ì ‘ ì•Œì§€ëŠ” ëª»í•˜ë”ë¼ë„ ì´ë“¤ì— ëŒ€í•œ ì •ë³´ê°€ $Y_1$ì— ë“¤ì–´ê°€ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— $Y_1$ ê°’ì„ ì•Œê²Œ ë˜ë©´ $X_1,...,X_n$ì˜ joint probabilityë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤. ê·¸ë˜ì„œ **ì¶©ë¶„(sufficient)**í•˜ë‹¤ëŠ” ê²ƒì´ë‹¤.\n","description":"ì§€ìˆ˜ì¡±","id":33,"section":"posts","tags":null,"title":"Exponential Family","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/exponential_family/"},{"content":"2021.03.06  ë¬¸ë“ ë¹ˆë„ë¡ ìì™€ ë² ì´ì§€ì•ˆì˜ ë…¼ìŸì´ ì¿¤ê³¼ í¬í¼ì˜ ê³¼í•™ì² í•™ ë…¼ìŸê³¼ ë¹„ìŠ·í•˜ë‹¤ëŠ” ìƒê°ì„ í–ˆë‹¤. ë¹ˆë„ë¡ ìëŠ” ê°€ì„¤ê²€ì •ì´ë¼ëŠ” ê²ƒì„ í•˜ë©° ê·€ë¬´ê°€ì„¤ê³¼ ëŒ€ë¦½ê°€ì„¤ì„ ë†“ê³  ê²€ì •í†µê³„ëŸ‰ì„ í†µí•´ ê¸°ê°í•˜ê±°ë‚˜ ì±„íƒì„ í•œë‹¤. ë°˜ë©´, ë² ì´ì§€ì•ˆì€ ì² ì €í•˜ê²Œ ë² ì´ì¦ˆ ì´ë¡ ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ë¶„í¬ë¥¼ ì œì‹œí•˜ì—¬ ê°€ëŠ¥ì„±ì„ ì œì‹œí•œë‹¤. í¬í¼ê°€ ë°˜ì¦ê°€ëŠ¥ì„±ì„ ì´ì•¼ê¸°í–ˆë‹¤ë©´, ì¿¤ì€ ì´ë¥¼ ë¹„íŒí•˜ë©° íŒ¨ëŸ¬ë‹¤ì„ì˜ ì „í™˜ì— ëŒ€í•´ ì´ì•¼ê¸°í–ˆë‹¤.  2021.03.28  ëŒ€í•™ì› ì§„í•™ì„ í•˜ê¸° ìœ„í•´ ì–´ëŠ ì •ë„ ê³ ë¯¼ì„ ë§ˆì³¤ì§€ë§Œ, ìƒê°ë³´ë‹¤ ë§ˆìŒì´ ëœ ì¡íŒ ê²ƒ ê°™ë‹¤. ì—´í’ˆíƒ€ë¥¼ ì‚¬ìš©í•˜ê³  ìˆëŠ”ë° ìƒê°ë³´ë‹¤ ì¢‹ì€ ê²ƒ ê°™ë‹¤. ë” ì˜ í™œìš©í•´ë³´ë„ë¡ í•´ì•¼ê² ë‹¤.  ","description":"","id":34,"section":"updates","tags":null,"title":"March 2021","uri":"https://jiwooblog.netlify.app/updates/diary/2021_03/"},{"content":"ë¹„ëª¨ìˆ˜í†µê³„í•™ ë¹„ëª¨ìˆ˜í†µê³„í•™(nonparametric statistics)ëŠ” ëª¨ìˆ˜ì  ê²€ì •ì˜ ê°€ì •ì´ ì¶©ì¡±ë˜ì§€ ëª»í•˜ê±°ë‚˜, ë°ì´í„° í˜•ì‹ì´ ìˆœì„œí˜•ì¼ ê²½ìš°ì²˜ëŸ¼ ì¼ë°˜ì ì´ì§€ ì•Šì€ ê²½ìš°ì— ì‚¬ìš©í•˜ëŠ” í†µê³„ì  ë°©ë²•ë¡ ì— ëŒ€í•œ ì—°êµ¬ë¥¼ í•œë‹¤.\ntê²€ì •ì—ì„œ ë…ë¦½í‘œë³¸ t-ê²€ì •ê³¼ ëŒ€ì‘í‘œë³¸ t-ê²€ì •ì´ ìˆìŠµë‹ˆë‹¤. ì´ì— ëŒ€ì‘í•˜ì—¬ ë¹„ëª¨ìˆ˜í†µê³„í•™ì—ì„œëŠ” Wilcoxon rank-sum test(Mann-Whitney U-test)ì™€ Wilcoxon signed-rank testê°€ ìˆìŠµë‹ˆë‹¤.\n1. Wilcoxon rank-sum test Mann-Whitney U-testë¼ê³ ë„ í•œë‹¤.\në…ë¦½í‘œë³¸ t-ê²€ì •ì˜ ë¹„ëª¨ìˆ˜ ë²„ì „ì´ë‹¤.\n2. Wilcoxon signed-rank test ëŒ€ì‘í‘œë³¸ t-ê²€ì •ì˜ ë¹„ëª¨ìˆ˜ ë²„ì „ì´ë‹¤.\nì°¸ê³  [1] ì—°ì„¸ëŒ€í•™êµ ì‹¬ë¦¬í†µê³„ 2019-1 ìˆ˜ì—…ìë£Œ [2] https://blog.naver.com/istech7/50152096673\n[3] http://www.incodom.kr/R%ED%99%9C%EC%9A%A9/Wilcoxon_Signed-Rank_Test\n[4] https://dermabae.tistory.com/159\n","description":"","id":35,"section":"posts","tags":null,"title":"ë¹„ëª¨ìˆ˜í†µê³„í•™","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/nonparametric/"},{"content":"ANOVA ANOVAëŠ” Analysis of Varianceì˜ ì•½ìë¡œ, í•œêµ­ì–´ë¡œëŠ” ë¶„ì‚° ë¶„ì„ì´ë¼ê³  í•œë‹¤. ì§‘ë‹¨ ê°„ ë¶„ì‚°ê³¼ ì§‘ë‹¨ ë‚´ ë¶„ì‚°ì„ ë¹„êµí•˜ì—¬ ì²˜ë¦¬íš¨ê³¼ê°€ ìˆëŠ”ì§€ ì‚´í´ë³´ëŠ” í†µê³„ë°©ë²•ì´ë‹¤.\n","description":"ë¶„ì‚°ë¶„ì„","id":36,"section":"posts","tags":null,"title":"ANOVA","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/anova/"},{"content":"t-ê²€ì • t-ê²€ì •ì€ ëª¨ì§‘ë‹¨ì˜ ë¶„ì‚°ì´ë‚˜ í‘œì¤€í¸ì°¨ë¥¼ ì•Œì§€ ëª»í•  ë•Œ, ëª¨ì§‘ë‹¨ì„ ëŒ€í‘œí•˜ëŠ” í‘œë³¸ìœ¼ë¡œë¶€í„° ì¶”ì •ëœ ë¶„ì‚°ì´ë‚˜ í‘œì¤€í¸ì°¨ë¥¼ ê°€ì§€ê³  ê²€ì •í•˜ëŠ” ë°©ë²•ì´ë‹¤.\n1. ë‹¨ì¼í‘œë³¸ t-ê²€ì • ëª¨ì§‘ë‹¨ì˜ í‰ê· ì´ íŠ¹ì •ê²€ì •ê°’ê³¼ ê°™ì€ì§€ í™•ì¸í•˜ëŠ” í†µê³„ë¹µë²•ì´ë‹¤.\n2. ë…ë¦½í‘œë³¸ t-ê²€ì • ë…ë¦½ëœ ë‘ ì§‘ë‹¨ ê°„ ë¹„êµí•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, ì„œë¡œ ë‹¤ë¥¸ ë‘ ëª¨ì§‘ë‹¨ìœ¼ë¡œë¶€í„° ë°ì´í„°ê°€ ì¶”ì¶œë˜ì—ˆì„ ë•Œ ì‹œí–‰í•œë‹¤.\n1 2 3 4 5 6 7 8  # independent t-test x1 = 3.6667 x2 = 6.0667 s1 = 2.60951 s2 = 2.37447 n1 = n2 = 15 sp = sqrt((s1^2*(n1-1) + s2^2*(n2-1)) / ((n1-1) + (n2-1))) t = (x1-x2) / (sp*sqrt(1/n1 + 1/n2))   3. ëŒ€ì‘í‘œë³¸ t-ê²€ì • í•œ ì§‘ë‹¨ ë‚´ ë¹„êµí•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, í•˜ë‚˜ì˜ ëª¨ì§‘ë‹¨ìœ¼ë¡œë¶€í„° ë°ì´í„°ë¥¼ ë°˜ë³µ ì¶”ì¶œí•˜ì˜€ì„ ë•Œ ì‹œí–‰í•œë‹¤.\n1 2 3 4 5 6 7  # paired t-test xa \u0026lt;- c(1,10,2,6,5,2,3,4,2,1,2,2,3,4,8) xb \u0026lt;- c(2,10,5,7,6,5,6,9,6,7,8,5,4,2,9) n \u0026lt;- length(xa) d_bar = (sum(xa)-sum(xb))/n d_sd = sqrt(sum((xa-xb-d_bar)^2)/(n-1)) t = d_bar / (d_sd/sqrt(n))   ì°¸ê³  [1] ì—°ì„¸ëŒ€í•™êµ ì‹¬ë¦¬í†µê³„ 2019-1 ìˆ˜ì—…ìë£Œ [2] https://wikidocs.net/34009\n","description":"t-test","id":37,"section":"posts","tags":null,"title":"t ê²€ì •","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/t_test/"},{"content":"ì‹ ë¢°êµ¬ê°„ê³¼ ì‹ ìš©êµ¬ê°„ ê°„ë‹¨í•˜ê²Œ êµ¬ë¶„í•˜ìë©´, ì‹ ë¢°êµ¬ê°„ì€ ë¹ˆë„ì£¼ì˜ìê°€, ì‹ ìš©êµ¬ê°„ì€ ë² ì´ì§€ì•ˆì´ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤.\nì¼ë°˜ì ìœ¼ë¡œ ì‹ ìš©êµ¬ê°„ì„ ì‹ ë¢°êµ¬ê°„ìœ¼ë¡œ ì°©ê°í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.\nì‹ ë¢°êµ¬ê°„ (Confidence Interval) â€œIf we repeat the experiment infinitely many times, 95% of the experiments will capture the population parameter in their confidence intervals.â€\r í•´ì„í•˜ìë©´, ë¬´ìˆ˜íˆ ë§ì´ ë°˜ë³µí•˜ì—¬ ë°ì´í„°ë¥¼ ì–»ê³  ì‹ ë¢°êµ¬ê°„ì„ ì‚°ì¶œí•œë‹¤ë©´, ê·¸ ìˆ˜ë§ì€ ì‹ ë¢°êµ¬ê°„ ì¤‘ 95%ëŠ” ëª¨ìˆ˜ë¥¼ ê°–ê³  ìˆì„ ê²ƒìœ¼ë¡œ ì‹ ë¢°í•œë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— í•œë²ˆì˜ ì‹¤í—˜ê²°ê³¼ë§Œìœ¼ë¡œ ì‹ ë¢°êµ¬ê°„ì„ êµ¬í•˜ê³  ì´ë¥¼ í™œìš©í•˜ëŠ” ë°ì—ëŠ” ë‹¤ì†Œ ë¬´ë¦¬ê°€ ìˆì–´ë³´ì¸ë‹¤. í•˜ì§€ë§Œ ì¤‘ì‹¬ê·¹í•œì •ë¦¬ë¥¼ í†µí•´ ì •ê·œì„±ì„ í™•ë³´í•¨ìœ¼ë¡œì¨ ì–´ëŠ ì •ë„ì˜ ë…¼ë¦¬ì  ë¹„ì•½ì€ ë§‰ëŠ”ë‹¤ê³  ë¹ˆë„ë¡ ìë“¤ì€ ìƒê°í•œë‹¤.\nì‹ ìš©êµ¬ê°„ (Credential Interval) â€œThere is 95% probability/plausibility/likelihood that the population parameter lies in the interval.â€\r í•´ë‹¹ êµ¬ê°„ì— ëª¨ìˆ˜ê°€ ìˆì„ í™•ë¥ ì„ êµ¬í•œë‹¤. 95%ê°€ ë˜ëŠ” êµ¬ê°„ì€ ë¬´ìˆ˜íˆ ë§ì´ ì¡ì„ ìˆ˜ ìˆê² ì§€ë§Œ, ê·¸ì¤‘ì—ì„œ HPD(Highest posterior Density) regionì„ êµ¬í•˜ì—¬ í™œìš©í•œë‹¤. ì´ëŠ” xì¶•ì— í‰í–‰í•œ ì„ ì„ ìœ„ì—ì„œë¶€í„° ë‚´ë ¤ì˜¤ë©´ì„œ ì ìš©í•˜ì—¬ ê·¸ ì‚¬ì´ ì˜ì—­ì˜ ë„“ì´ê°€ 95%ê°€ ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ê³„ì‚°í•œë‹¤.\nì‹ ìš©êµ¬ê°„ì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ì–»ì„ ìˆ˜ ìˆëŠ” ì¥ì ì€ í¬ê²Œ ë‘ ê°€ì§€ë¡œ ìš”ì•½ ëœë‹¤.\n ì‚¬í›„ë¶„í¬ê°€ ì •ê·œë¶„í¬ê°€ ì•„ë‹ˆë”ë¼ë„ í™•ë¥ ê³„ì‚°ì„ í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” ì •ì˜ì—­ì— ëŒ€í•œ ì „ì œë¥¼ ê³ ë ¤í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ìœ¼ë¡œ ì´ì–´ì§„ë‹¤. ì‚¬ì „í™•ë¥ ì„ ê³ ë ¤í•¨ìœ¼ë¡œì¨ ì‹ ë¢°êµ¬ê°„ë³´ë‹¤ ë¹ ë¥´ê²Œ ì‹ ìš©êµ¬ê°„ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.  ì°¸ê³ ì‚¬ì´íŠ¸ [1] https://towardsdatascience.com/do-you-know-credible-interval-e5b833adf399\n[2] FCB figure 3.6\n","description":"","id":38,"section":"posts","tags":null,"title":"ì‹ ë¢°êµ¬ê°„, ì‹ ìš©êµ¬ê°„","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/interval/"},{"content":"ì •ê·œì„± ê²€ì • ","description":"","id":39,"section":"posts","tags":null,"title":"ì •ê·œì„± ê²€ì •","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/normality/"},{"content":"ì‚¼ê°í•¨ìˆ˜ ê³µì‹(Trigonometric Functions) $\\sin^2{x} + \\cos^2{x} = 1 $\n$\\tan^2{x} + 1 = \\sec^2{x} $\n$\\cos{2x} = 1 - 2\\sin^2{x} = 2\\cos^2{x} -1 $\n$\\frac{d}{dx}\\tan{x} = \\sec^2{x} $\n$\\frac{d}{dx}\\sec{x} = \\sec{x}\\tan{x} $\n","description":"","id":40,"section":"posts","tags":null,"title":"ì‚¼ê°í•¨ìˆ˜ê³µì‹","uri":"https://jiwooblog.netlify.app/posts/statistics/calculus/3_trigonometry/"},{"content":"Pygame ê¸°ì´ˆ ë³¸ í¬ìŠ¤íŒ…ì€ í•´ë‹¹ ì‚¬ì´íŠ¸(https://kkamikoon.tistory.com/129)ë¥¼ ì ê·¹ì°¸ê³  í•˜ì˜€ìŠµë‹ˆë‹¤.\nì½”ë“œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  import pygame pygame.init() BLACK = (0,0,0) WHITE = (255,255,255) BLUE = (0,0,255) GREEN = (0,255,0) RED = (255,0,0) size = [400,300] screen = pygame.display.set_mode(size) pygame.display.set_caption(\u0026#39;Game Title\u0026#39;) done = False clock = pygame.time.Clock() while not done: clock.tick(10) for event in pygame.event.get(): if event.type == pygame.QUIT: done = True screen.fill(WHITE) pygame.draw.polygon(screen, GREEN, [[30,150], [125,100], [220,150]], 5) pygame.draw.polygon(screen, GREEN, [[30,150], [125,100], [220,150]],0) pygame.draw.lines(screen, RED,False, [[50,150], [50,250], [200,250], [200,150]],5) pygame.draw.rect(screen, BLACK, [75,175,75,50],5) pygame.draw.rect(screen, BLUE, [75,175,75,50],0) pygame.draw.line(screen, BLACK, [112,175], [112,225],5) pygame.draw.line(screen, BLACK, [75,200], [150,200],5) pygame.display.flip() #ì¶œì²˜: https://kkamikoon.tistory.com/129   ê²°ê³¼ë¬¼ ","description":"pygame ê¸°ì´ˆ","id":41,"section":"posts","tags":null,"title":"pygame[ê¸°ì´ˆ]","uri":"https://jiwooblog.netlify.app/posts/python/pygame_1/"},{"content":"ì˜¤ì°¨ \u0026amp; ì”ì°¨  ì˜¤ì°¨(error): ëª¨ì§‘ë‹¨ íšŒê·€ì‹ ì˜ˆì¸¡ê°’ - ì‹¤ì œ ê´€ì¸¡ê°’ ì”ì°¨(residual): í‘œë³¸ì§‘ë‹¨ íšŒê·€ì‹ ì˜ˆì¸¡ê°’ - ì‹¤ì œ ê´€ì¸¡ê°’  ","description":"ì˜¤ì°¨ì™€ ì”ì°¨ì˜ ì°¨ì´","id":42,"section":"posts","tags":null,"title":"ì˜¤ì°¨ì™€ ì”ì°¨","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/error_residual/"},{"content":"êµ­ë‚´/í•´ì™¸ ì§€ìˆ˜ ë° í™˜ìœ¨ 1ì›” ë„·ì§¸ì£¼    INDEX 1.18(ì›”) 1.19(í™”)     ì½”ìŠ¤í”¼ 3013.93 â–¼71.97(2.33%) 3092.66 â–²78.73(2.61%)   ì½”ìŠ¤ë‹¥ 944.67 â–¼19.77(2.05%) 957.75 â–²13.08(1.38%)   S\u0026amp;P500 3768.25 â–¼27.29(0.72%) 3768.25 â–¼27.27(0.72%)   ë‚˜ìŠ¤ë‹¥ 12998.50 â–¼114.14(0.87%) 12998.50 â–¼114.14(0.87%)   í™˜ìœ¨ 1103.90 â–²4.50(0.41%) 1102.90 â–¼1.00(0.09%)    1ì›” ì…‹ì§¸ì£¼ 1.15(ê¸ˆ) ì˜¤í›„ 10:36 ê¸°ì¤€    INDEX VALUE Change Rate     ì½”ìŠ¤í”¼ 3085.90 â–¼64.03(2.03%)   ì½”ìŠ¤ë‹¥ 964.44 â–¼15..85(1.62%)   S\u0026amp;P500 3795.54 â–¼14.30(0.38%)   ë‚˜ìŠ¤ë‹¥ 13112.65 â–¼16.31(0.12%)   í™˜ìœ¨ 1099.40 â–²1.40(0.13%)    ","description":"","id":43,"section":"updates","tags":null,"title":"ì£¼ì‹","uri":"https://jiwooblog.netlify.app/updates/stock/"},{"content":"Part 3. APIëŠ” ë¬´ì—‡ì¸ê°€ ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. API ì •ì˜  Application Programming Interface ë‘ ê°œì˜ ì‹œìŠ¤í…œì´ ì„œë¡œ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ ì¸í„°í˜ì´ìŠ¤(ë°ì´í„° ì£¼ê³  ë°›ê¸°!) ì¼ë°˜ì ìœ¼ë¡œ APIëŠ” REST APIë¥¼ ì§€ì¹­í•œë‹¤. ex) Web API: ì›¹ì„ í†µí•´ ì™¸ë¶€ ì„œë¹„ìŠ¤ë“¤ë¡œë¶€í„° ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” API  2. API ì ‘ê·¼ ê¶Œí•œ  Authentication: Identityê°€ ë§ë‹¤ëŠ” ì¦ëª… Authorization: APIë¥¼ í†µí•œ ì–´ë– í•œ ì•¡ì…˜ì„ í—ˆìš© ë‘˜ì€ ë‹¤ë¥´ë‹¤! Athenticationì„ í•˜ì˜€ë‹¤ê³  í•˜ë”ë¼ë„ Authorizationì„ í—ˆìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤! Security ì´ìŠˆê°€ ì¤‘ìš”í•˜ë‹¤.  API Key?  ë³´í†µ Request URL í˜¹ì€ Request Headerì— í¬í•¨ë˜ëŠ” ê¸´ ìŠ¤íŠ¸ë§ ex) Google Maps Platform \u0026gt; Geocoding API  https://maps.googleapis.com/maps/api/geocode/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA\u0026amp;key=YOUR_API_KEY ì—¬ê¸°ì„œ YOUR_API-KEY ì´ë¶€ë¶„ì„ ì±„ì›Œì£¼ì§€ ì•Šìœ¼ë©´, request deniedê°€ ëœ¨ê²Œ ëœë‹¤.    Baisc Auth  username:passwordì™€ ê°™ì€ credentialì„ Base64ë¡œ ì¸ì½”ë”©í•œ ê°’ì„ Request Header ì•ˆì— í¬í•¨  OAuth 2.0  End User \u0026lt;=\u0026gt; My App \u0026lt;=\u0026gt; Server(ex. Spotify) (1) Appì—ì„œ End Userí•œí…Œ ìƒì¼, ì „í™”ë²ˆí˜¸, í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì™€ ê°™ì€ ì •ë³´ë¥¼ ê°€ì ¸ê°€ëŠ” ê²ƒì— ëŒ€í•´ì„œ ë™ì˜ë¥¼ ë°›ëŠ”ë‹¤. (2) ë™ì˜ì„œë¥¼ ë°›ì•„ì™”ìœ¼ë‹ˆ Serverí•œí…Œ API ìš”ì²­ì„ í•˜ê³  ê·¸ì— ë§ëŠ” ë°ì´í„°ë¥¼ ìš”êµ¬í•œë‹¤.  3. Spotify Web API  Spotify ì§ì ‘ ë°©ë¬¸í•´ë³´ê¸°  4. Endpoints \u0026amp; Methods  Resource: APIë¥¼ í†µí•´ ë¦¬í„´ëœ ì •ë³´ Endpoint: Resource ì•ˆì—ëŠ” ì—¬ëŸ¬ ê°œì˜ Endpointsê°€ ì¡´ì¬ Method: ìì› ì ‘ê·¼ì— í—ˆìš©ëœ í–‰ìœ„(GET, POST, PUT, DELETE)     Method Action     GET í•´ë‹¹ ë¦¬ì†ŒìŠ¤ë¥¼ ì¡°íšŒí•˜ê³  ì •ë³´ë¥¼ ê°€ì ¸ì˜¨ë‹¤.   HEAD ì‘ë‹µì½”ë“œì™€ HEADë§Œ ê°€ì ¸ì˜¨ë‹¤.   POST ìš”ì²­ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•œë‹¤.   PUT ìš”ì²­ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ì—…ë°ì´íŠ¸ í•œë‹¤.   DELETE ìš”ì²­ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ì‚­ì œí•œë‹¤.    5. Parameters  Parameters: Endpointë¥¼ í†µí•´ Requestí•  ë•Œ ê°™ì´ ì „ë‹¬í•˜ëŠ” ì˜µì…˜ë“¤     Type ë‚´ìš©     Header Request Headerì— í¬í•¨. ì£¼ë¡œ Authorizationì— ê´€ë ¨   Path Query String(?) ì´ì „ì— Endpoint Path ì•ˆì— í¬í•¨. ex) id   Query String Query STring(?) ì´í›„ì— í¬í•¨. ex) ?utm_source=facebook\u0026amp;\u0026hellip;   Request Body Request Body ì•ˆì— í¬í•¨. ì£¼ë¡œ JSON í˜•íƒœ    \n","description":"APIëŠ” ë¬´ì—‡ì¸ê°€","id":44,"section":"posts","tags":null,"title":"API","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part3_1/"},{"content":"Chapter 03. One-parameter Models ë³¸ í¬ìŠ¤íŒ…ì€ First Course in Bayesian Statistical Methodsë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.\nBinomial Model Prior: $\\theta \\text{ ~ } Beta(a,b)$\nLikelihood: $Y|\\theta \\text{ ~ } Binomial(n, \\theta) $\nPosterior: $\\theta|y \\text{ ~ } Beta(a+y, b+n-y) $ a: prior ì„±ê³µíšŸìˆ˜, b: prior ì‹¤íŒ¨íšŸìˆ˜, $\\omega$=a+b: concentration $E[\\theta|y] = \\frac{a+y}{a+b+n} = \\frac{n}{a+b+n}\\times\\frac{y}{n} + \\frac{a+b}{a+b+n}\\times\\frac{a}{a+b}$ where $\\frac{y}{n}$ = sample mean, $\\frac{a}{a+b}$ = prior expectation Posterior Predictive\n$n^* = 1$ì¼ ë•Œ : $\\tilde{Y}|y \\text{ ~ } Ber(\\frac{a+y}{a+b+n})$\n$n^* \\geq 2$ì¼ ë•Œ : $p(\\tilde{Y}=y^*|y) = \\binom{n^*}{y^*}\\frac{B(a+y+y^*, b+n+n^*-y-y^*)}{B(a+y, b+n-y)}$ where $B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)} $\nPoisson Model Prior: $\\theta \\text{ ~ } Gamma(a,b) $\nLikelihood: $Y_1, ..., Y_n \\text{ ~ iid. } Poisson(\\theta)$\nPosterior: $\\theta|y_1, ..., y_n \\text{ ~ } Gamma(a+\\sum_{i=1}^{n}{y_i}, b+n) $ a: sum of counts from b prior observations, b: number of prior observations $E[\\theta|y_1, ..., y_n] = \\frac{a+\\sum y_i}{b+n} = \\frac{b}{b+n}\\frac{a}{b} + \\frac{n}{b+n}\\frac{\\sum y_i}{n}$ Posterior Predictive: $\\tilde{Y}=y^*|y_1, ..., y_n \\text{ ~ } NB(a+\\sum y_i+y^*, \\frac{b+n}{b+n+1}) $\në‹¨, ì—¬ê¸°ì„œ $Negative Binomial$ì€ ì„±ê³µì´ ì•„ë‹Œ ì‹¤íŒ¨íšŸìˆ˜ë¥¼ ì„¸ëŠ” ë¶„í¬ í˜•íƒœì´ë‹¤. ìì„¸í•œ ë‚´ìš©ì€ í™•ë¥ ë¶„í¬ í¬ìŠ¤íŒ…ì—ì„œ í™•ì¸í•˜ì.\nExponential Family exponential family(ì§€ìˆ˜ì¡±)ì˜ pdf ë˜ëŠ” pmfëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.\n$ p(y_i|\\phi) = h(y)c(\\phi)exp\\big[\\phi K(y)\\big]$\nexponential family ìì²´ì— ëŒ€í•´ì„œ ë³´ë‹¤ ìì„¸í•œ ê²ƒì€ í•´ë‹¹ í¬ìŠ¤íŒ…ì„ ì°¸ê³ í•˜ì.\nPrior\n$$\\begin{align}\rp(\\phi) \u0026amp;= k(n_0, t_0)c(\\phi)^n_0e^{n_0t_0\\phi} \\\\\r\u0026amp;\\propto c(\\phi)^n_0e^{n_0t_0\\phi}\r\\end{align}$$\nLikelihood\n$$L(\\phi|y_1,...,y_n) \\propto c(\\phi)^n exp(\\phi \\sum_{i=1}^{n}K(y_i))$$\nPosterior\n$$\\begin{align}\rp(\\phi|y) \u0026amp;\\propto p(\\phi)f(y|\\phi) \\\\\r\u0026amp;\\propto c(\\phi)^{n_0}e^{n_0t_0\\phi} \\cdot c(\\phi)^n exp(\\phi \\sum_{i=1}^{n}K(y_i)) \\\\\r\u0026amp;\\propto c(\\phi)^{n_0}exp\\big[n_0t_0\\phi + \\phi \\sum_{i=1}^{n}K(y_i) \\big] \\\\\r\u0026amp;\\propto c(\\phi)^{n_0}exp\\big[ \\phi \\big( n_0t_0 + n\\frac{\\sum_{i=1}^{n}K(y_i)}{n} \\big)\\big]\r\\end{align}$$\nì—¬ê¸°ì„œ $n_0$ì™€ $t_0$ì€ ê°ê° prior sample sizeì™€ prior guess of $K(Y)$ë¥¼ ëœ»í•œë‹¤.\n  ì°¸ê³ : FCB ì±… í‘œí˜„  Prior: $p(\\theta) \\propto g(\\theta)^\\eta \\ exp(\\phi(\\theta)^T \\ \\nu)$\nLikelihood: $p(y|\\theta) = \\prod_{i=1}^{N} f(y_i) \\ g(\\theta)^N \\ exp(\\phi(\\theta)^T \\ \\sum_{i=1}^{N}s(y_i))$ where $\\sum_{i=1}^{N}s(y_i))$ is sufficient statistics $t(y)$\nPosterior: $p(\\theta|y) \\propto g(\\theta)^{\\eta+N} \\ exp(\\phi(\\theta)^T \\ (\\nu + t(y)) $   Conjugate Prior priorì™€ posteriorì˜ í™•ë¥ ë¶„í¬í˜•íƒœê°€ ê°™ì„ ìˆ˜ ìˆë„ë¡ priorì„ ì„¤ì •í•˜ë©´ ì´ë¥¼ conjugate priorë¼ê³  í•œë‹¤.\nìœ„ì˜ ì˜ˆì‹œ ì™¸ì—ë„ Normal model ë“±ì´ ìˆëŠ”ë°, ì´ë“¤ì— ëŒ€í•´ì„œëŠ” ë‹¤ìŒì— ì´ì–´ì„œ ì‚´í´ë³´ë„ë¡ í•˜ê² ë‹¤.\në‹¤ì–‘í•œ ì˜ˆì‹œë“¤ì€ ìœ„í‚¤ë°±ê³¼ì— ìì„¸íˆ ë‚˜ì™€ìˆìœ¼ë‹ˆ ê¶ê¸ˆí•œ ì‚¬ëŒë“¤ì€ ì¶”ê°€ì ìœ¼ë¡œ ì‚´í´ë³´ì•„ë„ ì¢‹ê² ë‹¤.\nì£¼ì˜ì‚¬í•­ ì‚¬í›„í™•ë¥ ë¶„í¬ê°€ ì°¨ì´ê°€ ë§ì´ ë‚˜ëŠ” ê²ƒê³¼ ì‚¬í›„ì˜ˆì¸¡ì¹˜ê°€ ì°¨ì´ê°€ ë§ì´ ë‚˜ëŠ” ê²ƒì˜ ì°¨ì´ë¥¼ ì•Œì•„ë‘ì–´ì•¼ í•œë‹¤. ì¦‰, {${\\theta_1 \u0026gt; \\theta_2}$}ì™€ {$\\tilde{Y_1} \u0026gt; \\tilde{Y_2}$}ëŠ” ë‹¤ë¥´ë‹¤.\n Strong evidence of a difference between two populations does not mean that the difference itself is large.\n Conclusion Conjugacyë¥¼ ì˜ ì•Œì•„ë‘ì. í˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"One-parameter Models","id":45,"section":"posts","tags":null,"title":"Conjugacy","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/fcb03/"},{"content":"base í•¨ìˆ˜ ì¤‘ ìœ ìš©í•œ í•¨ìˆ˜ í›‘ì–´ë³´ê¸° 1 2  library(tidyverse) library(palmerpenguins)   1. split   split ì˜ˆì‹œ  1 2 3 4 5 6 7 8 9  #1colê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬ penguins %\u0026gt;% split(.$species) -\u0026gt; split1 #2colê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬ penguins %\u0026gt;% split(list(.$species, .$island)) -\u0026gt; split2 #10rowê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬(rowê°œìˆ˜ ì•ˆë§ìœ¼ë©´ error) splitrow \u0026lt;- rep(1:35, c(rep(10, 34), 4)) splitrow   ## [1] 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3\r## [26] 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5\r## [51] 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8\r## [76] 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10\r## [101] 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13\r## [126] 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15\r## [151] 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18\r## [176] 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20\r## [201] 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23\r## [226] 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25\r## [251] 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28\r## [276] 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30\r## [301] 31 31 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33\r## [326] 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34 35 35 35 35\r1  nrow(penguins)   ## [1] 344\r1  penguins %\u0026gt;% split(splitrow) -\u0026gt; split3      ","description":"","id":46,"section":"posts","tags":null,"title":"base","uri":"https://jiwooblog.netlify.app/posts/r/base/"},{"content":"Pygame ì‘ìš© ë³¸ í¬ìŠ¤íŒ…ì€ í•´ë‹¹ ì˜ìƒì„ ì ê·¹ì°¸ê³  í•˜ì˜€ìŠµë‹ˆë‹¤.\nì½”ë“œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282  import os import pygame ############################################################################## # ê¸°ë³¸ ì´ˆê¸°í™” (ë°˜ë“œì‹œ í•´ì•¼ í•˜ëŠ” ê²ƒë“¤) pygame.init() # ì´ˆê¸°í™” # í™”ë©´ í¬ê¸° ì„¤ì • screen_width = 640 # ê°€ë¡œ í¬ê¸° screen_height = 480 # ì„¸ë¡œ í¬ê¸° screen = pygame.display.set_mode((screen_width, screen_height)) # í™”ë©´ íƒ€ì´í‹€ ì„¤ì • pygame.display.set_caption(\u0026#39;Jiwoo Pang\u0026#39;) # FPS clock = pygame.time.Clock() ############################################################################## # 1. ì‚¬ìš©ì ê²Œì„ ì´ˆê¸°í™” (ë°°ê²½í™”ë©´, ê²Œì„ ì´ë¯¸ì§€, ì¢Œí‘œ, ì†ë„, í°íŠ¸ ë“±) current_path = os.path.dirname(__file__) # í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ ë°˜í™˜ image_path = os.path.join(current_path, \u0026#39;images\u0026#39;) # images í´ë” ìœ„ì¹˜ ë°˜í™˜ # ë°°ê²½ ë§Œë“¤ê¸° background = pygame.image.load(os.path.join(image_path, \u0026#39;game_background.jpg\u0026#39;)) # ìŠ¤í…Œì´ì§€ ë§Œë“¤ê¸° stage = pygame.image.load(os.path.join(image_path, \u0026#39;stage.png\u0026#39;)) stage_size = stage.get_rect().size stage_height = stage_size[1] # ìŠ¤í…Œì´ì§€ ë†’ì´ ìœ„ì— ìºë¦­í„°ë¥¼ ë‘ê¸° ìœ„í•´ ì‚¬ìš© # ìºë¦­í„° ë§Œë“¤ê¸° character = pygame.image.load(os.path.join(image_path, \u0026#39;cat.png\u0026#39;)) character_size = character.get_rect().size character_width = character_size[0] character_height = character_size[1] character_x_pos = (screen_width/2) - (character_width/2) character_y_pos = screen_height - character_height - stage_height # ìºë¦­í„° ì´ë™ ë°©í–¥ character_to_x = 0 # ìºë¦­í„°ì´ë™ ì†ë„ character_speed = 5 # ë¬´ê¸° ë§Œë“¤ê¸°  weapon = pygame.image.load(os.path.join(image_path, \u0026#39;weapon.png\u0026#39;)) weapon_size = weapon.get_rect().size weapon_width = weapon_size[0] # ë¬´ê¸°ëŠ” í•œ ë²ˆì— ì—¬ëŸ¬ë°œ ë°œ ì‚¬ ê°€ëŠ¥ weapons = [] # ë¬´ê¸° ì´ë™ ì†ë„ weapon_speed = 10 # ê³µ ë§Œë“¤ê¸° (4ê°œ í¬ê¸°ì— ëŒ€í•´ ë”°ë¡œ ì²˜ë¦¬) ball_images = [ pygame.image.load(os.path.join(image_path, \u0026#39;balloon1.png\u0026#39;)), pygame.image.load(os.path.join(image_path, \u0026#39;balloon2.png\u0026#39;)), pygame.image.load(os.path.join(image_path, \u0026#39;balloon3.png\u0026#39;)), pygame.image.load(os.path.join(image_path, \u0026#39;balloon4.png\u0026#39;))] # ê³µ í¬ê¸°ì— ë”°ë¥¸ ìµœì´ˆ ìŠ¤í”¼ë“œ ball_speed_y = [-18, -15, -12, -9] # ê³µë“¤  balls = [] # ìµœì´ˆ ë°œìƒí•˜ëŠ” í° ê³µ ì¶”ê°€ balls.append({ \u0026#39;pos_x\u0026#39; : 50, # ê³µì˜ xì¢Œí‘œ \u0026#39;pos_y\u0026#39; : 50, # ê³µì˜ yì¢Œí‘œ \u0026#39;img_idx\u0026#39; : 0, # ê³µì˜ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ \u0026#39;to_x\u0026#39; : 3, # xì¶• ì´ë™ë°©í–¥  \u0026#39;to_y\u0026#39; : -6, # yì¶• ì´ë™ë°©í–¥ \u0026#39;init_spd_y\u0026#39; : ball_speed_y[0]}) # y ìµœì´ˆ ì†ë„ # ì‚¬ë¼ì§ˆ ë¬´ê¸°, ê³µ ì •ë³´ ì €ì¥ ë³€ìˆ˜ weapon_to_remove = -1 ball_to_remove = -1 # í°íŠ¸ ì •ì˜ game_font = pygame.font.Font(None, 40) total_time = 100 start_ticks = pygame.time.get_ticks() # ì‹œì‘ ì‹œê°„ ì •ì˜ # ê²Œì„ ì¢…ë£Œ ë©”ì„¸ì§€ game_result = \u0026#39;Game Over\u0026#39; running = True while running: dt = clock.tick(30) # 2. ì´ë²¤íŠ¸ ì²˜ë¦¬ (í‚¤ë³´ë“œ. ë§ˆìš°ìŠ¤ ë“±) for event in pygame.event.get(): if event.type == pygame.QUIT: running = False if event.type == pygame.KEYDOWN: if event.key == pygame.K_LEFT: character_to_x -= character_speed elif event.key == pygame.K_RIGHT: character_to_x += character_speed elif event.key == pygame.K_SPACE: # ë¬´ê¸° ë°œì‚¬ weapon_x_pos = character_x_pos + (character_width / 2) - (weapon_width / 2) weapon_y_pos = character_y_pos weapons.append([weapon_x_pos, weapon_y_pos]) if event.type == pygame.KEYUP: if event.key == pygame.K_LEFT or event.key == pygame.K_RIGHT: character_to_x = 0 # 3. ê²Œì„ ìºë¦­í„° ìœ„ì¹˜ ì •ì˜ character_x_pos += character_to_x if character_x_pos \u0026lt; 0: character_x_pos = 0 elif character_x_pos \u0026gt; screen_width - character_width: character_x_pos = screen_width - character_width # ë¬´ê¸° ìœ„ì¹˜ ì¡°ì • weapons = [ [w[0], w[1] - weapon_speed] for w in weapons] # ë¬´ê¸° ìœ„ì¹˜ë¥¼ ìœ„ë¡œ # ì²œì¥ì— ë‹¿ì€ ë¬´ê¸° ì—†ì• ê¸° weapons = [ [w[0], w[1]] for w in weapons if w[1] \u0026gt; 0] # ê³µ ìœ„ì¹˜ ì •ì˜ for ball_idx, ball_val in enumerate(balls): ball_pos_x = ball_val[\u0026#39;pos_x\u0026#39;] ball_pos_y = ball_val[\u0026#39;pos_y\u0026#39;] ball_img_idx = ball_val[\u0026#39;img_idx\u0026#39;] ball_size = ball_images[ball_img_idx].get_rect().size ball_width = ball_size[0] ball_height = ball_size[1] # ê°€ë¡œë²½ì— ë‹¿ì•˜ì„ ë•Œ ê³µ ì´ë™ ìœ„ì¹˜ ë³€ê²½ (íŠ•ê²¨ë‚˜ì˜¤ëŠ” íš¨ê³¼) if ball_pos_x \u0026lt; 0 or ball_pos_x \u0026gt; screen_width - ball_width: ball_val[\u0026#39;to_x\u0026#39;] = ball_val[\u0026#39;to_x\u0026#39;] * (-1) # ì„¸ë¡œ ìœ„ì¹˜ # ìŠ¤í…Œì´ì§€ì— íŠ•ê²¨ì„œ ì˜¬ë¼ê°€ëŠ” ì²˜ë¦¬ if ball_pos_y \u0026gt;= screen_height - stage_height - ball_height: ball_val[\u0026#39;to_y\u0026#39;] = ball_val[\u0026#39;init_spd_y\u0026#39;] else: # ê·¸ì™¸ì˜ ëª¨ë“  ê²½ìš°ì—ëŠ” ì†ë„ë¥¼ ì¦ê°€ ball_val[\u0026#39;to_y\u0026#39;] += 0.5 ball_val[\u0026#39;pos_x\u0026#39;] += ball_val[\u0026#39;to_x\u0026#39;] ball_val[\u0026#39;pos_y\u0026#39;] += ball_val[\u0026#39;to_y\u0026#39;] # 4. ì¶©ëŒ ì²˜ë¦¬ # ìºë¦­í„° rect ì •ë³´ ì—…ë°ì´íŠ¸ character_rect = character.get_rect() character_rect.left = character_x_pos character_rect.top = character_y_pos for ball_idx, ball_val in enumerate(balls): ball_pos_x = ball_val[\u0026#39;pos_x\u0026#39;] ball_pos_y = ball_val[\u0026#39;pos_y\u0026#39;] ball_img_idx = ball_val[\u0026#39;img_idx\u0026#39;] # ê³µ rect ì •ë³´ ì—…ë°ì´íŠ¸ ball_rect = ball_images[ball_img_idx].get_rect() ball_rect.left = ball_pos_x ball_rect.top = ball_pos_y # ê³µê³¼ ìºë¦­í„° ì¶©ëŒ ì²˜ë¦¬ if character_rect.colliderect(ball_rect): running = False break # ê³µê³¼ ë¬´ê¸°ë“¤ ì¶©ëŒ ì²˜ë¦¬ for weapon_idx, weapon_val in enumerate(weapons): weapon_pos_x = weapon_val[0] weapon_pos_y = weapon_val[1] # ë¬´ê¸° rect ì •ë³´ ì—…ë°ì´íŠ¸ weapon_rect = weapon.get_rect() weapon_rect.left = weapon_pos_x weapon_rect.top = weapon_pos_y # ì¶©ëŒ ì²´í¬ if weapon_rect.colliderect(ball_rect): weapons_to_remove = weapon_idx # í•´ë‹¹ ë¬´ê¸° ì—†ì• ê¸° ìœ„í•œ ê°’ ì„¤ì • ball_to_remove = ball_idx if ball_img_idx \u0026lt; 3: # í˜„ì¬ ê³µ í¬ê¸° ì •ë³´ë¥¼ ê°€ì§€ê³  ì˜´ ball_width = ball_rect.size[0] ball_height = ball_rect.size[1] # ë‚˜ëˆ ì§„ ê³µ ì •ë³´ small_ball_rect = ball_images[ball_img_idx + 1].get_rect() small_ball_width = small_ball_rect.size[0] small_ball_height = small_ball_rect.size[1] # ì™¼ìª½ìœ¼ë¡œ íŠ•ê²¨ë‚˜ê°€ëŠ” ì‘ì€ ê³µ balls.append({ \u0026#39;pos_x\u0026#39; : ball_pos_x + (ball_width / 2) - (small_ball_width / 2), # ê³µì˜ xì¢Œí‘œ \u0026#39;pos_y\u0026#39; : ball_pos_y + (ball_height / 2) - (small_ball_height / 2), # ê³µì˜ yì¢Œí‘œ \u0026#39;img_idx\u0026#39; : ball_img_idx + 1, # ê³µì˜ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ \u0026#39;to_x\u0026#39; : -3, # xì¶• ì´ë™ë°©í–¥  \u0026#39;to_y\u0026#39; : -6, # yì¶• ì´ë™ë°©í–¥ \u0026#39;init_spd_y\u0026#39; : ball_speed_y[ball_img_idx + 1]}) # y ìµœì´ˆ ì†ë„ # ì˜¤ë¥¸ìª½ìœ¼ë¡œ íŠ•ê²¨ë‚˜ê°€ëŠ” ì‘ì€ ê³µ balls.append({ \u0026#39;pos_x\u0026#39; : ball_pos_x + (ball_width / 2) - (small_ball_width / 2), # ê³µì˜ xì¢Œí‘œ \u0026#39;pos_y\u0026#39; : ball_pos_y + (ball_height / 2) - (small_ball_height / 2), # ê³µì˜ yì¢Œí‘œ \u0026#39;img_idx\u0026#39; : ball_img_idx + 1, # ê³µì˜ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ \u0026#39;to_x\u0026#39; : 3, # xì¶• ì´ë™ë°©í–¥  \u0026#39;to_y\u0026#39; : -6, # yì¶• ì´ë™ë°©í–¥ \u0026#39;init_spd_y\u0026#39; : ball_speed_y[ball_img_idx + 1]}) # y ìµœì´ˆ ì†ë„  break else: # ê³„ì† ê²Œì„ì„ ì§„í–‰ continue # ì•ˆìª½ forë¬¸ ì¡°ê±´ì´ ë§ì§€ ì•Šìœ¼ë©´ continue. ë°”ê¹¥ forë¬¸ ê³„ì† ìˆ˜í–‰ break # ì•ˆìª½ forë¬¸ì—ì„œ breakë¥¼ ë§Œë‚˜ë©´ ì—¬ê¸°ë¡œ ì§„ì… ê°€ëŠ¥. 2ì¤‘ forë¬¸ì„ í•œë²ˆì— í†µê³¼í•˜ëŠ” íŠ¸ë¦­! # for ë°”ê¹¥ ì¡°ê±´: # ë°”ê¹¥ ë™ì‘ # for ì•ˆìª½ ì¡°ê±´: # ì•ˆìª½ ë™ì‘ # if ì¶©ëŒí•˜ë©´: # break # else: # continue # break # ì¶©ëŒëœ ê³µ or ë¬´ê¸° ì—†ì• ê¸° if ball_to_remove \u0026gt; -1: del balls[ball_to_remove] ball_to_remove = -1 if weapon_to_remove \u0026gt; -1: del weapons[weapon_to_remove] weapon_to_remove = -1 # ëª¨ë“  ê³µì„ ì—†ì•¤ ê²½ìš° ê²Œì„ ì¢…ë£Œ(ì„±ê³µ) if len(balls) == 0: game_result = \u0026#39;Mission Complete\u0026#39; running = False # 5. í™”ë©´ì— ê·¸ë¦¬ê¸° screen.blit(background, (0, 0)) for weapon_x_pos, weapon_y_pos in weapons: screen.blit(weapon, (weapon_x_pos, weapon_y_pos)) for idx, val in enumerate(balls): ball_pos_x = val[\u0026#39;pos_x\u0026#39;] ball_pos_y = val[\u0026#39;pos_y\u0026#39;] ball_img_dx = val[\u0026#39;img_idx\u0026#39;] screen.blit(ball_images[ball_img_idx], (ball_pos_x, ball_pos_y)) screen.blit(stage, (0, screen_height - stage_height)) screen.blit(character, (character_x_pos, character_y_pos)) # ê²½ê³¼ ì‹œê°„ ê³„ì‚° elapsed_time = (pygame.time.get_ticks() - start_ticks)/ 1000 timer = game_font.render(\u0026#39;Time: {}\u0026#39;.format(int(total_time - elapsed_time)), True, (255, 255, 255)) screen.blit(timer, (10, 10)) # ì‹œê°„ ì´ˆê³¼í–ˆë‹¤ë©´ if total_time - elapsed_time \u0026lt;= 0: game_result = \u0026#39;Time Over\u0026#39; running = False pygame.display.update() # ê²Œì„í™”ë©´ì„ ë‹¤ì‹œ ê·¸ë¦¬ê¸° # ê²Œì„ ì˜¤ë²„ ë©”ì„¸ì§€ msg = game_font.render(game_result, True, (255, 0, 0)) msg_rect = msg.get_rect(center=(int(screen_width/2), int(screen_height/2))) screen.blit(msg, msg_rect) pygame.display.update() # ì ì‹œ ëŒ€ê¸° pygame.time.delay(2000) # 2ì´ˆ ì •ë„ ëŒ€ê¸°(ms ë‹¨ìœ„) # pygame ì¢…ë£Œ pygame.quit()   ê²°ê³¼ë¬¼ ","description":"pygame ì‘ìš©","id":47,"section":"posts","tags":null,"title":"pygame[ì‘ìš©]","uri":"https://jiwooblog.netlify.app/posts/python/pygame_2/"},{"content":"Chapter 04. Monte Carlo Approximation ë³¸ í¬ìŠ¤íŒ…ì€ First Course in Bayesian Statistical Methodsë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.\nMonte Carlo Method Monte Carlo MethodëŠ” ì´ë¦„ì€ ê±°ì°½í•´ë³´ì´ì§€ë§Œ ì‚¬ì‹¤ ê·¸ ë°©ë²•ì€ ë§¤ìš° ê°„ë‹¨í•˜ë‹¤.\nìš°ì„ , ì‚¬í›„ë¶„í¬($p(\\theta|y_1,...,y_n)$)ë¡œë¶€í„° Sê°œì˜ random sampleì„ ë½‘ëŠ”ë‹¤.\n$$\\theta^{1}, \u0026hellip;, \\theta^{S} \\ \\stackrel{iid}{\\sim} \\ p(\\theta|y_1, \u0026hellip;, y_n) $$\nê·¸ëŸ¬ë©´ Sê°€ ì»¤ì§ˆìˆ˜ë¡ {$\\theta^{1}, ..., \\theta^{S}$}ëŠ” ê·¼ì‚¬ì ìœ¼ë¡œ ì‚¬í›„ë¶„í¬($p(\\theta|y_1,...,y_n)$)ë¥¼ ë”°ë¥¸ë‹¤.\nì´ë¥¼ í†µí•´ $E[\\theta|y_1, ..., y_n]$, $Var[\\theta|y_1, ..., y_n]$ë¶€í„° ì¤‘ì•™ê°’, $\\alpha$ percentile ë“±ì˜ í†µê³„ëŸ‰ê°’ë“¤ì„ ê·¼ì‚¬ì ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.\nì´ë•Œ approximate Monte Carlo Standard errorì€ $\\sqrt{\\hat{\\sigma}^2/S}$ì´ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì—, ê°€ë ¹ $E[\\theta|y_1, ..., y_n]$ì™€ Monte Carlo ì¶”ì •ì¹˜ì˜ ì°¨ì´ê°€ 0.01ì´í•˜ë¡œ í•˜ê³  ì‹¶ë‹¤ê³  í•œë‹¤ë©´, Monte Carlo Sample Sizeë¥¼ ì¡°ì •í•´ì£¼ë©´ ëœë‹¤. ì´ë•Œ ì˜ˆë¥¼ ë“¤ì–´ì„œ $\\hat{\\sigma}^2$ê°€ 0.024ë¼ê³  í•œë‹¤ë©´, Sample SizeëŠ” $2\\sqrt{0.024/S} \u0026lt; 0.01$ë¡œ ê³„ì‚°í•´ì„œ sampleì„ 960ê°œë³´ë‹¤ëŠ” ë§ì´ ë½‘ì•„ì•¼ í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.\nMonte Carlo Methodë¥¼ í™œìš©í•˜ë©´ ë‹¤ì–‘í•œ ê²ƒë“¤ì„ í•  ìˆ˜ ìˆëŠ”ë°, ê·¸ ëŒ€í‘œì ì¸ ì˜ˆì‹œë¡œ ì•„ë˜ ì„¸ ê°œë¥¼ ì´í•´í•´ë³´ì.\n1. Posterior Inference for Arbitrary Functions $\\theta$ ê·¸ ìì²´ê°€ ì•„ë‹ˆë¼ ì„ì˜ì˜ $f(\\theta)$ì˜ posterior distributionì´ ê¶ê¸ˆí•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ì„œ, log oddsì™€ ê°™ì€ ê²ƒ ë§ì´ë‹¤. í•˜ì§€ë§Œ ê²°êµ­ $\\gamma = f(\\theta)$ë„ $\\theta$ì²˜ëŸ¼ Monte Carlo Methodë¡œ ì‚¬í›„ë¶„í¬ì„ ì¶”ì •í•  ìˆ˜ ìˆë‹¤.\ní•˜ë‚˜ì˜ parameterë§Œ ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹¬ì§€ì–´ $Pr(\\theta_1 \u0026gt; \\theta_2 | Y_{1,1} = y_{1,1}, ..., Y_{n_2,2}=y_{n_2,2})$ë‚˜ $Pr(\\theta_1/\\theta_2 | Y_{1,1} = y_{1,1}, ..., Y_{n_2,2}=y_{n_2,2})$ì²˜ëŸ¼ parameterê°€ ë‘ ê°œì¸ ê²½ìš°ë„ êµ¬í•  ìˆ˜ ìˆë‹¤.\n2. Sampling from Predictive Distributions Step1. sample $\\theta^{(1)},...,\\theta^{(S)} \\text{ ~ i.i.d} \\ p(\\theta|y_1,...,y_n)$\nStep2. approximate $p(\\tilde{y}|y_1,...,.y_n)$ with $\\sum_{s=1}^{S}p(\\tilde{y}|\\theta^{(s)})/S$\nìœ„ ë°©ë²•ì„ í†µí•´ $Pr(\\tilde{Y_1}\u0026gt;\\tilde{Y_2}|\\sum Y_{i,1}=217,\\sum Y_{i,2}=66)$ë¥¼ ê·¼ì‚¬í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤. ì™œëƒí•˜ë©´ $Pr(\\tilde{Y_1})$ì™€ $Pr(\\tilde{Y_2})$ì€ posterior independentí•˜ê¸° ë•Œë¬¸ì´ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12  set.seed(1) a\u0026lt;-2 ; b\u0026lt;-1 sy1\u0026lt;-217 ; n1\u0026lt;-111 sy2\u0026lt;-66 ; n2\u0026lt;-44 theta1.mc\u0026lt;-rgamma(10000,a+sy1, b+n1) theta2.mc\u0026lt;-rgamma(10000,a+sy2, b+n2) y1.mc\u0026lt;-rpois(10000,theta1.mc) y2.mc\u0026lt;-rpois(10000,theta2.mc) mean(theta1.mc\u0026gt;theta2.mc)   ## [1] 0.9708\r1  mean(y1.mc\u0026gt;y2.mc)   ## [1] 0.4846\rìœ„ ê²°ê³¼ë¥¼ í†µí•´ì„œ ì£¼ì˜ê¹Šê²Œ ì‚´í´ë³´ì•„ì•¼ í•  ê²ƒì€, ì˜ˆì¸¡ì¹˜ì˜ ì°¨ì´ì™€ ëª¨ìˆ˜ì˜ ì°¨ì´ê°€ ê°™ì§€ ì•Šë‹¤ëŠ” ì ì´ë‹¤.\nì•„ë˜ ì„¸ ê°œ êµ¬ë¶„í•˜ê¸°  (1) sampling model: $Pr(\\tilde{Y}=\\tilde{y}|\\theta)$ (2) prior predictive model: $Pr(\\tilde{Y}=\\tilde{y})$  $\\theta$ì— ëŒ€í•œ ì‚¬ì „í™•ë¥ ë¶„í¬ê°€ ê´€ì¸¡ê°€ëŠ¥í•œ ë°ì´í„° $\\tilde{Y}$ì— ëŒ€í•´ í•©ë¦¬ì ì¸ ë¯¿ìŒì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ëŠ” ìš©ë„ë¡œ í™œìš©ê°€ëŠ¥í•˜ë‹¤.   (3) posterior predictive model: $Pr(\\tilde{Y}=\\tilde{y}|Y_1=y_1, ..., Y_n=y_n)$  3. Posterior Predictive Model Checking  We should at least make sure that our model generates predictive datasets $\\tilde{Y}$ that resemble the observed dataset in terms of features that are of interest\n   Code  1 2 3  load(\u0026#34;gss.RData\u0026#34;) table(gss$DEG[gss$YEAR==1998])   ## ## 0 1 2 3 4 ## 430 1500 209 478 205\r1 2 3 4 5 6  y1\u0026lt;-gss$PRAYER[gss$YEAR==1998 \u0026amp; gss$RELIG==1 ] y1\u0026lt;-1*(y1==1) y1\u0026lt;-y1[!is.na(y1) ] sy1\u0026lt;-sum(y1) n1\u0026lt;-length(y1) sy1/n1   ## [1] 0.3616803\r1 2 3 4 5 6  y2\u0026lt;-gss$PRAYER[gss$YEAR==1998 \u0026amp; gss$RELIG!=1 ] y2\u0026lt;-1*(y2==1) y2\u0026lt;-y2[!is.na(y2) ] sy2\u0026lt;-sum(y2) n2\u0026lt;-length(y2) sy2/n2   ## [1] 0.5471464\r1  table(gss$FEMALE[gss$YEAR==1998])   ## ## 0 1 ## 1232 1600\r1 2 3 4 5 6  y\u0026lt;-gss$FEMALE[gss$YEAR==1998] y\u0026lt;-1*(y==1) y\u0026lt;-y[!is.na(y) ] sy\u0026lt;-sum(y) n\u0026lt;-length(y) sy/n   ## [1] 0.5649718\r1 2 3  sy\u0026lt;-sy2 n\u0026lt;-n2 sy/n   ## [1] 0.5471464\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  #### MC approximations set.seed(1) a\u0026lt;-1 ; b\u0026lt;-1 theta.prior.sim\u0026lt;-rbeta(10000,a,b) gamma.prior.sim\u0026lt;- log( theta.prior.sim/(1-theta.prior.sim) ) n0\u0026lt;-860-441 ; n1\u0026lt;-441 theta.post.sim\u0026lt;-rbeta(10000,a+n1,b+n0) gamma.post.sim\u0026lt;- log( theta.post.sim/(1-theta.post.sim) ) par(mar=c(3,3,1,1),mgp=c(1.75,.75,0)) par(mfrow=c(2,3)) par(cex=.8) par(mfrow=c(1,2),mar=c(3,3,1,1), mgp=c(1.75,.75,.0)) plot(density(gamma.prior.sim,adj=2),xlim=c(-5,5),main=\u0026#34;\u0026#34;, xlab=expression(gamma), ylab=expression(italic(p(gamma))),col=\u0026#34;gray\u0026#34;) plot(density(gamma.post.sim,adj=2),xlim=c(-5,5),main=\u0026#34;\u0026#34;,xlab=expression(gamma), ylab=expression(paste(italic(\u0026#34;p(\u0026#34;),gamma,\u0026#34;|\u0026#34;,y[1],\u0026#34;...\u0026#34;,y[n],\u0026#34;)\u0026#34;, sep=\u0026#34;\u0026#34;)) ) lines(density(gamma.prior.sim,adj=2),col=\u0026#34;gray\u0026#34;)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  set.seed(1) a\u0026lt;-2 ; b\u0026lt;-1 sy1\u0026lt;-217 ; n1\u0026lt;-111 sy2\u0026lt;-66 ; n2\u0026lt;-44 theta1.mc\u0026lt;-rgamma(10000,a+sy1, b+n1) theta2.mc\u0026lt;-rgamma(10000,a+sy2, b+n2) y1.mc\u0026lt;-rpois(10000,theta1.mc) y2.mc\u0026lt;-rpois(10000,theta2.mc) #### Posterior predictive check  y1\u0026lt;-gss$CHILDS[gss$FEMALE==1 \u0026amp; gss$YEAR\u0026gt;=1990 \u0026amp; gss$AGE==40 \u0026amp; gss$DEG\u0026lt;3 ] y1\u0026lt;-y1[!is.na(y1)] set.seed(1) a\u0026lt;-2 ; b\u0026lt;-1 t.mc\u0026lt;-NULL for(s in 1:10000) { theta1\u0026lt;-rgamma(1,a+sum(y1), b+length(y1)) y1.mc\u0026lt;-rpois(length(y1),theta1) t.mc\u0026lt;-c(t.mc,sum(y1.mc==2)/sum(y1.mc==1)) } t.obs\u0026lt;-sum(y1==2)/sum(y1==1) mean(t.mc\u0026gt;=t.obs)   ## [1] 0.0049\r   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  par(mar=c(3,3,1,1),mgp=c(1.75,.75,0)) par(mfrow=c(1,2)) ecdf\u0026lt;-(table(c(y1,0:9))-1 )/sum(table(y1)) #ecdf.mc\u0026lt;-(table(c(y1.mc,0:9))-1 )/sum(table(y1.mc)) ecdf.mc\u0026lt;- dnbinom(0:9,size=a+sum(y1),mu=(a+sum(y1))/(b+length(y1))) plot(0:9+.1,ecdf.mc,type=\u0026#34;h\u0026#34;,lwd=5,xlab=\u0026#34;number of children\u0026#34;, ylab=expression(paste(\u0026#34;Pr(\u0026#34;,italic(Y[i]==y[i]),\u0026#34;)\u0026#34;,sep=\u0026#34;\u0026#34;)),col=\u0026#34;gray\u0026#34;, ylim=c(0,.35)) points(0:9-.1, ecdf,lwd=5,col=\u0026#34;black\u0026#34;,type=\u0026#34;h\u0026#34;) legend(1.8,.35, legend=c(\u0026#34;empirical distribution\u0026#34;,\u0026#34;predictive distribution\u0026#34;), lwd=c(2,2),col= c(\u0026#34;black\u0026#34;,\u0026#34;gray\u0026#34;),bty=\u0026#34;n\u0026#34;,cex=.8) hist(t.mc,prob=T,main=\u0026#34;\u0026#34;,ylab=\u0026#34;\u0026#34;,xlab=expression(t(tilde(Y))) ) segments(t.obs,0,t.obs,.25,col=\u0026#34;black\u0026#34;,lwd=3)   ì‹¤ì œ(empirical) ë¶„í¬ì™€ ì˜ˆì¸¡ ë¶„í¬ì˜ ëª¨ìŠµì´ ë‹¤ì†Œ ì°¨ì´ê°€ ë‚¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nì°¸ê³  [1] FCB code\ní˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"","id":48,"section":"posts","tags":null,"title":"Monte Carlo Method","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/fcb04/"},{"content":"Part 3. APIëŠ” ë¬´ì—‡ì¸ê°€ ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. Spotify App ìƒì„± ë° í† í° ë°œê¸‰ Client Credentials Flow 1 2 3 4 5  { \u0026#34;access_token\u0026#34;: \u0026#34;NgCXRKc...MzYjw\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34;, \u0026#34;expires_in\u0026#34;: 3600, }    client id, client secretì„ ì œê³µí•˜ë©´ ìš°ë¦¬ëŠ” 3600ì´ˆ, ì¦‰ 1ì‹œê°„ë™ì•ˆ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.  2. Python ê¸°ë³¸ 1 2 3 4 5 6 7 8 9 10 11  import sys def main(): print(\u0026#39;fastcampus\u0026#39;) #pythonìœ¼ë¡œ ì‹¤í–‰í–ˆì„ ë•Œ, í•´ë‹¹ pyíŒŒì¼ ì´ë¦„ì´ ì „ë‹¬ë˜ë©´, main()ì„ ì‹¤í–‰í•˜ë¼ if __name__ == \u0026#39;__main__\u0026#39;: main() #ì§ì ‘ pyíŒŒì¼ì´ ì‹¤í–‰ ì•ˆë˜ê³ , import spotify_apiì™€ ê°™ì´ ëª¨ë“ˆì²˜ëŸ¼ importë˜ë©´, ~~ë¥¼ printí•˜ë¼. else: print(\u0026#39;this script i being imported\u0026#39;)    WindowsëŠ” Windows Powershellì„ í†µí•´ì„œ ì§„í–‰í•˜ë©´ ëœë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ ìœ„ì²˜ëŸ¼ ì½”ë”©ì„ ì‹œì‘í•˜ê²Œ ëœë‹¤.  3. Python Requests íŒ¨í‚¤ì§€ requests python library \u0026gt; Developer Interface ì°¸ê³ í•˜ê¸°\npowershellì—ì„œ pip install requests ì‹¤í–‰í•˜ê¸°\n4. APIë¥¼ í†µí•œ ë°ì´í„° ìš”ì²­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  import sys import requests import base64 import json import logging client_id = \u0026#39;\u0026#39; # client_id ì…ë ¥ client_secret = \u0026#39;\u0026#39; # client_secret ì…ë ¥ def main(): headers = get_headers(client_id, client_secret) params = { \u0026#39;q\u0026#39;: \u0026#39;BTS\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;artist\u0026#39;, \u0026#39;limit\u0026#39;: 5 } r = requests.get(\u0026#39;https://api.spotify.com/v1/search\u0026#39;, params=params, headers=headers) # print(r.status_code) # 200ì´ë©´ ì´ìƒ ì—†ëŠ” ê²ƒ # print(r.text) # sys.exit(0) def get_headers(client_id, client_secret): # 1ì‹œê°„ë§Œ ìˆìœ¼ë©´ expireë˜ê¸° ë•Œë¬¸ì— ì¶”ê°€ë¡œ function í•˜ë‚˜ë¥¼ ë§Œë“¤ì–´ë‘ëŠ” ê²ƒì´ë‹¤. endpoint = \u0026#39;https://accounts.spotify.com/api/token\u0026#39; encoded = base64.b64encode(\u0026#34;{}:{}\u0026#34;.format(client_id, client_secret).encode(\u0026#39;utf-8\u0026#39;)).decode(\u0026#39;ascii\u0026#39;) headers = { \u0026#39;Authorization\u0026#39;: \u0026#39;Basic {}\u0026#39;.format(encoded) } payload = { \u0026#39;grant_type\u0026#39;: \u0026#39;client_credentials\u0026#39; } r = requests.post(endpoint, data=payload, headers=headers) # ì¤‘ê°„ì— ì˜ ë˜ëŠ”ì§€ í™•ì¸í•´ë³´ëŠ” ì½”ë“œ # print(r.status_code) # print(r.text) # print(type(r.text)) #stringìœ¼ë¡œ ì¶œë ¥ë˜ë¯€ë¡œ ì•„ë˜ì—ì„œ json.loadsë¥¼ í†µí•´ dictionaryë¡œ ë§Œë“¤ì–´ì¤˜ì•¼ í•œë‹¤. # sys.exit(0) access_token = json.loads(r.text)[\u0026#39;access_token\u0026#39;] headers = { \u0026#39;Authorization\u0026#39;: \u0026#34;Bearer {}\u0026#34;.format(access_token) } return headers if __name__ == \u0026#39;__main__\u0026#39;: main()   5. Status Code  Status Codeë¥¼ ì•Œì•„ì•¼ í•˜ëŠ” ì´ìœ : ë°ì´í„° ì—”ì§€ë‹ˆì–´ì˜ ì˜ëª»ì´ ì•„ë‹Œ, Spotify ì„œë²„ì˜ ì˜¤ë¥˜ ë“±ìœ¼ë¡œ ì¸í•œ ë¬¸ì œì¸ì§€ ì²´í¬í•  ìˆ˜ ìˆë‹¤. Spotify Web API ê¸°ì¤€ì´ì§€ë§Œ, RFC 2616ì™€ RFC 6585ì— ì˜í•´ ì¼ë°˜ì ìœ¼ë¡œ í†µìš©ë˜ëŠ” ê¸°ì¤€ì´ë‹¤.     STATUS CODE DESCRIPTION     200 OK - The request has succeeded. The client can read the result of the request in the body and the headers of the response.   201 Created - The request has been fulfilled and resulted in a new resource being created.   202 Accepted - The request has been accepted for processing, but the processing has not been completed.   204 No Content - The request has succeeded but returns no message body.   304 Not Modified. See Conditional requests.   400 Bad Request - The request could not be understood by the server due to malformed syntax. The message body will contain more information; see Response Schema.   401 Unauthorized - The request requires user authentication or, if the request included authorization credentials, authorization has been refused for those credentials.   403 Forbidden - The server understood the request, but is refusing to fulfill it.   404 Not Found - The requested resource could not be found. This error can be due to a temporary or permanent condition.   429 Too Many Requests - Rate limiting has been applied.   500 Internal Server Error. You should never receive this error because our clever coders catch them all â€¦ but if you are unlucky enough to get one, please report it to us through a comment at the bottom of this page.   502 Bad Gateway - The server was acting as a gateway or proxy and received an invalid response from the upstream server.   503 Service Unavailable - The server is currently unable to handle the request due to a temporary condition which will be alleviated after some delay. You can choose to resend the request again.    6. ì—ëŸ¬ í•¸ë“¤ë§ sys.exit(0)ê³¼ sys.exit(1) ì°¨ì´ 1 2 3 4  # í”„ë¡œê·¸ë¨ì„ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œì‹œí‚¤ê³  ì‹¶ì„ ë•Œ sys.exit(0) # í”„ë¡œê·¸ë¨ì„ ê°•ì œì ìœ¼ë¡œ ì¢…ë£Œì‹œí‚¤ê³  ì‹¶ì„ ë•Œ sys.exit(1)   Status Code 401, 409 ì—ëŸ¬ í•¸ë“¤ë§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  r = requests.get(\u0026#39;https://api.spotify.com/v1/search\u0026#39;, params=params, headers=headers) if r.status_code != 200: logging.error(r.text) ## Too many requests if r.status_code == 429: retry_after = json.loads(r.headers)[\u0026#39;Retry-After\u0026#39;] time.sleep(int(retry_after)) r = requests.get(\u0026#39;https://api.spotify.com/v1/search\u0026#39;, params=params, headers=headers) ## access_token expireed elif r.status_code == 401: headers = get_headers(client_id, client_secret) r = requests.get(\u0026#39;https://api.spotify.com/v1/search\u0026#39;, params=params, headers=headers) else: sys.exit(1) #ê°•ì œì¢…ë£Œ   7. í˜ì´ì§€ë„¤ì´ì…˜ í•¸ë“¤ë§ ì°¸ê³ ì‚¬ì´íŠ¸\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  import sys import requests import base64 import json import logging client_id = \u0026#39;\u0026#39; # client_id ì…ë ¥ client_secret = \u0026#39;\u0026#39; # client_secret ì…ë ¥ def main(): headers = get_headers(client_id, client_secret) # Get BTS\u0026#39; Albums r = requests.get(\u0026#39;https://api.spotify.com/v1/artists/3Nrfpe0tUJi4K4DXYWgMUX/albums\u0026#39;, headers=headers) raw = json.loads(r.text) # total = raw[\u0026#39;total\u0026#39;] # ì´ 104ê°œê°€ ìˆìŒì„ í™•ì¸ # offset = raw[\u0026#39;offset\u0026#39;] # ì‹œì‘ì€ 0 # limit = raw[\u0026#39;limit\u0026#39;] # 20ê°œì”© ë½‘ê² ë‹¤. next = raw[\u0026#39;next\u0026#39;] albums = [] albums.extend(raw[\u0026#39;items\u0026#39;]) ## ë‚œ 200ê°œë§Œ ë½‘ì•„ ì˜¤ê² ë‹¤. count = 0 while count \u0026lt; 200 and next: # while next: ë¼ê³ ë§Œ í•˜ë©´ ëê¹Œì§€ ê°€ì ¸ì˜¤ê²Œ ëœë‹¤. r = requests.get(raw[\u0026#39;next\u0026#39;], headers=headers) raw = json.loads(r.text) next = raw[\u0026#39;next\u0026#39;] # print(next) # ë§¨ ë§ˆì§€ë§‰ì—ëŠ” noneì´ ë‚˜ì˜¤ê²Œ ëœë‹¤. ì´ì— ëŒ€í•´ì„œëŠ” Spotify í˜ì´ì§€ë¥¼ ì°¸ê³ í•˜ë©´ ëœë‹¤. albums.extend(raw[\u0026#39;items\u0026#39;]) count = len(albums) print(len(albums)) def get_headers(client_id, client_secret): endpoint = \u0026#39;https://accounts.spotify.com/api/token\u0026#39; encoded = base64.b64encode(\u0026#34;{}:{}\u0026#34;.format(client_id, client_secret).encode(\u0026#39;utf-8\u0026#39;)).decode(\u0026#39;ascii\u0026#39;) headers = {\u0026#39;Authorization\u0026#39;: \u0026#39;Basic {}\u0026#39;.format(encoded)} payload = {\u0026#39;grant_type\u0026#39;: \u0026#39;client_credentials\u0026#39;} r = requests.post(endpoint, data=payload, headers=headers) access_token = json.loads(r.text)[\u0026#39;access_token\u0026#39;] headers = {\u0026#39;Authorization\u0026#39;: \u0026#34;Bearer {}\u0026#34;.format(access_token)} return headers if __name__ == \u0026#39;__main__\u0026#39;: main()   \n","description":"APIëŠ” ë¬´ì—‡ì¸ê°€","id":49,"section":"posts","tags":null,"title":"Spotify API","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part3_2/"},{"content":"Chapter 05. Normal Model ë³¸ í¬ìŠ¤íŒ…ì€ First Course in Bayesian Statistical Methodsì™€ Bayesian Data Analysisë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.\nWarm up!  Gamma Distribution Inverse Gamma Distribution Scaled Inverse Chi-squared Distribution  1. Single Parameter Conjugacy í‰ê· ì´ë‚˜ ë¶„ì‚° ì¤‘ í•˜ë‚˜ë§Œì„ ëª¨ë¥´ëŠ” ê²½ìš°\n1-1. í‰ê· ì„ ëª¨ë¥´ëŠ” ê²½ìš° Prior: $\\mu \\text{ ~ } N(\\mu_0, \\tau_0^{2})$\nLikelihood: $y|\\mu \\text{ ~ } N(\\mu, \\sigma^2)$\nPosterior: $\\mu|y \\text{ ~ } N(\\mu_n, \\tau_n^{2})$\nwhere $\\frac{1}{\\tau_n^{2}} = \\frac{1}{\\tau_0^{2}} + \\frac{n}{\\sigma^2}$ and $\\mu_n = \\frac{\\frac{1}{\\tau_0^{2}}}{\\frac{1}{\\tau_0^{2}} + \\frac{n}{\\sigma^2}}\\mu_0 + \\frac{\\frac{n}{\\sigma^2}}{\\frac{1}{\\tau_0^{2}} + \\frac{n}{\\sigma^2}}\\bar{y} $\nPosterior Predictive: $\\tilde{y}|y \\text{ ~ } N(\\mu_n, \\sigma^2+\\tau_n^{2})$\n1-2. ë¶„ì‚°ì„ ëª¨ë¥´ëŠ” ê²½ìš° Prior: $\\sigma^2 \\text{ ~ } \\chi^{-2}(\\nu_0, \\sigma_0^2)$\nLikelihood: $y|\\sigma^2 \\text{ ~ } N(\\mu, \\sigma^2)$ Posterior: $\\sigma^2|y \\text{ ~ } \\chi^{-2}(\\nu_n, \\sigma_n^2)$\nwhere $\\nu_n = \\nu_0 + n$ and $\\sigma_n^2 = \\frac{\\nu_0\\sigma_0^2 + ns(y)}{\\nu_0 + n}$\nc.f. $s(y) = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\mu)^2$, ì´ëŠ” MLEì´ë‹¤(biased estimator). ì°¸ê³ ë¡œ, ë² ì´ì§€ì•ˆì€ frequentistë“¤ì˜ ê¸°ì¤€ì¸ unbiasednessë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ì§€ ì•ŠëŠ”ë‹¤.\n2. Two Parameter marginal distribution ì–»ëŠ” ë‘ ê°€ì§€ ë°©ë²•  Integreation: joint posterior distributionì„ êµ¬í•œ í›„, ê´€ì‹¬ ì—†ëŠ” ëª¨ìˆ˜(nuisance parameter)ì— ëŒ€í•´ ì ë¶„ Simulation: joint posterior distributionì—ì„œ sampleì„ êµ¬í•œ í›„, ê´€ì‹¬ ìˆëŠ” ëª¨ìˆ˜ì˜ ë¶„í¬ë§Œ ê³ ë ¤(ë‚˜ë¨¸ì§€ëŠ” ë¬´ì‹œ)  ê·¸ë ‡ë‹¤ë©´ joint posterior distributionì€ ì–´ë–»ê²Œ êµ¬í• ê¹Œ?  marginal and conditional simulationì„ í†µí•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤.\n$\\theta_2 \\text{ ~ } \\theta_2|y$ and $\\theta_1 | \\theta_2, y$\n$\\rightarrow (\\theta_1, \\theta_2) \\text{ ~ } (\\theta_1, \\theta_2|y)$  2-1. noninformative prior Prior: $p(\\mu, \\sigma^2) = p(\\mu)p(\\sigma^2) \\propto (\\sigma^2)^{-1} $ (ë…ë¦½ ê°€ì •, improper prior)\nLikelihood: $p(y|\\mu, \\sigma^2) \\propto \\sigma^{-n}exp(\\frac{-1}{2}\\sigma^2\\sum_{i=1}^{n}(y_i - \\mu)^2) $\nPosterior: $\\mu, \\sigma^2 |y \\text{ ~ } N(\\bar{y}, \\frac{\\sigma^2}{n}) \\times \\chi^{-2}(n-1, s^2)$\nPosterior Predictive: $\\tilde{y}|y \\text{ ~ } t_{n-1}(\\bar{y}, (1+\\frac{1}{n}s^2))$\nì´ëŠ” posteriorê³¼ ë¹„êµí•´ì„œ, dataì˜ uncertainty($s^2$)ì´ ì¶”ê°€ëœ í˜•íƒœë¼ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤.\nPosterior Distribution êµ¬í•˜ê¸° (Noninformative) í•´ë‹¹ Posterior Distributionì„ êµ¬í•˜ëŠ” ê³¼ì •ì€ ë‹¤ì†Œ ë³µì¡í•˜ê¸° ë•Œë¬¸ì— ìì„¸í•˜ê²Œ ì„œìˆ í•´ë³´ë„ë¡ í•˜ê² ë‹¤.\nìš°ì„  ì‹œì‘í•˜ê¸°ì— ì•ì„œ, í•œë§ˆë””ë¡œ ì´ ê³¼ì •ì„ ìš”ì•…í•œë‹¤ë©´ Conditional Posterior X Marginalì¼ ê²ƒì´ë‹¤.\nSTEP1. $p(\\mu|\\sigma^2,y)$ $p(\\sigma^2|y)$ì˜ í˜•íƒœë¥¼ íŒŒì•…í•œë‹¤.\n  $\\mu|\\sigma^2,y \\text{ ~ } N(\\bar{y}, \\frac{\\sigma^2}{n})$\nì´ë¶€ë¶„ì€ ìœ„ì˜ í‰ê· ì„ ëª¨ë¥´ì§€ë§Œ, ë¶„ì‚°ì„ ì•„ëŠ” ê²½ìš°ì—ì„œ prior precision $\\frac{1}{\\tau^2}=0$ìœ¼ë¡œ ì£¼ë©´ ìœ„ì™€ ê°™ì´ ë‚˜ì˜¨ë‹¤. prior precisionì„ 0ìœ¼ë¡œ ì£¼ëŠ” ì´ìœ ëŠ”, non-informative priorë¥¼ ê°€ì •í•˜ê³  ìˆê¸° ë•Œë¬¸ì´ë‹¤.\n  $\\sigma^2|y \\text{ ~ } \\chi^{-2}(n-1, s^2)$\nì´ëŠ” ì•„ë˜ì˜ ìˆ˜ì‹ì„ ê³„ì‚°í•´ì„œ ì–»ì„ ìˆ˜ ìˆë‹¤.\n  \\begin{align}\rp(\\mu, \\sigma^2|y) \u0026amp;\\propto p(\\mu, \\sigma^2) \\times p(y|\\mu, \\sigma^2) \\\\\r\u0026amp;\\propto \\sigma^{-n-2}exp\\bigg(\\frac{-1}{2\\sigma^2}\\big[(n-1)s^2 + n(\\bar{y}-\\mu)^2\\big]\\bigg) \\\\\r\\rightarrow p(\\sigma^2|y) \u0026amp;= \\int p(\\mu,\\sigma^2|y)d\\mu \\end{align}\nSTEP2. ë² ì´ì¦ˆë£°ì„ ì´ìš©í•˜ì—¬ posterior distributionì„ ê³„ì‚°í•´ì¤€ë‹¤.\nìœ„ì˜ ê³¼ì •ì„ ê±°ì¹œë‹¤ë©´, ê·¸ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.\n\\begin{align}\r\\mu|\\sigma^2,y \u0026amp;\\text{ ~ } N(\\bar{y}, \\frac{\\sigma^2}{n}) \\\\\r\\sigma^2|y \u0026amp;\\text{ ~ } \\chi^{-2}(n-1, s^2) \\\\\r\\mu, \\sigma^2 |y \u0026amp;\\text{ ~ } N(\\bar{y}, \\frac{\\sigma^2}{n}) \\times \\chi^{-2}(n-1, s^2)\r\\end{align}\nPosterior Meanì˜ Marginal Distribution êµ¬í•˜ê¸° ë²ˆì™¸ë¡œ, $\\mu$ì˜ marginal posterior distribution $p(\\mu|y)$ì€ $\\int p(\\mu,\\sigma^2)d\\sigma^2$ë¥¼ í†µí•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  í˜•íƒœëŠ” ì•„ë˜ì™€ ê°™ë‹¤.\n$$p(\\mu|y) \\text{ ~ } t_{n-1}(\\bar{y}, \\frac{s^2}{n})$$\nPosterior Prediction êµ¬í•˜ëŠ” ê³¼ì • \\begin{align}\rp(\\tilde{y}|y) \u0026amp;= \\int\\int p(\\tilde{y}|\\mu,\\sigma^2) p(\\mu, \\sigma^2|y)\\ d\\mu \\ d\\sigma^2 \\\\\r\u0026amp;= \\int\\int p(\\tilde{y}|\\mu,\\sigma^2) \\ p(\\mu|\\sigma^2,y)\\ d\\mu \\cdot p(\\sigma^2|y) \\ d\\sigma^2 \\\\ \u0026amp;= \\int p(\\tilde{y}|\\sigma^2) \\ p(\\sigma^2|y) \\ d\\sigma^2\r\\end{align}\nPosterior Predictive: $\\tilde{y}|y \\text{ ~ } t_{n-1}(\\bar{y}, (1+\\frac{1}{n}s^2))$\nì´ ê²°ê³¼ë¥¼ ë°”ë¡œ ìœ„ì˜ Posterior Meanì˜ marginal ë¶„í¬ì™€ ë¹„êµí•´ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.\nì™œëƒí•˜ë©´ predictionì„ í•  ë•Œì— $s^2$, ì¦‰ uncertaintyê°€ ì¶”ê°€ëœë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.\nTwo parameter Normal modelì´ ì¤‘ìš”í•œ ì´ìœ ëŠ” ë‹¤ìŒ 3. Frequentistì™€ Bayesianì˜ ì°¨ì´ì„ ë³´ë©´ ëª…í™•í•˜ë‹¤. Frequentistì™€ Bayesianì˜ ê¸°ë³¸ì ì¸ ì „ì œì™€ ì…ì¥ ì°¨ì´ë¥¼ ì´í•´í•œë‹¤ë©´, ì •ë³´ê°€ ì—†ëŠ” priorê°€ ê²°êµ­ ì–´ë– í•œ ê²°ë¡ ìœ¼ë¡œ ì´ì–´ê°€ëŠ”ì§€ ì´í•´í•  ìˆ˜ ìˆë‹¤.\n2-2. conjugate prior Prior: $p(\\mu, \\sigma^2) = p(\\mu|\\sigma^2) \\times p(\\sigma_0^2) \\text{ ~ N-Inv-} \\chi^2(\\mu_0, \\frac{\\sigma^2}{k_0}; v_0, \\sigma_0^2)$\n\\begin{align}\r\\mu|\\sigma^2 \u0026amp;\\text{ ~ } N(\\mu_0, \\frac{\\sigma^2}{k_0}) \\\\\r\\sigma^2 \u0026amp;\\text{ ~ } \\chi^{-2}(v_0, \\sigma^2_0) \\\\\r\\rightarrow \\mu, \\sigma^2 \u0026amp;\\propto \\sigma^{-1}(\\sigma^2)^{-(\\frac{v_0}{2}+1)}exp\\bigg(\\frac{-1}{2\\sigma^2}\\big[v_0\\sigma_0^2 + k_0(\\mu_0 - \\mu)^2\\big]\\bigg)\r\\end{align}\nLikelihood: $p(y|\\mu, \\sigma^2) \\propto \\sigma^{-n}exp\\bigg(\\frac{-1}{2\\sigma^2}\\sum_{i=1}{n}(y_i-\\mu)^2\\bigg)$\nPosterior: $p(\\mu, \\sigma^2|y) \\text{ ~ N-Inv-}\\chi^2(\\mu_n, \\frac{\\sigma_n^2}{k_n}; v_n, \\sigma_n^2) $\n\\begin{align}\r\\mu_n \u0026amp;= \\frac{k_0}{k_0+n}\\mu_0 + \\frac{n}{k_0+n}\\bar{y} \\\\\rk_n \u0026amp;= k_0 +n \\\\\rv_n \u0026amp;= v_o + n \\\\\rv_n\\sigma_n^2 \u0026amp;= v_0\\sigma_0^2 + (n-1)s^2 + \\frac{k_0n}{k_0+n}(\\bar{y}-\\mu_0)^2 \\\\\r\\rightarrow \\text{posterior ss} \u0026amp;= \\text{prior ss} + \\text{sample ss} + \\text{additional uncertainty}(\\bar{y}-\\mu_0)\r\\end{align}\n3. Frequentistì™€ Bayesianì˜ ì°¨ì´ Frequentist: parameterë¥¼ ì•Œ ë•Œ, í†µê³„ëŸ‰ì˜ ë¶„í¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•œë‹¤.\nlet $y \\text{ ~ } N(\\mu, \\sigma^2)$\n $\\bar{y} \\text{ ~ } N(\\mu, \\frac{\\sigma^2}{n}) $ $\\frac{(n-1)s^2}{\\sigma^2} \\text{ ~ } \\chi^2(n-1)$ $\\frac{\\bar{y}-\\mu}{s/\\sqrt{n}}|\\mu,\\sigma^2 \\text{ ~ } t_{n-1}$  Bayesian: dataë¥¼ ì•Œ ë•Œ, parameterì˜ ë¶„í¬ì— ëŒ€í•´ ì´ì•¼ê¸°í•œë‹¤.\n $\\mu \\text{ ~ } N(\\bar{y}, \\frac{\\sigma^2}{n})$ $\\sigma^2 \\text{ ~ } \\chi^{-2}(n-1, s^2)$ $\\frac{\\mu-\\bar{y}}{s/\\sqrt{n}}|y \\text{ ~ } t_{n-1} $  ë§Œì•½ Bayesianì´ noninformative priorë¥¼ ê°€ì •í•œë‹¤ë©´, ì¦‰ priorê°€ ê±°ì˜ ì—†ë‹¤ê³  ìƒê°í•œë‹¤ë©´ frequetistë‘ ê²°ê³¼ê°€ ë¹„ìŠ·í•˜ê²Œ ë‚˜ì˜¤ëŠ” ê²ƒì€ ë‹¹ì—°í•˜ë‹¤.\n4. Multinomial Model Likelihood: $y|\\theta \\text{ ~ Multinomial}(\\theta) \\propto \\prod_{j=1}^{k}\\theta_j^{y_j}$\nPrior: $\\theta \\text{ ~ } Dir(\\alpha) \\propto \\prod_{j=1}^{k}\\theta_j^{\\alpha_j-1}$\nPosterior: $\\theta|y \\text{ ~ } Dir(\\alpha +y) \\propto \\prod_{j=1}^{k}\\theta_j^{\\alpha_j-y_j-1}$\nì°¸ê³ ë¡œ Multinomial distributionì€ ì´í•­ë¶„í¬ì˜ í™•ì¥ì´ë©°, Dirichlet distributionì€ ë² íƒ€ë¶„í¬ì˜ í™•ì¥ì´ë¼ê³  ìƒê°í•˜ë©´ ì‰½ë‹¤. ì™œëƒí•˜ë©´ Beta-Binomial ëª¨ë¸ì— ëŒ€í•´ì„œëŠ” Chapter3ì—ì„œ ì´ë¯¸ ì¶©ë¶„íˆ ë‹¤ë£¨ì—ˆê¸° ë•Œë¬¸ì´ë‹¤.\ní˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"Normal Model","id":50,"section":"posts","tags":null,"title":"Normal Model","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/fcb05/"},{"content":"Part 4. ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤ ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n0. Data Type  numeric data/time character/string unicode character/string binary miscellaneous  1. Relational Database(RDB)  ëª¨ë“  ë°ì´í„°ë¥¼ 2ì°¨ì›ì˜ í…Œì´ë¸”ë¡œ í‘œí˜„ í•˜ë‚˜ ì´ìƒì˜ í…Œì´ë¸”ë¡œ êµ¬ì„± Entity-Relationship ëª¨ë¸ Normalization (Reduce Redundacy)  2. AWS í´ë¼ìš°ë“œ MySQL ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±  aws.amazon.com \u0026gt; RDS \u0026gt; ë°ì´í„° ìƒì„± Templates \u0026gt; Free Tierë¡œ ì„¤ì • (ê³¼ê¸ˆ ì˜ˆë°©) Public Access í—ˆìš©í•˜ê¸° VPCì—ì„œ ì¸ë°”ìš´ë“œ ê·œì¹™ì— MySql ì¶”ê°€í•˜ê¸°  3. í„°ë¯¸ë„ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°í•˜ê¸° (Windows ê¸°ì¤€)\n mysql client workbench ë‹¤ìš´ë¡œë“œ MySQL Workbenchë‘ AWSë¥¼ ì—°ê²°í•˜ê³ , ê·¸ê²ƒì„ termianl(powershell)ë¡œ ì—°ê²°í•˜ëŠ” ë²• termianlì—ì„œ ì•„ë˜ì˜ ì»¤ë§¨ë“œë¥¼ ì‘ì„±í•˜ê³ , ì´ì–´ì„œ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ë©´ ëœë‹¤.  mysql -h {hostname} -P 3306 -D {Default Schema} -u {username} -p 4. MySQL ë°ì´í„°ë² ì´ìŠ¤ ì•ˆì—ì„œ í…Œì´ë¸” ìƒì„± 1 2  CREATE TABLE people (first_name VARCHAR(20), last_name VARCHAR(20), age INT); SHOW TABLES;   5. ì—”í„°í‹° ê´€ê³„ë„(ERD)  Entity Relationship Diagram ë°ì´í„° ëª¨ë¸ë§ ì„¤ê³„ ê³¼ì •ì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ì•½ì†ëœ ê¸°í˜¸ë¥¼ ì´ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ êµ¬ì¡°ë¥¼ ì‰½ê²Œ ì´í•´í•˜ê¸° ìœ„í•¨ì´ë‹¤.  ERDì˜ ê¸°ë³¸ìš”ì†Œ  Entities: ê°œì²´ Attributes: ì—”í„°í‹°ì˜ ì†ì„± Relationship: ì—”í„°í‹° ê°„ì˜ ê´€ê³„  6. Primary Key \u0026amp; Unique Key Primary Key  í…Œì´ë¸”ì— í•˜ë‚˜ ë°–ì— ì—†ëŠ” ìœ ë‹ˆí¬í•œ êµ¬ë³„ ê°’ Null ê°’ ì•ˆ ë¨  Foreign Key  í•œ ê°œ ì´ìƒ ê°€ëŠ¥ NULL ê°’ë„ ê°€ëŠ¥  Unique Key  Primary Keyì²˜ëŸ¼ ìœ ë‹ˆí¬í•˜ê¸´ í•˜ë‹¤. í•˜ì§€ë§Œ, Null ê°’ì€ í•˜ë‚˜ëŠ” ê°€ì§ˆ ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  í•˜ë‚˜ ì´ìƒì˜ ìœ ë‹ˆí¬ í‚¤ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆë‹¤. Primary Keyë³´ë‹¤ëŠ” indexë¡œì„œì˜ ì„±ëŠ¥ì€ ë‚®ë‹¤. ex) Primary Key: ìˆ˜í—˜ë²ˆí˜¸, Unique Key: ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸  ","description":"ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤","id":51,"section":"posts","tags":null,"title":"RDBMS","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part4_1/"},{"content":"Chapter 06. Posterior Approximation with the Gibbs sampler ë³¸ í¬ìŠ¤íŒ…ì€ First Course in Bayesian Statistical Methodsë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.\n1. A Semi-conjugate prior distribution 2. Discrete approximations 3. Sampling from the conditional distributions 4. Gibbs Sampling 5. General properties of the Gibbs sampler 6. Introduction to MCMC diagnostics Conclusion semi-conjugate ë¶„í¬ë¥¼ ëª¨ë‘ ì•Œë©´ full conditional probabilityë¥¼ ì•„ëŠ” ê²ƒê³¼ ê±°ì˜ ê°™ë‹¤. í˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"Gibbs Sampling","id":52,"section":"posts","tags":null,"title":"Gibbs Sampling","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/fcb06/"},{"content":"Part 4. ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤ ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. Spotify ë°ì´í„° ì´í•´ Spotify Web API \u0026gt; get an artist\nartist object 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  { \u0026#34;external_urls\u0026#34; : { \u0026#34;spotify\u0026#34; : \u0026#34;https://open.spotify.com/artist/0OdUWJ0sBjDrqHygGUXeCF\u0026#34; }, \u0026#34;followers\u0026#34; : { \u0026#34;href\u0026#34; : null, \u0026#34;total\u0026#34; : 306565 }, \u0026#34;genres\u0026#34; : [ \u0026#34;indie folk\u0026#34;, \u0026#34;indie pop\u0026#34; ], \u0026#34;href\u0026#34; : \u0026#34;https://api.spotify.com/v1/artists/0OdUWJ0sBjDrqHygGUXeCF\u0026#34;, \u0026#34;id\u0026#34; : \u0026#34;0OdUWJ0sBjDrqHygGUXeCF\u0026#34;, \u0026#34;images\u0026#34; : [ { \u0026#34;height\u0026#34; : 816, \u0026#34;url\u0026#34; : \u0026#34;https://i.scdn.co/image/eb266625dab075341e8c4378a177a27370f91903\u0026#34;, \u0026#34;width\u0026#34; : 1000 }, { \u0026#34;height\u0026#34; : 522, \u0026#34;url\u0026#34; : \u0026#34;https://i.scdn.co/image/2f91c3cace3c5a6a48f3d0e2fd21364d4911b332\u0026#34;, \u0026#34;width\u0026#34; : 640 }, { \u0026#34;height\u0026#34; : 163, \u0026#34;url\u0026#34; : \u0026#34;https://i.scdn.co/image/2efc93d7ee88435116093274980f04ebceb7b527\u0026#34;, \u0026#34;width\u0026#34; : 200 }, { \u0026#34;height\u0026#34; : 52, \u0026#34;url\u0026#34; : \u0026#34;https://i.scdn.co/image/4f25297750dfa4051195c36809a9049f6b841a23\u0026#34;, \u0026#34;width\u0026#34; : 64 } ], \u0026#34;name\u0026#34; : \u0026#34;Band of Horses\u0026#34;, \u0026#34;popularity\u0026#34; : 59, \u0026#34;type\u0026#34; : \u0026#34;artist\u0026#34;, \u0026#34;uri\u0026#34; : \u0026#34;spotifyğŸ§‘â€ğŸ¨0OdUWJ0sBjDrqHygGUXeCF\u0026#34; }   2. Spotify ë°ì´í„° ëª¨ë¸ ì˜ˆì‹œ ","description":"ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤","id":53,"section":"posts","tags":null,"title":"Spotify Data","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part4_2/"},{"content":"Chapter 07. The Multivariate Normal Model ë³¸ í¬ìŠ¤íŒ…ì€ First Course in Bayesian Statistical Methodsë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.\n1. Multivariate Normal Desity univariate modelì— ëŒ€í•´ì„œ ì•ì„  ì±•í„°ì—ì„œ ì´ì•¼ê¸°ë¥¼ ë§ì´ í–ˆì§€ë§Œ, ì‚¬ì‹¤ í˜„ì‹¤ì„¸ê³„ì—ì„œëŠ” multivariateì¸ ê²½ìš°ê°€ í›¨ì”¬ ë§ë‹¤.\n1-1. Bivariate Normal   Bivariate Case  1 2 3 4 5  library(tidyverse) library(gridExtra) library(MASS) library(reshape2) library(ash)   1 2 3 4 5 6 7 8 9 10 11 12 13  #### 4-1. Draw yourself Figure 7.1 # ì´ˆê¸° ì„¤ì • inv \u0026lt;- solve MU = matrix(c(50,50), ncol=1) SIGMA = matrix(c(64,0,0,144), ncol=2) # MVN pdf calc.dmvn = Vectorize(function(a,b, mu=MU, sigma=SIGMA){ y \u0026lt;- c(a,b) log.p \u0026lt;- (-nrow(mu)/2)*log(2*pi) - 0.5*log(det(sigma)) - 0.5*(t(y-mu) %*% inv(sigma) %*% (y-mu)) exp(log.p) })   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  # do it at once allInOne \u0026lt;- function(corr){ SIGMA = matrix(c(64,0,0,144), ncol=2) s1 \u0026lt;- sqrt(SIGMA[1,1]); s2 \u0026lt;- sqrt(SIGMA[2,2]) SIGMA[1,2] \u0026lt;- s1*s2*corr; SIGMA[2,1] \u0026lt;- s1*s2*corr # MVN density function calc.dmvn = Vectorize(function(a,b, mu=MU, sigma=SIGMA){ y \u0026lt;- c(a,b) log.p \u0026lt;- (-nrow(mu)/2)*log(2*pi) - 0.5*log(det(sigma)) - 0.5*(t(y-mu) %*% inv(sigma) %*% (y-mu)) exp(log.p) }) # sample sample = mvrnorm(n=30, mu=MU, Sigma=SIGMA) sample = data.frame(sample) colnames(sample) = c(\u0026#39;y1\u0026#39;,\u0026#39;y2\u0026#39;) # calculate density xLim = seq(20, 80, length=101) yLim = seq(20, 80, length=101) density.mvn \u0026lt;- outer(xLim, yLim, FUN=calc.dmvn) rownames(density.mvn) \u0026lt;- xLim colnames(density.mvn) \u0026lt;- yLim density.mvn \u0026lt;- melt(density.mvn) # graph density.mvn %\u0026gt;% ggplot(aes(x=Var1, y=Var2)) + geom_tile(aes(fill=value, alpha=value)) + geom_contour(aes(z=value), color=\u0026#39;white\u0026#39;, size=0.1) + geom_point(data=sample, mapping=aes(x=y1, y=y2, color=\u0026#39;red\u0026#39;), show.legend=FALSE) + scale_fill_gradient(low=\u0026#39;grey\u0026#39;, high=\u0026#39;steelblue\u0026#39;, guide=FALSE) + scale_alpha(guide=FALSE) + theme(legend.position=\u0026#39;None\u0026#39;) + theme_bw() + ggtitle(paste0(\u0026#39;corr=\u0026#39;,corr)) + xlab(\u0026#39;y1\u0026#39;) + ylab(\u0026#39;y2\u0026#39;) }   1 2 3 4  p1 \u0026lt;- allInOne(corr=-0.5) p2 \u0026lt;- allInOne(corr=0) p3 \u0026lt;- allInOne(corr=0.5) grid.arrange(p1,p2,p3, nrow=1)     1-2. Multivariate Normal Model $$p(\\boldsymbol{y}|\\boldsymbol{\\mu}, \\Sigma) = (2\\pi)^{-p/2}|\\Sigma|^{-1/2}exp\\Big(-\\frac{1}{2}(\\boldsymbol{y}-\\boldsymbol{\\mu})^T\\Sigma^{-1}(\\boldsymbol{y}-\\boldsymbol{\\mu}) \\Big) $$\nwhere\n$$\\boldsymbol{y} = \\begin{pmatrix}\ry_1 \\\\\ry_2 \\\\\r\\vdots \\\\\ry_p\r\\end{pmatrix}$$\n$$\\boldsymbol{\\mu} = \\begin{pmatrix}\r\\mu_1 \\\\\r\\mu_2 \\\\\r\\vdots \\\\\r\\mu_p\r\\end{pmatrix}$$\n$$\\Sigma = \\begin{pmatrix}\r\\sigma^2_{1} \u0026amp; \\sigma_{1,2} \u0026amp; \\cdots \u0026amp; \\sigma_{1,p} \\\\\r\\sigma_{2,1} \u0026amp; \\sigma^2_{2} \u0026amp; \\cdots \u0026amp; \\sigma_{2,p} \\\\\r\\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\\\\r\\sigma_{p,1} \u0026amp; \\cdots \u0026amp; \\cdots \u0026amp; \\sigma^2_{p}\r\\end{pmatrix}$$\n2. Semiconjugate prior distribution for the mean (known covariance matrix) Semiconjugateë¼ê³  í•˜ëŠ” ê²ƒì€, ë‘ ëª¨ìˆ˜ ì¤‘ í•˜ë‚˜ê°€ ì£¼ì–´ì¡Œì„ ê²½ìš°ì— conjugateí•œ ê²½ìš°ë¥¼ ëœ»í•œë‹¤.\nì—¬ê¸°ì„œëŠ” ê³µë¶„ì‚° í–‰ë ¬ì´ ì£¼ì–´ì¡Œì„ ë•Œ, í‰ê·  ë²¡í„°ì˜ semiiconjugate priorë¥¼ êµ¬í•˜ëŠ” ê²ƒ(ì¡°ê¸ˆ ë” ì‰¬ì›€)ì„ ë¨¼ì € ë³´ê³  ì´ì–´ì„œ ê³µë¶„ì‚° í–‰ë ¬ì˜ semiconjugate priorë¥¼ êµ¬í•˜ëŠ” ê²ƒì„ ì‚´í´ë³¼ ê²ƒì´ë‹¤.\nPrior: $\\boldsymbol{\\mu} \\text{ ~ } MVN(\\boldsymbol{\\mu_0}, \\Lambda_0)$\n\\begin{align}\rp(\\boldsymbol{\\mu}) \u0026amp;= (2\\pi)^{-p/2}|\\Lambda_0|^{-1/2}exp\\Big(-\\frac{1}{2}(\\boldsymbol{\\mu}-\\boldsymbol{\\mu_0})^T\\Lambda_0^{-1}(\\boldsymbol{\\mu}-\\boldsymbol{\\mu_0})\\Big) \\\\\r\u0026amp;\\propto exp(-\\frac{1}{2}\\boldsymbol{\\mu}^T\\Lambda^{-1}\\boldsymbol{\\mu} \\ + \\ \\boldsymbol{\\mu}^T\\Lambda^{-1}_0\\boldsymbol{\\mu_0}) \\\\\r\u0026amp;= exp(-\\frac{1}{2}\\boldsymbol{\\mu}^TA_0\\boldsymbol{\\mu} \\ + \\ \\boldsymbol{\\mu}^T\\boldsymbol{b_0})\r\\end{align}\nwhere $A_0 = \\Lambda^{-1}_0, \\boldsymbol{b_0} = \\Lambda^{-1}_0\\boldsymbol{\\mu_0}$\nLikelihood: $Y_1, ..., Y_n|\\boldsymbol{\\mu},\\Sigma \\text{ ~ iid } MVN(\\boldsymbol{\\mu}, \\Sigma)$\n\\begin{align}\rp(\\boldsymbol{y_1}, ...,\\boldsymbol{y_n}|\\boldsymbol{\\mu},\\Sigma) \u0026amp;= \\prod^{n}_{i=1} (2\\pi)^{-p/2}|\\Sigma|^{-1/2}exp\\Big(-\\frac{1}{2}(\\boldsymbol{y_i}-\\boldsymbol{\\mu})^T\\Sigma^{-1}(\\boldsymbol{y_i}-\\boldsymbol{\\mu}) \\Big) \\\\\r\u0026amp;= (2\\pi)^{-np/2}|\\Sigma|^{-n/2}exp\\Big(-\\frac{1}{2}\\sum_{i=1}^{n}(\\boldsymbol{y_i}-\\boldsymbol{\\mu})^T\\Sigma^{-1}(\\boldsymbol{y_i}-\\boldsymbol{\\mu}) \\Big) \\\\\r\u0026amp;\\propto exp(-\\frac{1}{2}\\boldsymbol{\\mu}^TA_1\\boldsymbol{\\mu} \\ + \\ \\boldsymbol{\\mu}^T\\boldsymbol{b_1})\r\\end{align}\nwhere $A_1 = n\\Sigma^{-1}, \\boldsymbol{b_1} = n\\Sigma^{-1}\\boldsymbol{\\bar{y}}$\nPosterior: $\\boldsymbol{\\mu}|\\boldsymbol{y_1}, ..., \\boldsymbol{y_n}, \\Sigma \\text{ ~ } MVN(\\boldsymbol{\\mu_n}, \\Lambda_n)$\n$$\n\\begin{align}\rp(\\boldsymbol{\\mu}|\\boldsymbol{y_1}, ..., \\boldsymbol{y_n}, \\Sigma) \u0026amp;\\propto exp(-\\frac{1}{2}\\boldsymbol{\\mu}^TA_0\\boldsymbol{\\mu} \\ + \\ \\boldsymbol{\\mu}^T\\boldsymbol{b_0}) \\times exp(-\\frac{1}{2}\\boldsymbol{\\mu}^TA_1\\boldsymbol{\\mu} \\ + \\ \\boldsymbol{\\mu}^T\\boldsymbol{b_1}) \\\\\r\u0026amp;= exp(-\\frac{1}{2}\\boldsymbol{\\mu}^TA_n\\boldsymbol{\\mu} \\ + \\ \\boldsymbol{\\mu}^T\\boldsymbol{b_n}) \\\\\r\\\\\r\\text{where } A_n \u0026amp;= A_0 + A_1 = \\Lambda_0^{-1}+n\\Sigma^{-1} \\\\\r\\boldsymbol{b_n} \u0026amp;= \\boldsymbol{b_0} + \\boldsymbol{b_1} = \\Lambda_0^{-1}\\boldsymbol{\\mu_0}+n\\Sigma^{-1}\\boldsymbol{\\bar{y}} \\\\\r\\\\\r\\rightarrow \\Lambda_n^{-1} \u0026amp;= \\Lambda_0^{-1}+n\\Sigma^{-1} \\\\\r\\boldsymbol{\\mu_n} \u0026amp;= (\\Lambda_0^{-1}+n\\Sigma^{-1})^{-1}(\\Lambda_0^{-1}\\boldsymbol{\\mu_0}+n\\Sigma^{-1}\\boldsymbol{\\bar{y}})\r\\end{align}\n$$\n3. Semiconjugate prior distribution for the covariance matrix (known mean) ì´ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë³µì¡í•œë°, ê·¸ ì´ìœ ëŠ” ì´ì „ê³¼ ë‹¬ë¦¬ matrix í˜•íƒœì—ë‹¤ê°€ priorì„ ì£¼ì–´ì•¼í•˜ê¸° ë•Œë¬¸ì´ë‹¤.\nê·¸ë˜ì„œ êµ¬ì²´ì ì¸ priorì™€ likelihoodë¥¼ ì´ì•¼ê¸°í•˜ê¸° ì•ì„œì„œ í•„ìš”í•œ ë‘ ê°€ì§€ ê°œë…ì— ëŒ€í•´ì„œ ì§šê³  ë„˜ì–´ê°€ë„ë¡ í•˜ì.\nì²« ë²ˆì§¸ëŠ” inverse-Wishart ë¶„í¬ì´ë©°, ë‹¤ìŒì€ Positive Definiteì´ë¼ëŠ” ì„ í˜•ëŒ€ìˆ˜ ê°œë…ì´ë‹¤.\n3-1. inverse-Wishart Distribution inverse-Wishart Distributionì€ ê³µë¶„ì‚° í–‰ë ¬ì˜ semiconjugate priorì„ ì£¼ê¸° ìœ„í•´ì„œ ì•Œì•„ì•¼ í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. ë‚¯ì„  í™•ë¥ ë¶„í¬ì²˜ëŸ¼ ë³´ì´ê¸°ë„ í•˜ì§€ë§Œ, ìì„¸íˆ ì‚´í´ë³´ë©´ ì´ëŠ” inverse-Gamma distributionì˜ ë‹¤ì°¨ì› í™•ì¥ ë²„ì „ì— ë¶ˆê³¼í•˜ê¸´ í•˜ë‹¤.\n3-2. Positive Definite Covariance MatrixëŠ” Positive Definite Matrixì´ì–´ì•¼ í•œë‹¤. Positive Definiteì˜ ì •ì˜ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.\n$$\\boldsymbol{x'}\\Sigma\\boldsymbol{x} \u0026gt; 0 \\ \\text{ for all vectors} \\ \\boldsymbol{x}$$\nunivariate caseì—ì„œ ë¶„ì‚°ì´ ì–¸ì œë‚˜ 0 ì´ìƒì´ì–´ì•¼ í•˜ëŠ” ê²ƒì²˜ëŸ¼, ì´ì™€ ê°™ì€ ë§¥ë½ì˜ ì¡°ê±´ì„ ë‹¤ì°¨ì›ì—ì„œ ë§Œì¡±í•˜ë ¤ë©´ PD(Positive Definite)ì´ì–´ì•¼ í•œë‹¤. ë§Œì•½ ê³µë¶„ì‚° í–‰ë ¬ì´ Positive Definiteí•˜ë‹¤ë©´, ì´ëŠ” ëª¨ë“  ë¶„ì‚°ì´ 0ë³´ë‹¤ í¬ë©° ê³µë¶„ì‚°ì´ -1ê³¼ 1 ì‚¬ì´ì— ìˆë„ë¡ í•œë‹¤.\në˜í•œ, PDëŠ” ëŒ€ì¹­í–‰ë ¬(symmetric)ì—ì„œ ì •ì˜ë˜ëŠ” ê°œë…ì´ê¸° ë•Œë¬¸ì—, $\\sigma_{i,j} = \\sigma_{j,i}$ë¼ëŠ” ì¡°ê±´ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì„±ë¦½í•œë‹¤.\n3-2-1. Positive Definiteì´ ë˜ê¸° ìœ„í•œ ì¡°ê±´ì€? ë‹¤ì‹œ í•œë²ˆ ë§í•˜ìë©´, Positive Definiteì€ ëŒ€ì¹­í–‰ë ¬ì˜ íŠ¹ìˆ˜í•œ í˜•íƒœì´ë©°, ëª¨ë“  eigenvalueë“¤ì´ 0ë³´ë‹¤ í¬ë‹¤ëŠ” ë§ê³¼ ê°™ë‹¤.\nì—¬ê¸°ì„œ eigenvalueê°€ 0ë³´ë‹¤ í¬ë‹¤ëŠ” ê²ƒì€ ì •í™•íˆ ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œ?\nì •ë°©í–‰ë ¬ì„ Spectral Decompositionì„ í–ˆì„ ë•Œ, $A = VDV^{-1}$\n$$A_{p\\text{ x }p} = \\begin{bmatrix}\r| \u0026amp; \u0026amp; |\\\\\ra_1 \u0026amp; \\cdots \u0026amp; a_p\\\\\r| \u0026amp; \u0026amp; |\\\\\r\\end{bmatrix} = \\begin{bmatrix}\r| \u0026amp; \u0026amp; |\\\\\rv_1 \u0026amp; \\cdots \u0026amp; v_p\\\\\r| \u0026amp; \u0026amp; | \\\\\r\\end{bmatrix} \\begin{bmatrix}\r\\lambda_1 \u0026amp; \u0026amp; \\\\\r\u0026amp; \\ddots \u0026amp; \\\\\r\u0026amp; \u0026amp; \\lambda_p\r\\end{bmatrix} \\begin{bmatrix}\r| \u0026amp; \u0026amp; |\\\\\rv_1 \u0026amp; \\cdots \u0026amp; v_p\\\\\r| \u0026amp; \u0026amp; |\\\\\r\\end{bmatrix}^{-1}$$\neigenvalueê°€ 0ë³´ë‹¤ í¬ë‹¤ëŠ” ê²ƒì€, ì„ í˜•ë³€í™˜ì„ í–ˆì„ ë•Œ ê·¸ ê¸°ì €ì˜ ë°©í–¥ì´ ë°˜ëŒ€ë¡œ ë°”ë€Œì§€ëŠ” ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.\n3-3. random Covariance Matrix ë§Œë“¤ê¸° ì´ëŠ” covariance matrixì— ëŒ€í•´ uninformative priorë¥¼ ì£¼ê¸° ìœ„í•¨ì´ë‹¤.\n$$\\frac{1}{n}\\sum_{i=1}^n\\boldsymbol{z_iz_i^T} = \\frac{1}{n}Z^TZ$$\n$$\\boldsymbol{z_iz_i^T} = \\begin{pmatrix}\rz_{i,1}^2 \u0026amp; z_{i,1}z_{i,2} \u0026amp; \\cdots \u0026amp; z_{i,1}z_{i,p} \\\\\rz_{i,2}z_{i,1} \u0026amp; z_{i,2}^2 \u0026amp; \\cdots \u0026amp; z_{i,2}z_{i,p} \\\\\r\\vdots \u0026amp; \u0026amp; \u0026amp; \\vdots \\\\\rz_{i,p}z_{i,1} \u0026amp; z_{i,p}z_{i,2} \u0026amp; \\cdots \u0026amp; z_{i,p}^2\r\\end{pmatrix}$$\n\\begin{align}\r\\frac{1}{n}\\big[Z^TZ\\big]_{j,j} \u0026amp;= \\frac{1}{n}\\sum_{i=1}^{n}z_{i,j}^2 = s_{j,j} = s_j^2\\\\\r\\frac{1}{n}\\big[Z^TZ\\big]_{j,k} \u0026amp;= \\frac{1}{n}\\sum_{i=1}^{n}z_{i,j}z_{i,k} = s_{j,k}\r\\end{align}\nì—¬ê¸°ì„œ n \u0026gt; p ì´ê³ , ëª¨ë“  $\\boldsymbol{z_i}$ë“¤ì´ ì„œë¡œ ì„ í˜•ë…ë¦½ì´ë¼ë©´, $Z^TZ$ëŠ” í•­ìƒ positive definiteì¼ ê²ƒì´ë‹¤.\n$$\\text{Proof) } \\boldsymbol{x}^{T}Z^{T}Z\\boldsymbol{x} = (Z\\boldsymbol{x})^{T}(Z\\boldsymbol{x}) = ||Z\\boldsymbol{x}||^2 \\ge 0$$\nSTEP1. Set $\\nu_0$(prior sample size), $\\Phi_0$(prior covariance matrix)\nSTEP2. Sample $\\boldsymbol{z_i} \\ \\stackrel{iid}{\\sim} \\ MVN(\\boldsymbol{0}, \\Phi_0)$\nSTEP3. Calculate $Z_TZ = \\sum_{i=1}^{\\nu_0}\\boldsymbol{z_iz_i^T}$\nSTEP4. repeat the procedure S times generating $Z_i^TZ_i$\n${Z_1^TZ_1, Z_2^TZ_2, ..., Z_S^TZ_S} \\text{ ~ } Wis(\\nu_0, \\Phi_0)$\nWishartë¶„í¬ì™€ inv-Wishartë¶„í¬ íŠ¹ì§• $$\\Sigma^{-1} \\sim Wis(\\nu_0, S_0^{-1}) \\rightarrow E[\\Sigma^{-1}]=\\nu_0S_0^{-1} \\\\\r\\Sigma \\sim Wis^{-1}(\\nu_0, S_0^{-1}) \\rightarrow E[\\Sigma]=\\frac{1}{\\nu_0-p-1}S_0$$\ncovariance matrix semiconjugate prior ëª¨ìˆ˜ ì„¤ì • ë°©ë²• 1-1. If belief that $\\Sigma = \\Sigma_0$ is strong, $\\nu_0$ \\uparrow 1-2. If belief that $\\Sigma = \\Sigma_0$ is weak, $\\nu_0 = p+2$\n2. Set $S_0=(\\nu_0-p-1)\\Sigma_0$\n3-4. Full conditional distribution of Covariance Matrix Prior: $\\Sigma \\sim \\text{inv-}Wis(\\nu_0, S_0^{-1})$\n$$p(\\Sigma) = \\bigg[2^{\\nu_0p/2}\\pi^{p/2}|S_0|^{\\nu_0/2}\\prod_{j=1}^{p}\\Gamma(\\frac{\\nu_0+1-j}{2})\\bigg]^{-1} \\times |\\Sigma|^{-(\\nu_0+p+1)/2} \\times exp\\Big(-\\frac{1}{2}tr(S_0\\Sigma^{-1})\\Big) $$\nLikelihood: $\\boldsymbol{Y}|\\boldsymbol{\\mu} \\stackrel{iid}\\sim MVN(\\boldsymbol{\\mu}, \\Sigma)$\n\\begin{align}\rp(\\boldsymbol{y_1, ..., y_n}|\\boldsymbol{\\mu}, \\Sigma) \u0026amp;= (2\\pi)^{-np/2}|\\Sigma|^{-n/2} exp\\bigg(-\\frac{1}{2}\\sum_{i=1}^{n} \\boldsymbol{(y_i-\\mu)}^T\\Sigma^{-1}\\boldsymbol{(y_i-\\mu)} \\bigg) \\\\\r\u0026amp;\\propto |\\Sigma|^{-n/2}exp\\bigg(-\\frac{1}{2}tr(S_\\mu\\Sigma^{-1})\\bigg)\r\\end{align}\nwhere $S_\\mu = \\sum_{i=1}^{n}\\boldsymbol{(y_i-\\mu)}\\boldsymbol{(y_i-\\mu)}^T$\nPosterior: $\\Sigma|\\boldsymbol{y} \\sim \\text{inv-}Wis(\\nu_0+n, [S_0+S_\\mu]^{-1})$\n\\begin{align}\rp(\\Sigma|\\boldsymbol{y_1, ..., y_n, \\mu}) \u0026amp;\\propto p(\\Sigma)p(\\boldsymbol{y_1, ..., y_n}|\\boldsymbol{\\mu},\\Sigma) \\\\\r\u0026amp;\\propto|\\Sigma|^{-(\\nu_0+p+1)/2} \\times exp\\Big(-\\frac{1}{2}tr(S_0\\Sigma^{-1})\\Big) \\times |\\Sigma|^{-n/2}exp\\bigg(-\\frac{1}{2}tr(S_\\mu\\Sigma^{-1})\\bigg) \\\\\r\u0026amp;\\propto |\\Sigma|^{-(\\nu_0+p+n+1)/2}exp\\bigg(-\\frac{1}{2}tr([S_0+S_\\mu]\\Sigma^{-1})\\bigg)\r\\end{align}\n\\begin{align}\rE[\\Sigma|\\boldsymbol{y_1, ..., y_n, \\mu}] \u0026amp;= \\frac{1}{\\nu_0+n-p-1}(S_0+S_\\mu) \\\\\r\u0026amp;= \\frac{\\nu_0-p-1}{\\nu_0+n-p-1}\\cdot\\frac{1}{\\nu_0-p-1}S_0 + \\frac{n}{\\nu_0+n-p-1}\\cdot\\frac{1}{n}S_\\mu \\\\\r\u0026amp;= \\frac{\\nu_0-p-1}{\\nu_0+n-p-1}\\cdot\\Sigma_0 + \\frac{n}{\\nu_0+n-p-1}\\cdot\\frac{1}{n}S_\\mu\r\\end{align}\nSummary  Semiconjugate prior for $\\mu$\nPrior: $\\boldsymbol{\\mu} \\text{ ~ } MVN(\\boldsymbol{\\mu_0}, \\Lambda_0)$\nLikelihood: $Y_1, ..., Y_n|\\boldsymbol{\\mu},\\Sigma \\text{ ~ iid } MVN(\\boldsymbol{\\mu}, \\Sigma)$\nPosterior: $\\boldsymbol{\\mu}|\\boldsymbol{y_1}, ..., \\boldsymbol{y_n}, \\Sigma \\text{ ~ } MVN(\\boldsymbol{\\mu_n}, \\Lambda_n)$  \\begin{align}\r\\Lambda_n^{-1} \u0026amp;= \\Lambda_0^{-1}+n\\Sigma^{-1} \\\\\r\\boldsymbol{\\mu_n} \u0026amp;= (\\Lambda_0^{-1}+n\\Sigma^{-1})^{-1}(\\Lambda_0^{-1}\\boldsymbol{\\mu_0}+n\\Sigma^{-1}\\boldsymbol{\\bar{y}})\r\\end{align}\nSemiconjugate prior for $\\Sigma$\nPrior: $\\Sigma \\sim \\text{inv-}Wis(\\nu_0, S_0^{-1}) \\text{ where } S_0 = (\\nu_0-p-1)\\Sigma_0$\nLikelihood: $\\boldsymbol{Y}|\\boldsymbol{\\mu} \\stackrel{iid}\\sim MVN(\\boldsymbol{\\mu}, \\Sigma)$\nPosterior: $\\Sigma|\\boldsymbol{y_1, ..., y_n} \\sim \\text{inv-}Wis(\\nu_0+n, [S_0+S_\\mu]^{-1})$  $$E[\\Sigma|\\boldsymbol{y_1, ..., y_n, \\mu}] = \\frac{\\nu_0-p-1}{\\nu_0+n-p-1}\\cdot\\Sigma_0 + \\frac{n}{\\nu_0+n-p-1}\\cdot\\frac{1}{n}S_\\mu$$\n  ê·¸ë˜í”„ ê·¸ë¦¬ê¸°  4-2. Draw yourself Figure 7.2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  # Load Data test \u0026lt;- matrix(c(59, 43, 34, 32, 42, 38, 55, 67, 64, 45, 49, 72, 34, 70, 34, 50, 41, 52, 60, 34, 28, 35, 77, 39, 46, 26, 38, 43, 68, 86, 77, 60, 50, 59, 38, 48, 55, 58, 54, 60, 75, 47, 48, 33), ncol=2, byrow=FALSE) colnames(test) \u0026lt;- c(\u0026#39;pretest\u0026#39;,\u0026#39;posttest\u0026#39;) # Preparing n \u0026lt;- nrow(test) ybar \u0026lt;- colMeans(test) Sigma \u0026lt;- cov(test) THETA \u0026lt;- NULL SIGMA \u0026lt;- NULL inv \u0026lt;- solve sample.size = 5000 sample.new = NULL # prior mu0 \u0026lt;- c(50,50); nu0 \u0026lt;- 4 #(nu0 = p+2 = 4)  S0 \u0026lt;- L0 \u0026lt;- matrix(c(625,312.5,312.5,625), nrow=2, ncol=2) set.seed(2021) for(i in 1:sample.size){ # update theta Ln = inv(inv(L0) + n*inv(Sigma)) mun = Ln %*% (inv(L0)%*%mu0 + n*inv(Sigma)%*%ybar) theta = mvrnorm(1, mun, Ln) # update sigma Sn = S0 + (t(test)-theta)%*%t(t(test)-theta) Sigma = inv(rWishart(1, nu0+n, inv(Sn))[,,1]) # Save results THETA \u0026lt;- rbind(THETA, theta) SIGMA \u0026lt;- rbind(SIGMA, c(Sigma)) # sample new sample.new = rbind(sample.new, mvrnorm(n=1, mu=theta, Sigma=Sigma)) } rownames(THETA) \u0026lt;- 1:sample.size rownames(SIGMA) \u0026lt;- 1:sample.size   1 2 3 4 5 6 7 8 9 10  # graph(ì½”ë“œ ë”°ë¼í•˜ê¸°) par(mfrow=c(1,2),mgp=c(1.75,.75,0),mar=c(3,3,1,1)) plot.hdr2d(THETA,xlab=expression(theta[1]),ylab=expression(theta[2]) ) abline(0,1) plot.hdr2d(sample.new,xlab=expression(italic(y[1])),ylab=expression(italic(y[2])), xlim=c(0,100),ylim=c(0,100) ) points(test[,1],test[,2],pch=16,cex=.7) abline(0,1)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # graph(ggplot í™œìš©) p1 \u0026lt;- data.frame(THETA) %\u0026gt;% ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color=\u0026#39;orange\u0026#39;) + geom_abline(slope=1, intercept=0) + xlab(expression(theta[1])) + ylab(expression(theta[2])) + ggtitle(\u0026#39;Posterior draws of Mu\u0026#39;) p2 \u0026lt;- data.frame(sample.new) %\u0026gt;% ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color=\u0026#39;orange\u0026#39;) + geom_abline(slope=1, intercept=0) + xlab(expression(y[1])) + ylab(expression(y[2])) + ggtitle(\u0026#39;Posterior Predictive\u0026#39;) grid.arrange(p1, p2, nrow=1)     4. Gibbs Sampling of the mean and covariance Gibbs samplingì€ full conditional distributionì„ í†µí•´ ì°¨ë¡€ëŒ€ë¡œ ëª¨ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ë©´ì„œ joint posterior distributionì„ êµ¬í•˜ëŠ” ê²ƒì´ ëª©ì ì´ë‹¤.\nSTEP1. Full conditional distributionì„ í™•ë³´í•œë‹¤.\n $\\boldsymbol{\\mu}|\\boldsymbol{y_1}, ..., \\boldsymbol{y_n}, \\Sigma \\sim MVN(\\boldsymbol{\\mu_n}, \\Lambda_n)$ $\\Sigma|\\boldsymbol{y_1, ..., y_n} \\sim \\text{inv-}Wis(\\nu_0+n, [S_0+S_\\mu]^{-1})$  STEP2. ì°¨ë¡€ëŒ€ë¡œ ì—…ë°ì´íŠ¸í•˜ë©´ì„œ joint posterior distribution $\\boldsymbol{\\mu},\\Sigma|\\boldsymbol{y_1}, ..., \\boldsymbol{y_n}$ì„ êµ¬í•œë‹¤.\n4-1. NA imputation MAR(Missing at Random)ì¸ ê²½ìš°ì—, missing dataë¥¼ ì¼ì¢…ì˜ ëª¨ìˆ˜ë¡œ ë³´ê³  gibbs samplingì„ í†µí•´ na imputationì„ í•´ì¤„ ìˆ˜ ìˆë‹¤.\nConclusion MVNë„ ì˜ ì•Œì•„ë‘ì. inv-Wishart ë¶„í¬ë„! í˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"","id":54,"section":"posts","tags":null,"title":"MVN","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/fcb07/"},{"content":"Part 4. ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤ ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. Pymysql íŒ¨í‚¤ì§€ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  import sys import requests import base64 import json import logging import pymysql #New library client_id = \u0026#39;\u0026#39; #ì§ì ‘ ì…ë ¥ client_secret = \u0026#39;\u0026#39; # ì§ì ‘ ì…ë ¥ host = \u0026#39;\u0026#39; #host port = 3306 username = \u0026#39;\u0026#39; #user database = \u0026#39;\u0026#39; #db password = \u0026#39;\u0026#39; #passwd def main(): try: conn = pymysql.connect(host=host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset=\u0026#39;utf8\u0026#39;) cursor = conn.cursor() except: logging.error(\u0026#39;could not connect to RDS\u0026#39;) sys.exit(1) cursor.execute(\u0026#39;SHOW TABLES\u0026#39;) print(cursor.fetchall()) print(\u0026#39;success\u0026#39;) sys.exit(0) if __name__ == \u0026#39;__main__\u0026#39;: main()   2. INSERT, UPDATE, REPLACE, INSERT IGNORE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  CREATE TABLE artists (id VARCHAR(255), name VARCHAR(255), followers INT, popularity INT, url VARCHAR(255), image_url VARCHAR(255), PRIMARY KEY(id)) ENGINE=InnoDB DEFAULT CHARSET=\u0026#39;utf8\u0026#39;; CREATE TABLE artist_genres (artist_id VARCHAR(255), genre VARCHAR(255)) ENGINE=InnoDB DEFAULT CHARSET=\u0026#39;utf8\u0026#39;; SHOW CREATE TABLE artists; -- INSERT INSERT INTO artist_genres (artist_id, genre) VALUES (\u0026#39;1234\u0026#39;, \u0026#39;pop\u0026#39;); DELETE FROM artist_genres; --ì œê±° DROP TABLE artist_genres; --ì œê±° CREATE TABLE artist_genres (artist_id VARCHAR(255), genre VARCHAR(255), UNIQUE KEY(artist_id, genre)) ENGINE=InnoDB DEFAULT CHARSET=\u0026#39;utf8\u0026#39;; --unique key ìƒì„± INSERT INTO artist_genres (artist_id, genre) VALUES (\u0026#39;1234\u0026#39;, \u0026#39;pop\u0026#39;); INSERT INTO artist_genres (artist_id, genre) VALUES (\u0026#39;1234\u0026#39;, \u0026#39;pop\u0026#39;); --ë‘ ë²ˆ í•˜ë©´ ERROR  -- UPDATE UPDATE artist_genres SET genre=\u0026#39;pop\u0026#39; WHERE artist_id =\u0026#39;1234\u0026#39;; ALTER TABLE artist_genres ADD COLUMN country VARCHAR(255); ALTER TABLE artist_genres ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP; --ì—…ë°ì´íŠ¸ë˜ëŠ” ì‹œê°ëŒ€ ìë™ì¶”ê°€ INSERT INTO artist_genres (artist_id, genre, country) VALUES (\u0026#39;1234\u0026#39;,\u0026#39;pop\u0026#39;,\u0026#39;UK\u0026#39;); -- ì˜¤ë¥˜ ë°œìƒí•¨  -- REPLACE REPLACE INTO artist_genres (artist_id, genre, country) VALUES (\u0026#39;1234\u0026#39;,\u0026#39;pop\u0026#39;,\u0026#39;UK\u0026#39;); /* ë¬¸ì œì (1) ì§€ìš°ê³  ì—…ë°ì´íŠ¸í•˜ê¸° ë•Œë¬¸ì— 2ë²ˆì˜ ê³¼ì •ì„ ê±°ì³ì„œ í¼í¬ë¨¼ìŠ¤ì ìœ¼ë¡œ ë¬¸ì œ ìƒê¸¸ ìˆ˜ê°€ ìˆë‹¤. ë¬¸ì œì (2) primary keyê°€ auto_incrementì¸ ê²½ìš° ìƒˆë¡œìš´ ìˆ«ìë¡œ ë°”ë€Œê²Œ ëœë‹¤. */ -- INSERT IGNORE INSERT IGNORE INTO artist_genres (artist_id, genre, country) VALUES (\u0026#39;1234\u0026#39;,\u0026#39;rock\u0026#39;,\u0026#39;UK\u0026#39;); /* ë¬¸ì œì (1) ì´ë¯¸ ê°’ì´ ìˆìœ¼ë©´ ì¶”ê°€í•˜ì§€ ì•Šê²Œ ëœë‹¤.*/ -- INSERT ... ON DUPLICATE KEY UPDATE INSERT INTO artist_genres (artist_id, genre, country) VALUES (\u0026#39;1234\u0026#39;,\u0026#39;rock\u0026#39;,\u0026#39;UK\u0026#39;) ON DUPLICATE KEY UPDATE artist_id=\u0026#39;1234\u0026#39;, genre=\u0026#39;rock\u0026#39;, country=\u0026#39;FR\u0026#39;; --UKë¥¼ FRë¡œ ë°”ê¾¼ë‹¤.  -- ETC ALTER TABLE artist_genres DROP COLUMN country; --ë¶ˆí•„ìš”í•œ ì¹¼ëŸ¼ ì§€ìš°ê¸°   *MySQLì—ì„œ ì§„í–‰í•˜ì˜€ë‹¤.\níŠ¹ì´ì‚¬í•­  data typeì„ INTEGERë¡œ í•˜ë‹ˆê¹Œ ì•ˆ ë˜ê³ , INTë¡œ í•˜ë‹ˆê¹Œ ëë‹¤.  3. _, .format() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  def main(): try: conn = pymysql.connect(host=host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset=\u0026#39;utf8\u0026#39;) cursor = conn.cursor() except: logging.error(\u0026#39;could not connect to RDS\u0026#39;) sys.exit(1) cursor.execute(\u0026#39;SHOW TABLES\u0026#39;) print(cursor.fetchall()) query = \u0026#34;INSERT INTO artist_genres (artist_id, genre) VALUES (\u0026#39;{0}\u0026#39;, \u0026#39;{1}\u0026#39;)\u0026#34;.format(\u0026#39;2345\u0026#39;,\u0026#39;hip-hop\u0026#39;) cursor.execute(query) conn.commit() sys.exit(0) if __name__ == \u0026#39;__main__\u0026#39;: main()   4. Dictionaryì™€ JSON Package 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  def main(): try: conn = pymysql.connect(host=host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset=\u0026#39;utf8\u0026#39;) cursor = conn.cursor() except: logging.error(\u0026#39;could not connect to RDS\u0026#39;) sys.exit(1) headers = get_headers(client_id, client_secret) ## Spotify Search api params = { \u0026#39;q\u0026#39;: \u0026#39;BTS\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;artist\u0026#39;, \u0026#39;limit\u0026#39;: \u0026#39;5\u0026#39; } r = requests.get(\u0026#39;https://api.spotify.com/v1/search\u0026#39;, params=params, headers=headers) raw = json.loads(r.text) print(raw[\u0026#39;artists\u0026#39;].keys) def get_headers(client_id, client_secret): endpoint = \u0026#39;https://accounts.spotify.com/api/token\u0026#39; encoded = base64.b64encode(\u0026#34;{}:{}\u0026#34;.format(client_id, client_secret).encode(\u0026#39;utf-8\u0026#39;)).decode(\u0026#39;ascii\u0026#39;) headers = {\u0026#39;Authorization\u0026#39;: \u0026#39;Basic {}\u0026#39;.format(encoded)} payload = {\u0026#39;grant_type\u0026#39;: \u0026#39;client_credentials\u0026#39;} r = requests.post(endpoint, data=payload, headers=headers) access_token = json.loads(r.text)[\u0026#39;access_token\u0026#39;] headers = {\u0026#39;Authorization\u0026#39;: \u0026#34;Bearer {}\u0026#34;.format(access_token)} return headers if __name__ == \u0026#39;__main__\u0026#39;: main()   5. Duplicate Record í•¸ë“¤ë§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  def main(): try: conn = pymysql.connect(host=host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset=\u0026#39;utf8\u0026#39;) cursor = conn.cursor() except: logging.error(\u0026#39;could not connect to RDS\u0026#39;) sys.exit(1) headers = get_headers(client_id, client_secret) ## Spotify Search api params = { \u0026#39;q\u0026#39;: \u0026#39;BTS\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;artist\u0026#39;, \u0026#39;limit\u0026#39;: \u0026#39;1\u0026#39; } r = requests.get(\u0026#39;https://api.spotify.com/v1/search\u0026#39;, params=params, headers=headers) raw = json.loads(r.text) artist_raw = raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0] if artist_raw[\u0026#39;name\u0026#39;] == params[\u0026#39;q\u0026#39;]: artist = { \u0026#39;id\u0026#39;: artist_raw[\u0026#39;id\u0026#39;], \u0026#39;name\u0026#39;: artist_raw[\u0026#39;name\u0026#39;], \u0026#39;followers\u0026#39;: artist_raw[\u0026#39;followers\u0026#39;][\u0026#39;total\u0026#39;], \u0026#39;popularity\u0026#39;: artist_raw[\u0026#39;popularity\u0026#39;], \u0026#39;url\u0026#39;: artist_raw[\u0026#39;external_urls\u0026#39;][\u0026#39;spotify\u0026#39;], \u0026#39;image_url\u0026#39;: artist_raw[\u0026#39;images\u0026#39;][0][\u0026#39;url\u0026#39;] } query = \u0026#34;\u0026#34;\u0026#34; INSERT INTO artists (id, name, followers, popularity, url, image_url) VALUES (\u0026#39;{}\u0026#39;, \u0026#39;{}\u0026#39;, {}, {}, \u0026#39;{}\u0026#39;, \u0026#39;{}\u0026#39;) ON DUPLICATE KEY UPDATE id=\u0026#39;{}\u0026#39;, name=\u0026#39;{}\u0026#39;, followers={}, popularity={}, url=\u0026#39;{}\u0026#39;, image_url=\u0026#39;{}\u0026#39; \u0026#34;\u0026#34;\u0026#34;.format( artist[\u0026#39;id\u0026#39;], artist[\u0026#39;name\u0026#39;], artist[\u0026#39;followers\u0026#39;], artist[\u0026#39;popularity\u0026#39;], artist[\u0026#39;url\u0026#39;], artist[\u0026#39;image_url\u0026#39;], artist[\u0026#39;id\u0026#39;], artist[\u0026#39;name\u0026#39;], artist[\u0026#39;followers\u0026#39;], artist[\u0026#39;popularity\u0026#39;], artist[\u0026#39;url\u0026#39;], artist[\u0026#39;image_url\u0026#39;] ) cursor.execute(query) conn.commit()   6. Duplicate Record í•¸ë“¤ë§ì„ ìœ„í•œ íŒŒì´ì¬ í•¨ìˆ˜ 5ì™€ ë‹¤ë¥¸ ì ì„ ëˆˆì—¬ê²¨ ë³´ê¸° (5ë¥¼ ë³´ë‹¤ ê°„ë‹¨í•˜ê²Œ í•œ ì½”ë“œ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  def main(): ## .... ì—¬ê¸°ê¹Œì§€ëŠ” ìœ„ì™€ ë™ì¼ r = requests.get(\u0026#39;https://api.spotify.com/v1/search\u0026#39;, params=params, headers=headers) raw = json.loads(r.text) artist = {} artist_raw = raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0] if artist_raw[\u0026#39;name\u0026#39;] == params[\u0026#39;q\u0026#39;]: artist.update({ \u0026#39;id\u0026#39;: artist_raw[\u0026#39;id\u0026#39;], \u0026#39;name\u0026#39;: artist_raw[\u0026#39;name\u0026#39;], \u0026#39;followers\u0026#39;: artist_raw[\u0026#39;followers\u0026#39;][\u0026#39;total\u0026#39;], \u0026#39;popularity\u0026#39;: artist_raw[\u0026#39;popularity\u0026#39;], \u0026#39;url\u0026#39;: artist_raw[\u0026#39;external_urls\u0026#39;][\u0026#39;spotify\u0026#39;], \u0026#39;image_url\u0026#39;: artist_raw[\u0026#39;images\u0026#39;][0][\u0026#39;url\u0026#39;] }) insert_row(cursor, data=artist, table=\u0026#39;artists\u0026#39;) conn.commit() def insert_row(cursor, data, table): placeholders = \u0026#39;, \u0026#39;.join([\u0026#39;%s\u0026#39;] * len(data)) columns = \u0026#39;, \u0026#39;.join(data.keys()) key_placeholders = \u0026#39;, \u0026#39;.join([\u0026#39;{0}=%s\u0026#39;.format(k) for k in data.keys()]) sql = \u0026#39;INSERT INTO %s( %s) VALUES ( %s) ON DUPLICATE KEY UPDATE %s\u0026#39; % (table, columns, placeholders, key_placeholders) cursor.execute(sql, list(data.values())*2)   7. Artist list ì¶”ì¶œí•˜ê¸°  íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ ê°•ì¢Œë¥¼ í†µí•´ ì œê³µëœ artist_list.csv íŒŒì¼ì„ í™œìš©í•˜ì˜€ë‹¤.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  def main(): try: conn = pymysql.connect(host=host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset=\u0026#39;utf8\u0026#39;) cursor = conn.cursor() except: logging.error(\u0026#39;could not connect to RDS\u0026#39;) sys.exit(1) headers = get_headers(client_id, client_secret) artists = [] with open(\u0026#39;../artist_list.csv\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;) as f: raw = csv.reader(f) for row in raw: artists.append(row[0]) for a in artists: params = { \u0026#39;q\u0026#39;: a, \u0026#39;type\u0026#39;: \u0026#39;artist\u0026#39;, \u0026#39;limit\u0026#39;: \u0026#39;1\u0026#39; } r = requests.get(\u0026#39;https://api.spotify.com/v1/search\u0026#39;, params=params, headers=headers) raw = json.loads(r.text) artist = {} try: if raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0][\u0026#39;name\u0026#39;] == params[\u0026#39;q\u0026#39;]: artist.update( { \u0026#39;id\u0026#39;: raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0][\u0026#39;id\u0026#39;], \u0026#39;name\u0026#39;: raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0][\u0026#39;name\u0026#39;], \u0026#39;followers\u0026#39;: raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0][\u0026#39;followers\u0026#39;][\u0026#39;total\u0026#39;], \u0026#39;popularity\u0026#39;: raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0][\u0026#39;popularity\u0026#39;], \u0026#39;url\u0026#39;: raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0][\u0026#39;external_urls\u0026#39;][\u0026#39;spotify\u0026#39;], \u0026#39;image_url\u0026#39;: raw[\u0026#39;artists\u0026#39;][\u0026#39;items\u0026#39;][0][\u0026#39;images\u0026#39;][0][\u0026#39;url\u0026#39;] } ) insert_row(cursor, artist, \u0026#39;artists\u0026#39;) except: logging.error(\u0026#39;NO ITEMS FROM SEARCH API\u0026#39;) continue conn.commit() # sys.exit(0)   ERROR:root:NO ITEMS FROM SEARCH APIì™€ ê°™ì€ ì—ëŸ¬ê°€ ì—¬ëŸ¬ ê°œê°€ ë‚˜ì˜¤ê²Œ ëœë‹¤.\në§ê·¸ëŒ€ë¡œ SERACH APIë¥¼ í†µí•´ì„œ ITEMSë¥¼ ì°¾ì§€ ëª»í•˜ê²Œ ëœ ê²½ìš°ì— í•´ë‹¹í•œë‹¤.\n8. Batch í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ìš”ì²­  í•œë²ˆì— ë¬¶ì–´ì„œ APIì— ì „ë‹¬í•˜ëŠ” ë°©ì‹ì´ë‹¤. ëª¨ë“  APIê°€ ì œê³µí•˜ëŠ” ê²ƒì€ ì•„ë‹ˆê¸´ í•˜ë‹¤! SpotifyëŠ” \u0026lsquo;Get Several Artists\u0026rsquo;í•˜ëŠ” ë²•ì„ ì œê³µí•˜ê³  ìˆë‹¤.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  def main(): try: conn = pymysql.connect(host=host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset=\u0026#39;utf8\u0026#39;) cursor = conn.cursor() except: logging.error(\u0026#39;could not connect to RDS\u0026#39;) sys.exit(1) headers = get_headers(client_id, client_secret) cursor.execute(\u0026#34;SELECT id FROM artists\u0026#34;) artists = [] for (id, ) in cursor.fetchall(): artists.append(id) artist_batch = [artists[i: i+50] for i in range(0, len(artists), 50)] for i in artist_batch: ids = \u0026#39;,\u0026#39;.join(i) URL = \u0026#39;https://api.spotify.com/v1/artists/?ids={}\u0026#39;.format(ids) r= requests.get(URL, headers=headers) raw = json.loads(r.text) print(raw) print(len(raw[\u0026#39;artists\u0026#39;])) sys.exit(0)   1 2  -- ì œëŒ€ë¡œ ì˜ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸í•´ë³´ê¸° select * from artist_genres limit 10;   9. MySQL í…Œì´ë¸”ë“¤ë¡œ ë°ì´í„° ì €ì¥ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  def main(): ## ... ì—¬ê¸°ê¹Œì§€ëŠ” ìœ„ì™€ ë˜‘ê°™ìŒ artist_batch = [artists[i: i+50] for i in range(0, len(artists), 50)] artist_genres = [] for i in artist_batch: ids = \u0026#39;,\u0026#39;.join(i) URL = \u0026#39;https://api.spotify.com/v1/artists/?ids={}\u0026#39;.format(ids) r= requests.get(URL, headers=headers) raw = json.loads(r.text) for artist in raw[\u0026#39;artists\u0026#39;]: for genre in artist[\u0026#39;genres\u0026#39;]: artist_genres.append( { \u0026#39;artist_id\u0026#39;: artist[\u0026#39;id\u0026#39;], \u0026#39;genre\u0026#39;: genre } ) for data in artist_genres: insert_row(cursor, data, \u0026#39;artist_genres\u0026#39;) conn.commit() sys.exit(0) ## ... ì•„ë˜ë„ ë‹¤ ë˜‘ê°™ìŒ   \n","description":"ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤","id":55,"section":"posts","tags":null,"title":"Python \u0026 MySQL","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part4_3/"},{"content":"Part 4. ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤ ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. Artist Data 1  SELECT genre, COUNT(*) FROM artist_genres GROUP BY 1 ORDER BY 2 DESC LIMIT 20;   2. Artist Genre Analysis with SQL 1 2 3  SELECT popularity, name FROM artists ORDER BY 1 DESC LIMIT 20; SELECT genre, COUNT(*) FROM artists t1 JOIN artist_genres t2 ON t2.artist_id = t1.id WHERE t1.popularity \u0026gt; 80 GROUP BY 1 ORDER BY 2 DESC LIMIT 20;    joinì„ í†µí•´ ERDì˜ ì¥ì ì„ í™œìš©í•˜ì—¬ ê¸°ì´ˆë¶„ì„ì„ í•  ìˆ˜ ìˆë‹¤.  ","description":"ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤","id":56,"section":"posts","tags":null,"title":"SQL í™œìš© (MySQL)","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part4_4/"},{"content":"Chapter 09. The Multivariate Normal Model ë³¸ í¬ìŠ¤íŒ…ì€ First Course in Bayesian Statistical Methodsë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.\n1. Linear Regression Model 2. Bayesian estimation for a regression model 3. Model Selection 1  library(tidyverse)     Code Example  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  ## Data load  data = dget(\u0026#39;https://www2.stat.duke.edu/~pdh10/FCBS/Inline/yX.o2uptake\u0026#39;) y = data[,1] X = data[,-1] inv = solve ## set prior g = length(y) nu0 = 1 s20 = summary(lm(y~-1+X))$sigma^2 n = length(y) p = ncol(X) ## MCMC setup S = 1000 set.seed(2021) BETA = matrix(NA, nrow=S, ncol=p) sigma2 = matrix(NA, nrow=S, ncol=1) BETA[1,] = inv(t(X) %*% X) %*% t(X) %*% y sigma2[1,] = s20 ## gibbs sampling nun = nu0 + n betan = (g/(g+1)) * inv(t(X) %*% X) %*% t(X) %*% y for(s in 2:S){ s2n = nu0*s20 + t(y-X%*%BETA[s-1,]) %*% (y-X%*%BETA[s-1,]) sigma2[s,] = 1/rgamma(1, shape=nun/2, rate=s2n/2) Sigman = (g/(g+1)) * sigma2[s,] * inv(t(X) %*% X) BETA[s,] = MASS::mvrnorm(n=1, betan, Sigman) } ## graph colnames(BETA) = colnames(X) gather(as.data.frame(BETA)) %\u0026gt;% ggplot(aes(y=value, fill=key)) + geom_histogram() + coord_flip() + facet_wrap(~key, scales=\u0026#39;free_x\u0026#39;) + ggtitle(\u0026#39;Posterior samples of Beta\u0026#39;) + theme(legend.position = \u0026#39;None\u0026#39;)   ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\r  ","description":"","id":57,"section":"posts","tags":null,"title":"Bayesian Linear Regression","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/fcb09/"},{"content":"Part 4. ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤ ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\nì´ í¬ìŠ¤íŒ…ì€ NoSQL ì¤‘ DynamoDBë¥¼ ìœ„ì£¼ë¡œ ì„œìˆ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n1. NoSQL vs. RDB  Not Only SQL ì°¨ì´ì (1) ë‹¤ì´ë‚˜ë¯¹ ìŠ¤í‚¤ë§ˆ  êµ¬ì¡°ë¥¼ ì •ì˜í•˜ì§€ ì•Šê³ ë„ Documents, Key Values ë“±ì„ ìƒì„± ê°ê°ì˜ Documentê°€ ì„œë¡œ ë‹¤ë¥¸ êµ¬ì¡°ë¡œ êµ¬ì„± ê°€ëŠ¥ ë°ì´í„°ë² ì´ìŠ¤ë“¤ë§ˆë‹¤ ë‹¤ë¥¸ syntax í•„ë“œ ì¶”ê°€ ê°€ëŠ¥   ì°¨ì´ì (2) Scalabilty  SQL DB: vertically scalable - CPU, RAM, SSDë¡œ ìš©ëŸ‰ ë¬¸ì œ í•´ê²°ê²° NoSQL DB: horizontally scalable - Sharding, Partitioningë¡œ ìš©ëŸ‰ ë¬¸ì œ í•´ê²°    2. Partition  ë°ì´í„° ë‚˜ëˆ„ê¸°(vertical \u0026amp; horizontal)  ë°ì´í„° ë§¤ë‹ˆì§€ë¨¼íŠ¸, í¼í¬ë¨¼ìŠ¤ ë“± ë‹¤ì–‘í•œ ì´ìœ      Vertical Partition  í…Œì´ë¸”ì„ ë” ì‘ì€ í…Œì´ë¸”ë¡œ ë‚˜ëˆ„ê¸°(Normalizationì™€ëŠ” ë‹¤ë¦„) ex. ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ì¹¼ëŸ¼ê³¼ ì•„ë‹Œ ì¹¼ëŸ¼ë“¤ ë‚˜ëˆ„ê¸°   Horizontal Partition  Schema / Structure ìì²´ë¥¼ ë³µì‚¬í•˜ì—¬ ë°ì´í„° ìì²´ë¥¼ Sharded Keyë¡œ ë¶„ë¦¬ NosQL DBì—ì„œëŠ” í•„ìˆ˜ì ì´ë‹¤.    3. DynamoDB  aws.amazon.com \u0026gt; DynamoDB Partition KeyëŠ” SQLì—ì„œ Primary Keyì™€ ìœ ì‚¬í•˜ë‹¤.  4. AWS SDK - Boto3 Package (DynamoDB ì—°ê²°) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import sys import os import boto3 import logging def main(): try: dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;, region_name=\u0026#39;ap-northeast-2\u0026#39;, endpoint_url=\u0026#39;http://dynamodb.ap-northeast-2.amazonaws.com\u0026#39;) except: logging.error(\u0026#34;could not connect to dynamodb\u0026#34;) sys.exit(1) print(\u0026#39;Success\u0026#39;) if __name__==\u0026#39;__main__\u0026#39;: main()   5. í…Œì´ë¸” ìƒì„± ë° ìŠ¤í™  Provisioned(í• ë‹¹ë¨) vs. On-demand(ì˜¨ë””ë§¨ë“œ)  6. Global Index, Local Index 7. INSERT(Single, Batch items) boto3 Documentation ì½ì–´ë³´ê¸°\nCreating a New Item 1 2 3 4 5 6 7 8 9  table.put_item( Item={ \u0026#39;username\u0026#39;: \u0026#39;janedoe\u0026#39;, \u0026#39;first_name\u0026#39;: \u0026#39;Jane\u0026#39;, \u0026#39;last_name\u0026#39;: \u0026#39;Doe\u0026#39;, \u0026#39;age\u0026#39;: 25, \u0026#39;account_type\u0026#39;: \u0026#39;standard_user\u0026#39;, } )   Batch Writing 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  with table.batch_writer() as batch: batch.put_item( Item={ \u0026#39;account_type\u0026#39;: \u0026#39;standard_user\u0026#39;, \u0026#39;username\u0026#39;: \u0026#39;johndoe\u0026#39;, \u0026#39;first_name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;last_name\u0026#39;: \u0026#39;Doe\u0026#39;, \u0026#39;age\u0026#39;: 25, \u0026#39;address\u0026#39;: { \u0026#39;road\u0026#39;: \u0026#39;1 Jefferson Street\u0026#39;, \u0026#39;city\u0026#39;: \u0026#39;Los Angeles\u0026#39;, \u0026#39;state\u0026#39;: \u0026#39;CA\u0026#39;, \u0026#39;zipcode\u0026#39;: 90001 } } ) batch.put_item( Item={ \u0026#39;account_type\u0026#39;: \u0026#39;super_user\u0026#39;, \u0026#39;username\u0026#39;: \u0026#39;janedoering\u0026#39;, \u0026#39;first_name\u0026#39;: \u0026#39;Jane\u0026#39;, \u0026#39;last_name\u0026#39;: \u0026#39;Doering\u0026#39;, \u0026#39;age\u0026#39;: 40, \u0026#39;address\u0026#39;: { \u0026#39;road\u0026#39;: \u0026#39;2 Washington Avenue\u0026#39;, \u0026#39;city\u0026#39;: \u0026#39;Seattle\u0026#39;, \u0026#39;state\u0026#39;: \u0026#39;WA\u0026#39;, \u0026#39;zipcode\u0026#39;: 98109 } } ) batch.put_item( Item={ \u0026#39;account_type\u0026#39;: \u0026#39;standard_user\u0026#39;, \u0026#39;username\u0026#39;: \u0026#39;bobsmith\u0026#39;, \u0026#39;first_name\u0026#39;: \u0026#39;Bob\u0026#39;, \u0026#39;last_name\u0026#39;: \u0026#39;Smith\u0026#39;, \u0026#39;age\u0026#39;: 18, \u0026#39;address\u0026#39;: { \u0026#39;road\u0026#39;: \u0026#39;3 Madison Lane\u0026#39;, \u0026#39;city\u0026#39;: \u0026#39;Louisville\u0026#39;, \u0026#39;state\u0026#39;: \u0026#39;KY\u0026#39;, \u0026#39;zipcode\u0026#39;: 40213 } } ) batch.put_item( Item={ \u0026#39;account_type\u0026#39;: \u0026#39;super_user\u0026#39;, \u0026#39;username\u0026#39;: \u0026#39;alicedoe\u0026#39;, \u0026#39;first_name\u0026#39;: \u0026#39;Alice\u0026#39;, \u0026#39;last_name\u0026#39;: \u0026#39;Doe\u0026#39;, \u0026#39;age\u0026#39;: 27, \u0026#39;address\u0026#39;: { \u0026#39;road\u0026#39;: \u0026#39;1 Jefferson Street\u0026#39;, \u0026#39;city\u0026#39;: \u0026#39;Los Angeles\u0026#39;, \u0026#39;state\u0026#39;: \u0026#39;CA\u0026#39;, \u0026#39;zipcode\u0026#39;: 90001 } } )   8. ë°ì´í„° ìš”ì²­ ë° ì œí•œì  boto3 Documentation ì½ì–´ë³´ê¸°\nGetting an Item 1 2 3 4 5 6  response = table.get_item( Key = { \u0026#39;artist_id\u0026#39;: \u0026#39;00FQb4jTyendYWaN8pK0wa\u0026#39;, \u0026#39;id\u0026#39;: \u0026#39;0Oqc0kKFsQ6MhFOLBNZIGX\u0026#39; } )   ClientError: An error occurred (ValidationException) when calling the GetItem operation: The provided key element does not match the schema\rìœ„ì™€ ê°™ì€ ì—ëŸ¬ê°€ ëœ¬ë‹¤ë©´, keyê°’ì„ ì œëŒ€ë¡œ ë‹¤ ë„£ì—ˆëŠ”ì§€ í™•ì¸í•´ë³¸ë‹¤.\nQuerying and Scanning  Querying: Primary Key ê°’ì„ ì•Œê³  ìˆì„ ë•Œ í™œìš© Scanning: Primary Key ê°’ì„ ëª¨ë¥´ì§€ë§Œ, ë‹¤ë¥¸ attributeë¥¼ ì•Œ ë•Œ í™œìš©\n- Scanì€ ëª¨ë“  í–‰ì„ ë‹¤ í›‘ëŠ” ë¹„íš¨ìœ¨ì ì¸ ê¸°ëŠ¥ì´ë¯€ë¡œ ê¼­ í•„ìš”í•  ë•Œë§Œ ì“°ëŠ” ê²ƒì´ ê¶Œì¥ëœë‹¤.  1 2 3 4 5 6 7 8 9 10 11 12  # Querying response = table.query( KeyConditionExpression=Key(\u0026#39;artist_id\u0026#39;).eq(\u0026#39;00FQb4jTyendYWaN8pK0wa\u0026#39;), FilterExpression=Attr(\u0026#39;popularity\u0026#39;).gt(75) #queryë„ filterexpresson ì“¸ ìˆ˜ ìˆë‹¤! ) print(len(response[\u0026#39;Items\u0026#39;])) # Scanning response = table.scan( FilterExpression=Attr(\u0026#39;popularity\u0026#39;).gt(75) ) print(len(response[\u0026#39;Items\u0026#39;]))   \n","description":"ë°ì´í„°ì˜ ì´í•´ì™€ ë°ì´í„°ë² ì´ìŠ¤","id":58,"section":"posts","tags":null,"title":"NoSQL (DynamoDB)","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part4_5/"},{"content":"Part 5. ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ êµ¬ì¶• ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. ë°ì´í„° ë ˆì´í¬ vs. ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤    êµ¬ë¶„ ë°ì´í„° ë ˆì´í¬ ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤     Data Structure Raw Processed   Purpose of Data Not yet Determined In Use   Users Data Scientists Business Professionals   Accessibility High / Quick to update Complicated / Costly     Schemaì˜ ì°¨ì´ê°€ ê°€ì¥ í¬ë‹¤. ë°ì´í„°ë ˆì´í¬ëŠ” ì°¨ì„¸ëŒ€ ì‹œìŠ¤í…œìœ¼ë¡œì„œ ë”ìš± ì£¼ëª© ë°›ê²Œ ë  ê²ƒì´ë‹¤. ETL(Extract-Transform-Load)  2. ë°ì´í„° ë ˆì´í¬ ì•„í‚¤í…ì²˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì˜ ê´€ì‹¬ì‚¬  ì–´ë–»ê²Œ ê´€ë¦¬ ìŠ¤ì¼€ì¥´ë§ ì—ëŸ¬ í•¸ë“¤ë§ ë°ì´í„° ë°±í•„  3. AWS S3  AWS S3 ë²„í‚· ìƒì„± cf. AWS Glue: table schema ê´€ë¦¬ (ë°ì´í„° ë ˆì´í¬ëŠ” ë°”ë€ë‹¤.)  4. JSON, Parquet 1 2 3 4 5  # JSON í˜•ì‹ìœ¼ë¡œ í•˜ëŠ” ë²• with open(\u0026#39;top_tracks.json\u0026#39;, \u0026#39;w\u0026#39;) as f: for i in top_tracks: json.dump(i, f) f.write(os.linesep)   1 2 3 4 5 6 7 8 9 10 11  # Parquet í˜•ì‹ìœ¼ë¡œ í•˜ëŠ” ë²• # í¼í¬ë¨¼ìŠ¤ì ìœ¼ë¡œ ìš°ìˆ˜í•´ì§„ë‹¤. top_tracks = pd.DataFrame(raw) top_tracks.to_parquet(\u0026#39;top-tracks.parquet\u0026#39;, engine=\u0026#39;pyarrow\u0026#39;, compressions=\u0026#39;snappy\u0026#39;) dt = datetime.utcnow().strftime(\u0026#34;%Y-%m-%d\u0026#34;) s3 = boto3.resource(\u0026#39;s3\u0026#39;) object = s3.Object(\u0026#39;spotify-artists\u0026#39;, \u0026#39;dt={}/top-tracks.parquet\u0026#39;.format(dt)) data = open(\u0026#39;top-tracks.parquet\u0026#39;, \u0026#39;rb\u0026#39;) object.put(Body=data)   5. S3 Data Lake ImportError: Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\rSpotify audio features\n","description":"ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ êµ¬ì¶•","id":59,"section":"posts","tags":null,"title":"ë°ì´í„° ë ˆì´í¬","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part5_1/"},{"content":"Part 5. ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ êµ¬ì¶• ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. Presto 2. Serverless 3. AWS Athena 4. í…Œì´ë¸” ìƒì„± 5. ë°ì´í„° ì¿¼ë¦¬ ","description":"ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ êµ¬ì¶•","id":60,"section":"posts","tags":null,"title":"S3 Athena","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part5_2/"},{"content":"Part 5. ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ êµ¬ì¶• ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. Apache Spark 2. EC-2 ì œí”Œë¦° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ","description":"ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ êµ¬ì¶•","id":61,"section":"posts","tags":null,"title":"Apache Spark","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part5_3/"},{"content":"Part 5. ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ êµ¬ì¶• ë³¸ í¬ìŠ¤íŒ…ì€ íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤(FastCampus)ì˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì˜¬ì¸ì› íŒ¨í‚¤ì§€ Onlineì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.\n1. Spark RDD 2. Spark Dataframes 3. Select Subset Columns 4. Filter Rows 5. Create UDF 6. Join 7. SQL 8. ë°ì´í„°ë¶„ì„ with Spark 9. ì‹œê°í™” with Spark ","description":"ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ êµ¬ì¶•","id":62,"section":"posts","tags":null,"title":"Pyspark","uri":"https://jiwooblog.netlify.app/posts/dataengineering/fc_part5_4/"},{"content":"Bias-Variance Tradeoff $$\\text{let } y = f(x) + \\varepsilon, \\text{ where } \\varepsilon \\text{ ~ } N(0, \\sigma^2)$$\n\\begin{align}\rMSE(\\hat{y}) \u0026amp;= E[(y-\\hat{y})^2] \\\\\r\u0026amp;= E[(f(x) + \\varepsilon - \\hat{f}(x))^2] \\\\\r\u0026amp;= E[(f(x)-\\hat{f}(x))^2] + E[\\varepsilon^2] + 2E[\\varepsilon(f(x) - \\hat{f}(x))] \\\\\r\u0026amp;= E[(f(x) - E(\\hat{f}(x)) + E(\\hat{f}(x)) - \\hat{f}(x) )^2] + \\sigma^2 \\\\\r\u0026amp;= E[(f(x) - E(\\hat{f}(x)))^2] + E[(\\hat{f}(x)-E(\\hat{f}(x)))^2] + 2(f(x) - E(\\hat{f}(x)))E[\\hat{f}(x) - E(\\hat{f}(x))] + \\sigma^2 \\\\\r\u0026amp;= {bias[\\hat{f}(x)]}^2 + Var(\\hat{f}(x)) + \\sigma^2 \\\\\r\u0026amp;= bias^2(\\hat{y}) + Var(\\hat{y}) + \\sigma^2\r\\end{align}\n$bias^2(\\hat{y})$: ì°¸ê°’ê³¼ ì¶”ì •ì¹˜ í‰ê· ì˜ ì°¨ì´ (ê°„ë‹¨í•œ ëª¨í˜•ì¼ìˆ˜ë¡ ë†’ìŒ)\n$Var(\\hat{y})$: ì¶”ì •ì¹˜ì™€ ì¶”ì •ì¹˜ í‰ê· ì˜ ì°¨ì´ (ë³µì¡í•œ ëª¨í˜•ì¼ìˆ˜ë¡ ë†’ìŒ)\n$\\sigma^2$: irreducible error\ní¸í–¥(bias)ëŠ” ê°„ë‹¨í•œ ëª¨í˜•ì¼ìˆ˜ë¡ ë†’ìœ¼ë©°, ë¶„ì‚°(variance)ëŠ” ë³µì¡í•œ ëª¨í˜•ì¼ìˆ˜ë¡ ë†’ë‹¤. ì´ë•Œ $\\sigma^2$ëŠ” ì¤„ì¼ ìˆ˜ ì—†ëŠ” ì˜¤ì°¨ì´ë‹¤. ê·¸ë ‡ë‹¤ë©´ ì ì ˆí•œ ëª¨í˜• ì„ íƒê³¼ ì‹¤í—˜ì„¤ê³„ë¥¼ í†µí•´ì„œ ê³¼ì í•©ì„ ë°©ì§€í•´ì•¼ í•˜ëŠ”ë°, ì´ëŸ¬í•œ ë¶€ë¶„ì€ ë¨¸ì‹ ëŸ¬ë‹ì„ í•˜ë©´ì„œ íŠ¹íˆ ë” ì£¼ì˜í•´ì•¼ í•˜ëŠ” ë¶€ë¶„ì´ë‹¤.\nbiasì™€ varianceì˜ ì°¨ì´ê°€ í—·ê°ˆë¦°ë‹¤ë©´ ì•„ë˜ì˜ ê·¸ë¦¼ì„ ë³´ë©´ í›¨ì”¬ ì˜ ì´í•´ê°€ ë  ê²ƒì´ë‹¤.\nì°¸ê³  [1] https://www.endtoend.ai/blog/bias-variance-tradeoff-in-reinforcement-learning/\ní˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"","id":63,"section":"posts","tags":null,"title":"í¸í–¥-ë¶„ì‚° Tradeoff","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/bias_variance/"},{"content":"Performance Measure ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ì§€í‘œì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆë‹¤. ê·¸ì¤‘ì—ì„œ ëŒ€í‘œì ì¸ ëª‡ ê°œë¥¼ ì•Œì•„ë³´ê³ ì í•œë‹¤.\n1. Accuracy $$Accuracy = \\frac{\\text{correctly predicted}}{\\text{all dataset}}$$\nAccuracyëŠ” balanced dataê°€ ì•„ë‹ˆë¼ë©´ ì¢‹ì€ ì§€í‘œë¡œì„œì˜ ì—­í• ì„ í•˜ê¸° í˜ë“¤ë‹¤. ì™œëƒí•˜ë©´ A,B,C,Dë¼ëŠ” ê·¸ë£¹ì´ ìˆì„ ë•Œ, B~Dê°€ ê°ê° 10ê°œì˜ ì¼€ì´ìŠ¤ ë°–ì— ì—†ê³  Aê°€ í˜¼ìì„œ 500ê°œì˜ ì¼€ì´ìŠ¤ê°€ ìˆë‹¤ê³  ê°€ì •í•œë‹¤ë©´ Accuracy ì§€í‘œëŠ” A ê·¸ë£¹ì— ì˜í•´ ì¢Œì§€ìš°ì§€ ë  ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤.\n2. Precision  Given a class prediction from the classifier, how likely is to be correct?\në‚´ê°€ \u0026lsquo;TRUE\u0026rsquo;ë¼ê³  ë§í•œ ê²ƒ ì¤‘ì—ì„œ ëª‡ %ê°€ ì§„ì§œ \u0026lsquo;TRUE\u0026rsquo;ì¸ê°€?\n $$Precision = \\frac{TP}{TP + FP} $$\nTP: True Positive, FP: False Positive\n3. Recall  Given a class, will the classifier detect it?\nì§„ì§œ \u0026lsquo;TRUE\u0026rsquo; ì¤‘ì—ì„œ ë‚´ê°€ \u0026lsquo;TRUE\u0026rsquo;ë¼ê³  ë§í•œ ê²ƒì€ ëª‡ %ì¸ê°€?\n $$Recall = \\frac{TP}{TP + FN} $$\nTP: True Positive, FN: False Negative\n4. F1 Score Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· \n$$F1 \\text{ score} = 2 \\times \\frac{\\text{precision}\\times\\text{recall}}{\\text{precision}+\\text{recall}} $$\n ì¶œì²˜: https://www.youtube.com/watch?v=HBi-P5j0Kec F1 ScoreëŠ” ìƒëŒ€ì ìœ¼ë¡œ imbalanced dataì—ì„œë„ íš¨ê³¼ê°€ ì¢‹ë‹¤. ê·¸ ì´ìœ ëŠ” ìœ„ ê·¸ë¦¼ì„ í†µí•´ì„œ ì´í•´í•  ìˆ˜ ìˆë‹¤.\nì¡°í™”í‰ê· ì€ ë” ê·¹ë‹¨ì¹˜ì— ëŒ€í•´ì„œ í˜ë„í‹°ë¥¼ ì£¼ê¸° ë•Œë¬¸ì´ë‹¤.\nì°¸ê³  [1] í—ˆë¯¼ì„ ìœ íŠœë¸Œ\n","description":"","id":64,"section":"posts","tags":null,"title":"F1 Score","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/performance_measure/"},{"content":"Fisher Information Fisher informationì€ score functionì˜ ë¶„ì‚°ì´ë‹¤. ì´ ì ì„ ëª…ì‹¬í•´ì„œ ì˜ë¯¸ë¥¼ ìƒê°í•´ë³´ì. ì•„ë˜ëŠ” Fisher informationì„ ë‹¤ì–‘í•œ ê¼´ë¡œ í‘œí˜„í•´ë³¸ ê²ƒì´ë‹¤.\n\\begin{align}\rI(\\theta;x) \u0026amp;= Var(\\frac{\\partial}{\\partial\\theta}logf(x;\\theta)) \\\\\r\u0026amp;= E\\bigg[\\Big(\\frac{\\partial}{\\partial\\theta}logf(x;\\theta)\\Big)^2\\bigg] \\\\\r\u0026amp;= -E\\bigg[\\frac{\\partial^2}{\\partial\\theta^2}log(f(x;\\theta)\\bigg]\r\\end{align}\nê³„ì‚° ì¦ëª… ìœ„ì— ëŒ€í•œ ìì„¸í•œ ê³„ì‚° ì¦ëª…ì€ ì•„ë˜ì™€ ê°™ë‹¤.\nìš°ì„ , score functionì˜ í‰ê· ì´ 0ì„ì„ êµ¬í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•œë‹¤.\n$$\\int \\frac{\\partial}{\\partial\\theta}logf(x;\\theta)f(x;\\theta)=0 $$\nì–‘ë³€ì„ $\\theta$ë¡œ ë¯¸ë¶„í•´ì¤€ë‹¤.\n$$\\int\\frac{\\partial^2}{\\partial\\theta^2}logf(x;\\theta)f(x;\\theta)dx + \\int\\frac{\\partial}{\\partial\\theta}logf(x;\\theta)f'(x;\\theta)dx = 0 $$\nì˜¤ë¥¸ìª½ ë¶€ë¶„ì„ ìš°ë³€ìœ¼ë¡œ ì´í•­í•˜ì—¬ ì •ë¦¬í•´ì£¼ë©´ ì•„ë˜ì™€ ê°™ë‹¤.\n\\begin{align}\rE\\bigg[\\frac{\\partial^2}{\\partial\\theta^2}logf(x;\\theta)\\bigg] \u0026amp;= -\\int\\frac{\\partial}{\\partial\\theta}logf(x;\\theta)f'(x;\\theta)dx \\\\ \u0026amp;= -\\int\\frac{\\partial}{\\partial\\theta}logf(x;\\theta)\\frac{f'(x;\\theta)}{f(x;\\theta)}f(x;\\theta)dx \\\\\r\u0026amp;= -\\int\\bigg(\\frac{\\partial}{\\partial\\theta}logf(x;\\theta)\\bigg)^2f(x;\\theta)dx \\\\\r\u0026amp;= -E\\bigg[\\Big(\\frac{\\partial}{\\partial\\theta}logf(x;\\theta)\\Big)^2\\bigg]\r\\end{align}\n","description":"","id":65,"section":"posts","tags":null,"title":"Fisher Information","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/fisher_information/"},{"content":"Jeffrey\u0026rsquo;s Prior 1. uninformative priorì˜ ì œí•œì  uninformative priorë¥¼ ì„ì˜ë¡œ ì£¼ê²Œ ë  ê²½ìš°, ì—¬ëŸ¬ ë¬¸ì œì ì´ ìˆì„ ìˆ˜ ìˆëŠ”ë° ê·¸ ì¤‘ í•˜ë‚˜ëŠ” ë³€ìˆ˜ë³€í™˜ì— ì·¨ì•½í•´ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì ì´ë‹¤.\nì˜ˆë¥¼ ë“¤ì–´, $p(\\theta) \\propto 1$ë¼ê³  uninformative priorë¥¼ ì£¼ì. ê·¸ë¦¬ê³  $ \\phi = exp(\\theta)$ë¼ê³  ê°€ì •í•´ë³´ì.\n\\begin{align}\rp(\\phi) \u0026amp;\\propto p(\\theta) \\bigg|\\frac{d\\theta}{d\\phi}\\bigg| \\\\\r\u0026amp;\\propto \\frac{1}{\\phi} \\neq 1\r\\end{align}\në³€ìˆ˜ë³€í™˜ í›„ì—ëŠ” priorê°€ uninformativeí•˜ì§€ ì•Šê²Œ ë˜ì–´ë²„ë¦¼ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n2. Jeffrey\u0026rsquo;s prior ê·¸ë ‡ë‹¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ ë³€ìˆ˜ë³€í™˜ì— ê°•ê±´í•œ priorë¥¼ ì¤„ ìˆ˜ ìˆì„ê¹Œ?\n$$\\pi(\\phi) \\propto \\sqrt{I(\\theta)} $$\nìœ„ì™€ ê°™ì´ ì£¼ë©´ ëœë‹¤. ì—¬ê¸°ì„œ $I(\\theta) $ëŠ” Fisher Informationì„ ëœ»í•˜ë©°, ì•„ë˜ì™€ ê°™ë‹¤.\n$$I(\\theta) = -E\\Big[ \\frac{\\partial^2}{\\partial{\\theta}^2}ln L(x|\\theta) \\Big]$$\n3. ì¦ëª… ì´ë¥¼ í•œ ë²ˆ ì¦ëª…í•´ë³´ì. ë‹¨, $\\phi = f(\\theta), \\ f:\\text{one-to-one}$ì´ë‹¤.\n\\begin{align}\rp(\\theta) \\propto \\sqrt{I(\\theta)} \u0026amp;\\xrightarrow{?} \\ p(\\phi) \\propto \\sqrt{I(\\phi)} \\\\\r\\\\\rp(\\phi) \u0026amp;= p(\\theta) \\bigg| \\frac{\\partial\\theta}{\\partial\\phi} \\bigg| \\\\\r\\\\\rI(\\phi) \u0026amp;= -E\\bigg[\\frac{\\partial^2}{\\partial\\phi^2}lnL(y|\\phi) \\bigg] \\\\\r\u0026amp;= E\\bigg[\\big(\\frac{\\partial}{\\partial\\phi}lnL(y|\\phi) \\big)^2 \\bigg] \\\\\r\u0026amp;= E\\bigg[\\big(\\frac{\\partial}{\\partial\\theta}lnL(y|\\theta) \\big)^2 \\big(\\frac{\\partial\\theta}{\\partial\\phi} \\big)^2 \\bigg] \\\\ \u0026amp;= I(\\theta) \\bigg|\\frac{\\partial\\theta}{\\partial\\phi} \\bigg|^2\\\\\r\\\\\rp(\\phi) \u0026amp;= p(\\theta)\\bigg|\\frac{\\partial\\theta}{\\partial\\phi} \\bigg| \\\\\r\u0026amp;\\propto \\sqrt{I(\\theta)}\\bigg|\\frac{\\partial\\theta}{\\partial\\phi} \\bigg| \\\\\r\u0026amp;=\\sqrt{I(\\phi)} \\\\\r\\\\\r\\rightarrow p(\\phi) \u0026amp;\\propto \\sqrt{I(\\phi)}\r\\end{align}\ní˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"","id":66,"section":"posts","tags":null,"title":"Jeffrey's Prior","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/jeffrey_prior/"},{"content":"Score Function $X \\text{ ~ } f(x;\\theta)$ì¼ ë•Œ, score function $s(\\theta;x)$ì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•œë‹¤.\n$$\\frac{\\partial}{\\partial\\theta}logf(x;\\theta) $$\ní‰ê·  ê³„ì‚° ì¦ëª… \\begin{align}\rE\\big[s(\\theta;x) \\big] \u0026amp;= \\int\\bigg[\\frac{\\partial}{\\partial\\theta}logf(x;\\theta)\\bigg]f(x;\\theta)dx \\\\\r\u0026amp;= \\int\\frac{f'(x;\\theta)}{f(x;\\theta)}f(x;\\theta)dx \\\\\r\u0026amp;= \\int f'(x;\\theta)dx \\\\\r\u0026amp;= \\frac{\\partial}{\\partial\\theta}\\int f(x;\\theta)dx \\\\\r\u0026amp;= \\frac{\\partial}{\\partial\\theta}1 = 0\r\\end{align}\nì˜ë¯¸ score functionì€ log likelihoodì˜ ê¸°ìš¸ê¸°ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ëŠ” ë°ì—ì„œ ì˜ë¯¸ê°€ ìˆë‹¤.\nscore functionì˜ í‰ê· ì´ 0ì´ë¼ëŠ” ê²ƒì˜ ì˜ë¯¸ë¥¼ ê·¸ë˜í”„ë¥¼ likelihood ê·¸ë˜í”„ë¥¼ ìƒìƒí•˜ì—¬ ìƒê°í•´ë³´ì.\n","description":"","id":67,"section":"posts","tags":null,"title":"Score Function","uri":"https://jiwooblog.netlify.app/posts/statistics/statistics/score_function/"},{"content":"Empirical Bayes ë² ì´ì§€ì•ˆì€ ê¸°ë³¸ì ìœ¼ë¡œ prior, ì¦‰ ì‚¬ì „í™•ë¥ ì„ ì„¤ì •í•œë‹¤.\nê·¸ëŸ°ë° ì´ë•Œ data density(histogram)ì— ë¹„ìŠ·í•œ ëª¨ì–‘ì„ ê°–ë„ë¡ priorë¥¼ ì„¤ì •í•˜ê³ ì í•˜ëŠ” ê²½ìš°ë„ ìˆëŠ”ë°, ì´ë¥¼ Empirical Bayesë¼ê³  í•œë‹¤.\nì‚¬ì „í™•ë¥ ì¸ë° ì™œ ë°ì´í„°ë¥¼ ë³´ê³  ì„¤ì •í•˜ëŠ”ì§€ì— ëŒ€í•œ ì˜ë¬¸ì´ ìƒê¸¸ ìˆ˜ë„ ìˆê¸´ í•œë‹¤\u0026hellip;\ní˜¹ì‹œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜ëª»ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì ê·¹ ë°˜ì˜í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ","description":"","id":68,"section":"posts","tags":null,"title":"Empirical Bayes","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/empricialbayes/"},{"content":"Gibbs Sampler ê¸°ë³¸ ì›ë¦¬ (ì¶”í›„ ì—…ë°ì´íŠ¸)\nì˜ˆì‹œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  ## Data load  data = dget(\u0026#39;https://www2.stat.duke.edu/~pdh10/FCBS/Inline/yX.o2uptake\u0026#39;) y = data[,1] X = data[,-1] inv = solve ## set prior g = length(y) nu0 = 1 s20 = summary(lm(y~-1+X))$sigma^2 n = length(y) p = ncol(X) ## setup S = 1000 set.seed(2021) BETA = matrix(NA, nrow=S, ncol=p) sigma2 = matrix(NA, nrow=S, ncol=1) BETA[1,] = inv(t(X) %*% X) %*% t(X) %*% y sigma2[1,] = s20 ## gibbs sampling nun = nu0 + n betan = (g/(g+1)) * inv(t(X) %*% X) %*% t(X) %*% y for(s in 2:S){ s2n = nu0*s20 + t(y-X%*%BETA[s-1,]) %*% (y-X%*%BETA[s-1,]) sigma2[s,] = 1/rgamma(1, shape=nun/2, rate=s2n/2) Sigman = (g/(g+1)) * sigma2[s,] * inv(t(X) %*% X) BETA[s,] = MASS::mvrnorm(n=1, betan, Sigman) } ## graph colnames(BETA) = colnames(X) gather(as.data.frame(BETA)) %\u0026gt;% ggplot(aes(y=value, fill=key)) + geom_histogram() + coord_flip() + facet_wrap(~key, scales=\u0026#39;free_x\u0026#39;) + ggtitle(\u0026#39;Posterior samples of Beta\u0026#39;) + theme(legend.position = \u0026#39;None\u0026#39;)   ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\rì¢…ë¥˜ 1. Systematic Sweep Gibbs Sampler ëª¨ë“  ëª¨ìˆ˜ì— ëŒ€í•´ ìƒ˜í”Œë§ì„ ë°˜ë³µí•˜ì—¬ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•\n2. Random Sweep Gibbs Sampler ë¬´ì‘ìœ„ë¡œ ëª¨ìˆ˜ë¥¼ ë½‘ì•„ì„œ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•\n3. Grouped Gibbs Sampler ì—¬ëŸ¬ ê°œì˜ ëª¨ìˆ˜ë¥¼ í•œë²ˆì— ë½‘ì•„ì„œ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•\nì´ë•Œ ëª¨ìˆ˜ ê°„ì˜ ì—°ê´€ì„±ì´ ìƒê¸´ë‹¤.\n4. Collapsed Gibbs Sampler ì ë¶„ì„ í†µí•´ì„œ íŠ¹ì • ëª¨ìˆ˜ì™€ ë…ë¦½ì ì¸ ë¶„í¬ë¥¼ ê³„ì‚°í•œ í›„, ìƒ˜í”Œë§í•˜ì—¬ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•\nì°¸ê³ ì‚¬ì´íŠ¸ [1] https://niceguy1575.tistory.com/entry/%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%ED%86%B5%EA%B3%84%ED%95%99-4-Gibbs-Sampler%EA%B9%81%EC%8A%A4-%EC%83%98%ED%94%8C%EB%9F%AC-%EC%9D%98-%EC%A2%85%EB%A5%98%EC%99%80-%EC%84%B1%EC%A7%88\n","description":"","id":69,"section":"posts","tags":null,"title":"Gibbs Sampler","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/gibbs_sampler/"},{"content":"fread íŒ¨í‚¤ì§€ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¹ ë¥´ê²Œ ë¶ˆëŸ¬ì˜¤ê¸° ì•½ 24000í–‰ì˜ ìƒ˜í”Œ csvê°€ ìˆë‹¤ê³  ê°€ì •í•˜ì. ê·¸ë ‡ë‹¤ë©´ freadì™€ read.csvì˜ ì„±ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11  library(data.table) fread(\u0026#39;sample.csv\u0026#39;) #ì•½ 24000x3 system.time(fread(\u0026#39;sample.csv\u0026#39;)) # ì‚¬ìš©ì ì‹œìŠ¤í…œ elapsed  # 0.02 0.00 0.01  system.time(read.csv(\u0026#39;sample.csv\u0026#39;)) # ì‚¬ìš©ì ì‹œìŠ¤í…œ elapsed  # 0.74 0.03 0.77   read.csvëŠ” 0.77ì´ˆê°€ ê±¸ë¦¬ëŠ” ë°ì— ë°˜í•´ freadëŠ” 0.01ì´ˆ ë§Œì— ì½ì–´ì™”ë‹¤.\nì´ì™¸ì—ë„ 3ë°±ë§Œ í–‰ì˜ csvìœ¼ë¡œ ì‹¤í—˜í•´ë³¸ ê²°ê³¼, ê°ê° 2ì´ˆì™€ 33ì´ˆë¡œ ê·¸ ì„±ëŠ¥ ì°¨ì´ê°€ ë”ìš± ë„ë“œë¼ì§ì„ ì•Œ ìˆ˜ ìˆì—ˆë‹¤.\n","description":"","id":70,"section":"posts","tags":null,"title":"fread","uri":"https://jiwooblog.netlify.app/posts/r/fread/"},{"content":"\r\ry \u0026lt;- c(93, 112, 122, 135, 122, 150, 118, 90, 124, 114)\rn \u0026lt;- length(y)\rs2 \u0026lt;- var(y)\rmy \u0026lt;- mean(y) \r# helper functions to sample from and evaluate\r# scaled inverse chi-squared distribution\rrsinvchisq \u0026lt;- function(n, nu, s2, ...) nu*s2 / rchisq(n , nu, ...)\rdsinvchisq \u0026lt;- function(x, nu, s2){\rexp(log(nu/2)*nu/2 - lgamma(nu/2) + log(s2)/2*nu - log(x)*(nu/2+1) - (nu*s2/2)/x)\r}\rns \u0026lt;- 1000\rsigma2 \u0026lt;- rsinvchisq(ns, n-1, s2)\rmu \u0026lt;- my + sqrt(sigma2/n)*rnorm(length(sigma2))\rsigma \u0026lt;- sqrt(sigma2)\rynew \u0026lt;- rnorm(ns, mu, sigma)\rt1l \u0026lt;- c(90, 150)\rt2l \u0026lt;- c(10, 60)\rnl \u0026lt;- c(50, 185)\rt1 \u0026lt;- seq(t1l[1], t1l[2], length.out = ns)\rt2 \u0026lt;- seq(t2l[1], t2l[2], length.out = ns)\rxynew \u0026lt;- seq(nl[1], nl[2], length.out = ns)\r# multiplication by 1./sqrt(s2/n) is due to the transformation of\r# variable z=(x-mean(y))/sqrt(s2/n), see BDA3 p. 21\rpm \u0026lt;- dt((t1-my) / sqrt(s2/n), n-1) / sqrt(s2/n)\rpmk \u0026lt;- density(mu, adjust = 2, n = ns, from = t1l[1], to = t1l[2])$y\r# the multiplication by 2*t2 is due to the transformation of\r# variable z=t2^2, see BDA3 p. 21\rps \u0026lt;- dsinvchisq(t2^2, n-1, s2) * 2*t2\rpsk \u0026lt;- density(sigma, n = ns, from = t2l[1], to = t2l[2])$y\r# multiplication by 1./sqrt(s2/n) is due to the transformation of variable\r# see BDA3 p. 21\rp_new \u0026lt;- dt((xynew-my) / sqrt(s2*(1+1/n)), n-1) / sqrt(s2*(1+1/n))\r# Combine grid points into another data frame\r# with all pairwise combinations\rdfj \u0026lt;- data.frame(t1 = rep(t1, each = length(t2)),\rt2 = rep(t2, length(t1)))\rdfj$z \u0026lt;- dsinvchisq(dfj$t2^2, n-1, s2) * 2*dfj$t2 * dnorm(dfj$t1, my, dfj$t2/sqrt(n))\r# breaks for plotting the contours\rcl \u0026lt;- seq(1e-5, max(dfj$z), length.out = 6)\rDemo 3.1\rdfm \u0026lt;- data.frame(t1, Exact = pm, Empirical = pmk) %\u0026gt;% gather(grp, p, -t1)\rmargmu \u0026lt;- ggplot(dfm) +\rgeom_line(aes(t1, p, color = grp)) +\rcoord_cartesian(xlim = t1l) +\rlabs(title = \u0026#39;Marginal of mu\u0026#39;, x = \u0026#39;\u0026#39;, y = \u0026#39;\u0026#39;) +\rscale_y_continuous(breaks = NULL) +\rtheme(legend.background = element_blank(),\rlegend.position = c(0.75, 0.8),\rlegend.title = element_blank())\rdfs \u0026lt;- data.frame(t2, Exact = ps, Empirical = psk) %\u0026gt;% gather(grp, p, -t2)\rmargsig \u0026lt;- ggplot(dfs) +\rgeom_line(aes(t2, p, color = grp)) +\rcoord_cartesian(xlim = t2l) +\rcoord_flip() +\rlabs(title = \u0026#39;Marginal of sigma\u0026#39;, x = \u0026#39;\u0026#39;, y = \u0026#39;\u0026#39;) +\rscale_y_continuous(breaks = NULL) +\rtheme(legend.background = element_blank(),\rlegend.position = c(0.75, 0.8),\rlegend.title = element_blank())\rjoint1labs \u0026lt;- c(\u0026#39;Samples\u0026#39;,\u0026#39;Exact contour\u0026#39;)\rjoint1 \u0026lt;- ggplot() +\rgeom_point(data = data.frame(mu,sigma), aes(mu, sigma, col = \u0026#39;1\u0026#39;), size = 0.1) +\rgeom_contour(data = dfj, aes(t1, t2, z = z, col = \u0026#39;2\u0026#39;), breaks = cl) +\rcoord_cartesian(xlim = t1l,ylim = t2l) +\rlabs(title = \u0026#39;Joint posterior\u0026#39;, x = \u0026#39;\u0026#39;, y = \u0026#39;\u0026#39;) +\rscale_y_continuous(labels = NULL) +\rscale_x_continuous(labels = NULL) +\rscale_color_manual(values=c(\u0026#39;blue\u0026#39;, \u0026#39;black\u0026#39;), labels = joint1labs) +\rguides(color = guide_legend(nrow = 1, override.aes = list(\rshape = c(16, NA), linetype = c(0, 1), size = c(2, 1)))) +\rtheme(legend.background = element_blank(),\rlegend.position = c(0.5, 0.9),\rlegend.title = element_blank())\rgrid.arrange(joint1, margsig, margmu, nrow = 2)\r\r","description":"","id":71,"section":"posts","tags":null,"title":"BDA Example","uri":"https://jiwooblog.netlify.app/posts/statistics/bayesian/bda_example/"},{"content":"\r\r\r\r\r\r.scroll-100 {\rmax-height: 100px;\roverflow-y: auto;\rbackground-color: 'white';\r}\r\rpre {\rmax-height: 300px;\roverflow-y: auto;\rbackground-color: 'white';\r}\rpre[class] {\rmax-height: 100px;\rbackground-color: 'green';\r}\r\r\r# plotly\r```r\rlibrary(ggplot2)\rlibrary(plotly)\rlibrary(gapminder)\r1 2 3 4 5 6 7 8  p \u0026lt;- gapminder %\u0026gt;% filter(year==1977) %\u0026gt;% ggplot( aes(gdpPercap, lifeExp, size = pop, color=continent)) + geom_point() + scale_x_log10() + theme_bw() ggplotly(p)   \r{\"x\":{\"data\":[{\"x\":[3.69111835304969,3.47837128685849,3.0124834262036,3.50716177034781,2.87121498358872,2.74515544499733,3.25125676748187,3.04507811557752,3.05460729073385,3.06915101836112,2.90078062155373,3.51310821042633,3.40101028408395,3.48879895792208,3.44490216214739,2.98162238872728,2.7039391611549,2.74570576546197,4.3373708614867,2.94682314869669,2.99704718642708,2.94185210799775,2.88350583493768,3.10298675433845,2.87237164152654,2.8063987207202,4.34145849934605,3.18871158763867,2.82166002181421,2.83657428165302,3.17536457562432,3.56948896052176,3.37486193965761,2.70098023955392,3.58843821514052,2.90789326381397,3.29709308978461,3.6354640490023,2.82612704524949,3.23994022438144,3.19361683040004,3.12978175413031,3.16166517152032,3.90464260358686,3.34301221488094,3.57765383934322,2.9833972607425,3.185478974435,3.49427662628827,2.92620510614229,3.20103869689067,2.83606300605042],\"y\":[58.014,39.483,49.19,59.319,46.137,45.91,49.355,46.775,47.383,50.939,47.804,55.625,52.374,46.519,53.319,42.024,44.535,44.51,52.79,41.842,51.756,40.762,37.465,56.155,52.208,43.764,57.442,46.881,43.767,41.714,50.852,64.93,55.73,42.495,56.437,41.291,44.514,67.064,45,58.55,48.879,36.788,41.974,55.527,47.8,52.537,49.919,52.887,59.837,50.35,51.386,57.674],\"text\":[\"gdpPercap: 4910.4168\nlifeExp: 58.01400\npop: 17152804\ncontinent: Africa\",\"gdpPercap: 3008.6474\nlifeExp: 39.48300\npop: 6162675\ncontinent: Africa\",\"gdpPercap: 1029.1613\nlifeExp: 49.19000\npop: 3168267\ncontinent: Africa\",\"gdpPercap: 3214.8578\nlifeExp: 59.31900\npop: 781472\ncontinent: Africa\",\"gdpPercap: 743.3870\nlifeExp: 46.13700\npop: 5889574\ncontinent: Africa\",\"gdpPercap: 556.1033\nlifeExp: 45.91000\npop: 3834415\ncontinent: Africa\",\"gdpPercap: 1783.4329\nlifeExp: 49.35500\npop: 7959865\ncontinent: Africa\",\"gdpPercap: 1109.3743\nlifeExp: 46.77500\npop: 2167533\ncontinent: Africa\",\"gdpPercap: 1133.9850\nlifeExp: 47.38300\npop: 4388260\ncontinent: Africa\",\"gdpPercap: 1172.6030\nlifeExp: 50.93900\npop: 304739\ncontinent: Africa\",\"gdpPercap: 795.7573\nlifeExp: 47.80400\npop: 26480870\ncontinent: Africa\",\"gdpPercap: 3259.1790\nlifeExp: 55.62500\npop: 1536769\ncontinent: Africa\",\"gdpPercap: 2517.7365\nlifeExp: 52.37400\npop: 7459574\ncontinent: Africa\",\"gdpPercap: 3081.7610\nlifeExp: 46.51900\npop: 228694\ncontinent: Africa\",\"gdpPercap: 2785.4936\nlifeExp: 53.31900\npop: 38783863\ncontinent: Africa\",\"gdpPercap: 958.5668\nlifeExp: 42.02400\npop: 192675\ncontinent: Africa\",\"gdpPercap: 505.7538\nlifeExp: 44.53500\npop: 2512642\ncontinent: Africa\",\"gdpPercap: 556.8084\nlifeExp: 44.51000\npop: 34617799\ncontinent: Africa\",\"gdpPercap: 21745.5733\nlifeExp: 52.79000\npop: 706367\ncontinent: Africa\",\"gdpPercap: 884.7553\nlifeExp: 41.84200\npop: 608274\ncontinent: Africa\",\"gdpPercap: 993.2240\nlifeExp: 51.75600\npop: 10538093\ncontinent: Africa\",\"gdpPercap: 874.6859\nlifeExp: 40.76200\npop: 4227026\ncontinent: Africa\",\"gdpPercap: 764.7260\nlifeExp: 37.46500\npop: 745228\ncontinent: Africa\",\"gdpPercap: 1267.6132\nlifeExp: 56.15500\npop: 14500404\ncontinent: Africa\",\"gdpPercap: 745.3695\nlifeExp: 52.20800\npop: 1251524\ncontinent: Africa\",\"gdpPercap: 640.3224\nlifeExp: 43.76400\npop: 1703617\ncontinent: Africa\",\"gdpPercap: 21951.2118\nlifeExp: 57.44200\npop: 2721783\ncontinent: Africa\",\"gdpPercap: 1544.2286\nlifeExp: 46.88100\npop: 8007166\ncontinent: Africa\",\"gdpPercap: 663.2237\nlifeExp: 43.76700\npop: 5637246\ncontinent: Africa\",\"gdpPercap: 686.3953\nlifeExp: 41.71400\npop: 6491649\ncontinent: Africa\",\"gdpPercap: 1497.4922\nlifeExp: 50.85200\npop: 1456688\ncontinent: Africa\",\"gdpPercap: 3710.9830\nlifeExp: 64.93000\npop: 913025\ncontinent: Africa\",\"gdpPercap: 2370.6200\nlifeExp: 55.73000\npop: 18396941\ncontinent: Africa\",\"gdpPercap: 502.3197\nlifeExp: 42.49500\npop: 11127868\ncontinent: Africa\",\"gdpPercap: 3876.4860\nlifeExp: 56.43700\npop: 977026\ncontinent: Africa\",\"gdpPercap: 808.8971\nlifeExp: 41.29100\npop: 5682086\ncontinent: Africa\",\"gdpPercap: 1981.9518\nlifeExp: 44.51400\npop: 62209173\ncontinent: Africa\",\"gdpPercap: 4319.8041\nlifeExp: 67.06400\npop: 492095\ncontinent: Africa\",\"gdpPercap: 670.0806\nlifeExp: 45.00000\npop: 4657072\ncontinent: Africa\",\"gdpPercap: 1737.5617\nlifeExp: 58.55000\npop: 86796\ncontinent: Africa\",\"gdpPercap: 1561.7691\nlifeExp: 48.87900\npop: 5260855\ncontinent: Africa\",\"gdpPercap: 1348.2852\nlifeExp: 36.78800\npop: 3140897\ncontinent: Africa\",\"gdpPercap: 1450.9925\nlifeExp: 41.97400\npop: 4353666\ncontinent: Africa\",\"gdpPercap: 8028.6514\nlifeExp: 55.52700\npop: 27129932\ncontinent: Africa\",\"gdpPercap: 2202.9884\nlifeExp: 47.80000\npop: 17104986\ncontinent: Africa\",\"gdpPercap: 3781.4106\nlifeExp: 52.53700\npop: 551425\ncontinent: Africa\",\"gdpPercap: 962.4923\nlifeExp: 49.91900\npop: 17129565\ncontinent: Africa\",\"gdpPercap: 1532.7770\nlifeExp: 52.88700\npop: 2308582\ncontinent: Africa\",\"gdpPercap: 3120.8768\nlifeExp: 59.83700\npop: 6005061\ncontinent: Africa\",\"gdpPercap: 843.7331\nlifeExp: 50.35000\npop: 11457758\ncontinent: Africa\",\"gdpPercap: 1588.6883\nlifeExp: 51.38600\npop: 5216550\ncontinent: Africa\",\"gdpPercap: 685.5877\nlifeExp: 57.67400\npop: 6642107\ncontinent: Africa\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(248,118,109,1)\",\"opacity\":1,\"size\":[6.32127781530702,5.29612899121632,4.85958274371316,4.29233940761101,5.26165272498491,4.97061767194295,5.5059176412168,4.66704214356912,5.05559917855771,4.06676322554192,6.94049569932146,4.52040583610645,5.45016604603988,4.01129639562885,7.60694585246374,3.97973112975184,4.73782100329548,7.39505365224446,4.26382530133105,4.22383634289638,5.76860640347983,5.03145493864573,4.27878249624843,6.11542223529683,4.44354450304809,4.56187177172394,4.77827606357594,5.51109590728372,5.22907021838905,5.3366454219231,4.49965617393791,4.33879188894232,6.41229679974379,5.82395887424691,4.36004866819238,5.23491359575959,8.62896025232351,4.17122854948148,5.09486783222961,3.77952755905512,5.17905878226218,4.854775454452,5.05045749460444,6.97912565512447,6.31771439639559,4.19891947998289,6.31954665895726,4.69663035294985,5.27632870617264,5.85427629024999,5.17305387000117,5.35482857766587],\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(248,118,109,1)\"}},\"hoveron\":\"points\",\"name\":\"Africa\",\"legendgroup\":\"Africa\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[4.00341859740172,3.54999558616307,3.82348196645535,4.34421307668719,3.67731159008544,3.58158649939174,3.77282591203612,3.80485437036137,3.42845697609622,3.82475196835622,3.71087205749874,3.68841917661215,3.27283885748582,3.50558514939778,3.82283441748743,3.88507437266432,3.7392851792172,3.72850897552038,3.51166593362054,3.7980489038637,3.98991789679654,3.89760258369119,4.38152357914239,3.81320321246222,4.11872592974958],\"y\":[68.481,50.023,61.489,74.21,67.052,63.837,70.75,72.649,61.788,61.31,56.696,56.029,49.923,57.402,70.11,65.032,57.47,68.681,66.353,58.447,73.44,68.3,73.38,69.481,67.456],\"text\":[\"gdpPercap: 10079.0267\nlifeExp: 68.48100\npop: 26983828\ncontinent: Americas\",\"gdpPercap: 3548.0978\nlifeExp: 50.02300\npop: 5079716\ncontinent: Americas\",\"gdpPercap: 6660.1187\nlifeExp: 61.48900\npop: 114313951\ncontinent: Americas\",\"gdpPercap: 22090.8831\nlifeExp: 74.21000\npop: 23796400\ncontinent: Americas\",\"gdpPercap: 4756.7638\nlifeExp: 67.05200\npop: 10599793\ncontinent: Americas\",\"gdpPercap: 3815.8079\nlifeExp: 63.83700\npop: 25094412\ncontinent: Americas\",\"gdpPercap: 5926.8770\nlifeExp: 70.75000\npop: 2108457\ncontinent: Americas\",\"gdpPercap: 6380.4950\nlifeExp: 72.64900\npop: 9537988\ncontinent: Americas\",\"gdpPercap: 2681.9889\nlifeExp: 61.78800\npop: 5302800\ncontinent: Americas\",\"gdpPercap: 6679.6233\nlifeExp: 61.31000\npop: 7278866\ncontinent: Americas\",\"gdpPercap: 5138.9224\nlifeExp: 56.69600\npop: 4282586\ncontinent: Americas\",\"gdpPercap: 4879.9927\nlifeExp: 56.02900\npop: 5703430\ncontinent: Americas\",\"gdpPercap: 1874.2989\nlifeExp: 49.92300\npop: 4908554\ncontinent: Americas\",\"gdpPercap: 3203.2081\nlifeExp: 57.40200\npop: 3055235\ncontinent: Americas\",\"gdpPercap: 6650.1956\nlifeExp: 70.11000\npop: 2156814\ncontinent: Americas\",\"gdpPercap: 7674.9291\nlifeExp: 65.03200\npop: 63759976\ncontinent: Americas\",\"gdpPercap: 5486.3711\nlifeExp: 57.47000\npop: 2554598\ncontinent: Americas\",\"gdpPercap: 5351.9121\nlifeExp: 68.68100\npop: 1839782\ncontinent: Americas\",\"gdpPercap: 3248.3733\nlifeExp: 66.35300\npop: 2984494\ncontinent: Americas\",\"gdpPercap: 6281.2909\nlifeExp: 58.44700\npop: 15990099\ncontinent: Americas\",\"gdpPercap: 9770.5249\nlifeExp: 73.44000\npop: 3080828\ncontinent: Americas\",\"gdpPercap: 7899.5542\nlifeExp: 68.30000\npop: 1039009\ncontinent: Americas\",\"gdpPercap: 24072.6321\nlifeExp: 73.38000\npop: 220239000\ncontinent: Americas\",\"gdpPercap: 6504.3397\nlifeExp: 69.48100\npop: 2873520\ncontinent: Americas\",\"gdpPercap: 13143.9510\nlifeExp: 67.45600\npop: 13503563\ncontinent: Americas\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(163,165,0,1)\",\"opacity\":1,\"size\":[6.97047083068522,5.15434238640086,10.3553727984455,6.77543956769576,5.77446910007444,6.85635435789675,4.65435232683653,5.6710443310913,5.18472018302092,5.42956521861593,5.0398270921093,5.23768683822733,5.13057191783969,4.83958883002819,4.66475315834704,8.68911697083458,4.74607251669638,4.59414954550014,4.82688148286866,6.23316601826461,4.84414878929001,4.37991825947829,12.9086371873162,4.80663028657321,6.03320025163606],\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(163,165,0,1)\"}},\"hoveron\":\"points\",\"name\":\"Americas\",\"legendgroup\":\"Americas\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[2.89548517717506,4.28645875933068,2.81946314412135,2.72013629197205,2.86995736499049,4.048680298964,2.91027070197067,3.14072860861607,4.07513053543838,4.16696961434647,4.12406772903255,4.22037948985684,3.45520305365965,3.61345080718246,3.66812684894598,4.7728017852095,3.93750268823479,3.58296303108212,3.21682849824462,2.56937390961505,2.84142982784579,4.07365765189317,3.07037821749517,3.37533512418369,4.53361654092087,4.04960907918865,3.12993971717703,3.50453672644772,3.74791804661293,3.29252733979409,2.85341657088882,3.56618184839601,3.26239535810376],\"y\":[38.438,65.593,46.923,31.22,63.96736,73.6,54.208,52.702,57.702,60.413,73.06,75.38,61.134,67.159,64.766,69.343,66.099,65.256,55.491,56.059,46.748,57.367,54.043,60.06,58.69,70.795,65.949,61.195,70.59,62.494,55.764,60.765,44.175],\"text\":[\"gdpPercap: 786.1134\nlifeExp: 38.43800\npop: 14880372\ncontinent: Asia\",\"gdpPercap: 19340.1020\nlifeExp: 65.59300\npop: 297410\ncontinent: Asia\",\"gdpPercap: 659.8772\nlifeExp: 46.92300\npop: 80428306\ncontinent: Asia\",\"gdpPercap: 524.9722\nlifeExp: 31.22000\npop: 6978607\ncontinent: Asia\",\"gdpPercap: 741.2375\nlifeExp: 63.96736\npop: 943455000\ncontinent: Asia\",\"gdpPercap: 11186.1413\nlifeExp: 73.60000\npop: 4583700\ncontinent: Asia\",\"gdpPercap: 813.3373\nlifeExp: 54.20800\npop: 634000000\ncontinent: Asia\",\"gdpPercap: 1382.7021\nlifeExp: 52.70200\npop: 136725000\ncontinent: Asia\",\"gdpPercap: 11888.5951\nlifeExp: 57.70200\npop: 35480679\ncontinent: Asia\",\"gdpPercap: 14688.2351\nlifeExp: 60.41300\npop: 11882916\ncontinent: Asia\",\"gdpPercap: 13306.6192\nlifeExp: 73.06000\npop: 3495918\ncontinent: Asia\",\"gdpPercap: 16610.3770\nlifeExp: 75.38000\npop: 113872473\ncontinent: Asia\",\"gdpPercap: 2852.3516\nlifeExp: 61.13400\npop: 1937652\ncontinent: Asia\",\"gdpPercap: 4106.3012\nlifeExp: 67.15900\npop: 16325320\ncontinent: Asia\",\"gdpPercap: 4657.2210\nlifeExp: 64.76600\npop: 36436000\ncontinent: Asia\",\"gdpPercap: 59265.4771\nlifeExp: 69.34300\npop: 1140357\ncontinent: Asia\",\"gdpPercap: 8659.6968\nlifeExp: 66.09900\npop: 3115787\ncontinent: Asia\",\"gdpPercap: 3827.9216\nlifeExp: 65.25600\npop: 12845381\ncontinent: Asia\",\"gdpPercap: 1647.5117\nlifeExp: 55.49100\npop: 1528000\ncontinent: Asia\",\"gdpPercap: 371.0000\nlifeExp: 56.05900\npop: 31528087\ncontinent: Asia\",\"gdpPercap: 694.1124\nlifeExp: 46.74800\npop: 13933198\ncontinent: Asia\",\"gdpPercap: 11848.3439\nlifeExp: 57.36700\npop: 1004533\ncontinent: Asia\",\"gdpPercap: 1175.9212\nlifeExp: 54.04300\npop: 78152686\ncontinent: Asia\",\"gdpPercap: 2373.2043\nlifeExp: 60.06000\npop: 46850962\ncontinent: Asia\",\"gdpPercap: 34167.7626\nlifeExp: 58.69000\npop: 8128505\ncontinent: Asia\",\"gdpPercap: 11210.0895\nlifeExp: 70.79500\npop: 2325300\ncontinent: Asia\",\"gdpPercap: 1348.7757\nlifeExp: 65.94900\npop: 14116836\ncontinent: Asia\",\"gdpPercap: 3195.4846\nlifeExp: 61.19500\npop: 7932503\ncontinent: Asia\",\"gdpPercap: 5596.5198\nlifeExp: 70.59000\npop: 16785196\ncontinent: Asia\",\"gdpPercap: 1961.2246\nlifeExp: 62.49400\npop: 44148285\ncontinent: Asia\",\"gdpPercap: 713.5371\nlifeExp: 55.76400\npop: 50533506\ncontinent: Asia\",\"gdpPercap: 3682.8315\nlifeExp: 60.76500\npop: 1261091\ncontinent: Asia\",\"gdpPercap: 1829.7652\nlifeExp: 44.17500\npop: 8403990\ncontinent: Asia\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,191,125,1)\",\"opacity\":1,\"size\":[6.14601109401926,4.06189233680308,9.29441811927379,5.39475462377927,22.6771653543307,5.08426676230058,19.2706113323364,10.9715821633898,7.43994831281003,5.89270757284543,4.9155533082844,10.342652961876,4.61658106384004,6.25889092142746,7.4890188516279,4.41106157328659,4.85034613145665,5.97722629927717,4.51816213431315,7.2295116202132,6.06899974449858,4.36894912815136,9.21575428359059,7.98702151037774,5.52430918996644,4.70007429187427,6.08413180764231,5.50291508915639,6.29375367739212,7.86362869673143,8.14954658274176,4.44626602186696,5.5539430462659],\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,191,125,1)\"}},\"hoveron\":\"points\",\"name\":\"Asia\",\"legendgroup\":\"Asia\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[3.54814411807184,4.29555439638822,4.28144187754483,3.54758782074795,3.88151249733011,4.05328536317461,4.17026642863828,4.31011744274222,4.19327554039949,4.26227627214274,4.31202751232983,4.15215143685527,4.06725083957618,4.29347221889702,4.04731308089082,4.15399722211687,3.98208706693409,4.32652140433408,4.36756741361793,3.97809563416623,4.00742708886894,3.97110865215781,4.11329709452241,4.03832857580155,4.18403893629866,4.12178698250771,4.27544324046184,4.43107881405245,3.63033859911073,4.24126620200209],\"y\":[68.93,72.17,72.8,69.86,70.81,70.64,70.71,74.69,72.52,73.83,72.5,73.68,69.95,76.11,72.03,73.48,73.066,75.24,75.37,70.67,70.41,69.46,70.3,70.45,70.97,74.39,75.44,75.39,59.507,72.76],\"text\":[\"gdpPercap: 3533.0039\nlifeExp: 68.93000\npop: 2509048\ncontinent: Europe\",\"gdpPercap: 19749.4223\nlifeExp: 72.17000\npop: 7568430\ncontinent: Europe\",\"gdpPercap: 19117.9745\nlifeExp: 72.80000\npop: 9821800\ncontinent: Europe\",\"gdpPercap: 3528.4813\nlifeExp: 69.86000\npop: 4086000\ncontinent: Europe\",\"gdpPercap: 7612.2404\nlifeExp: 70.81000\npop: 8797022\ncontinent: Europe\",\"gdpPercap: 11305.3852\nlifeExp: 70.64000\npop: 4318673\ncontinent: Europe\",\"gdpPercap: 14800.1606\nlifeExp: 70.71000\npop: 10161915\ncontinent: Europe\",\"gdpPercap: 20422.9015\nlifeExp: 74.69000\npop: 5088419\ncontinent: Europe\",\"gdpPercap: 15605.4228\nlifeExp: 72.52000\npop: 4738902\ncontinent: Europe\",\"gdpPercap: 18292.6351\nlifeExp: 73.83000\npop: 53165019\ncontinent: Europe\",\"gdpPercap: 20512.9212\nlifeExp: 72.50000\npop: 78160773\ncontinent: Europe\",\"gdpPercap: 14195.5243\nlifeExp: 73.68000\npop: 9308479\ncontinent: Europe\",\"gdpPercap: 11674.8374\nlifeExp: 69.95000\npop: 10637171\ncontinent: Europe\",\"gdpPercap: 19654.9625\nlifeExp: 76.11000\npop: 221823\ncontinent: Europe\",\"gdpPercap: 11150.9811\nlifeExp: 72.03000\npop: 3271900\ncontinent: Europe\",\"gdpPercap: 14255.9847\nlifeExp: 73.48000\npop: 56059245\ncontinent: Europe\",\"gdpPercap: 9595.9299\nlifeExp: 73.06600\npop: 560073\ncontinent: Europe\",\"gdpPercap: 21209.0592\nlifeExp: 75.24000\npop: 13852989\ncontinent: Europe\",\"gdpPercap: 23311.3494\nlifeExp: 75.37000\npop: 4043205\ncontinent: Europe\",\"gdpPercap: 9508.1415\nlifeExp: 70.67000\npop: 34621254\ncontinent: Europe\",\"gdpPercap: 10172.4857\nlifeExp: 70.41000\npop: 9662600\ncontinent: Europe\",\"gdpPercap: 9356.3972\nlifeExp: 69.46000\npop: 21658597\ncontinent: Europe\",\"gdpPercap: 12980.6696\nlifeExp: 70.30000\npop: 8686367\ncontinent: Europe\",\"gdpPercap: 10922.6640\nlifeExp: 70.45000\npop: 4827803\ncontinent: Europe\",\"gdpPercap: 15277.0302\nlifeExp: 70.97000\npop: 1746919\ncontinent: Europe\",\"gdpPercap: 13236.9212\nlifeExp: 74.39000\npop: 36439000\ncontinent: Europe\",\"gdpPercap: 18855.7252\nlifeExp: 75.44000\npop: 8251648\ncontinent: Europe\",\"gdpPercap: 26982.2905\nlifeExp: 75.39000\npop: 6316424\ncontinent: Europe\",\"gdpPercap: 4269.1223\nlifeExp: 59.50700\npop: 42404033\ncontinent: Europe\",\"gdpPercap: 17428.7485\nlifeExp: 72.76000\npop: 56179000\ncontinent: Europe\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,176,246,1)\",\"opacity\":1,\"size\":[4.73711086274366,5.46245399673978,5.69923465730081,5.00994841135964,5.59538443706805,5.04523525790558,5.73248147708556,5.15554006271282,5.10659105931128,8.26207702648979,9.21603585103979,5.64793676344929,5.77801236958701,4.00561540333621,4.87759423629259,8.38266622872152,4.20280449359801,6.06235892227666,5.00334741211677,7.39523452347783,5.68347312501541,6.63718460047671,5.58381321630558,5.11921103857739,4.57227899402677,7.48917192574021,5.53761739047554,5.31519777193933,7.78197424302696,8.38758788519898],\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,176,246,1)\"}},\"hoveron\":\"points\",\"name\":\"Europe\",\"legendgroup\":\"Europe\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[4.26326190559163,4.21041798943211],\"y\":[73.49,72.22],\"text\":[\"gdpPercap: 18334.1975\nlifeExp: 73.49000\npop: 14074100\ncontinent: Oceania\",\"gdpPercap: 16233.7177\nlifeExp: 72.22000\npop: 3164900\ncontinent: Oceania\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(231,107,243,1)\",\"opacity\":1,\"size\":[6.08061917751821,4.85899251590851],\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(231,107,243,1)\"}},\"hoveron\":\"points\",\"name\":\"Oceania\",\"legendgroup\":\"Oceania\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":26.2283105022831,\"r\":7.30593607305936,\"b\":40.1826484018265,\"l\":37.2602739726027},\"plot_bgcolor\":\"rgba(255,255,255,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[2.45920251583532,4.88297317898922],\"tickmode\":\"array\",\"ticktext\":[\"300\",\"1000\",\"3000\",\"10000\",\"30000\"],\"tickvals\":[2.47712125471966,3,3.47712125471966,4,4.47712125471966],\"categoryorder\":\"array\",\"categoryarray\":[\"300\",\"1000\",\"3000\",\"10000\",\"30000\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"gdpPercap\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[28.9755,78.3545],\"tickmode\":\"array\",\"ticktext\":[\"30\",\"40\",\"50\",\"60\",\"70\"],\"tickvals\":[30,40,50,60,70],\"categoryorder\":\"array\",\"categoryarray\":[\"30\",\"40\",\"50\",\"60\",\"70\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"lifeExp\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":\"transparent\",\"line\":{\"color\":\"rgba(51,51,51,1)\",\"width\":0.66417600664176,\"linetype\":\"solid\"},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.88976377952756,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895},\"y\":0.93503937007874},\"annotations\":[{\"text\":\"continent\npop\",\"x\":1.02,\"y\":1,\"showarrow\":false,\"ax\":0,\"ay\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"xref\":\"paper\",\"yref\":\"paper\",\"textangle\":-0,\"xanchor\":\"left\",\"yanchor\":\"bottom\",\"legendTitle\":true}],\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"11b040177098\":{\"x\":{},\"y\":{},\"size\":{},\"colour\":{},\"type\":\"scatter\"}},\"cur_data\":\"11b040177098\",\"visdat\":{\"11b040177098\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r1 2  tmp \u0026lt;- c(1,2,3,4) print(tmp)   ## [1] 1 2 3 4\r","description":"test","id":72,"section":"posts","tags":null,"title":"test","uri":"https://jiwooblog.netlify.app/posts/r/test/"},{"content":"Natural Scene Categories Revealed in Distributed Patterns of Activity in the Human Brain(Walther, 2009)\nReference Walther, D. B., Caddigan, E., Fei-Fei, L., \u0026amp; Beck, D. M. (2009). Natural scene categories revealed in distributed patterns of activity in the human brain. Journal of neuroscience, 29(34), 10573-10581.\nSummary ìì—° ì¥ë©´ì„ ë³´ê³  ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•  ë•Œ, ë‡Œì—ì„œ ì–´ë– í•œ íŒ¨í„´ì´ ì¼ì–´ë‚˜ëŠ”ì§€ ë¶„ì„í•˜ëŠ” ê²ƒì´ ë³¸ ë…¼ë¬¸ì˜ í•µì‹¬ì´ë‹¤. fMRIì™€ MVPA (multivoxel pattern analysis)ë¥¼ í™œìš©í•˜ì—¬ ë‡Œì˜ ì–´ë–¤ ì˜ì—­ì—ì„œ ê·¸ë¦¬ê³  ì–´ë– í•œ íŒ¨í„´ìœ¼ë¡œ ìì—° ì¥ë©´ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ êµ¬ë¶„í•˜ëŠ”ì§€ í™•ì¸í•˜ì˜€ë‹¤. ë‹¤ì„¯ ëª…ì˜ ì°¸ê°€ìê°€ ìˆì—ˆìœ¼ë©° ì´ ì—¬ì„¯ ê°œì˜ ì¹´í…Œê³ ë¦¬(ì¹´í…Œê³ ë¦¬ë³„ 120ê°œ ì‚¬ì§„)ë¥¼ í™œìš©í•˜ì˜€ë‹¤. ì—°êµ¬ ê²°ê³¼, V1, PPA, RSC, LOC ì˜ì—­ ëª¨ë‘ì—ì„œ ìì—°ì¥ë©´ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ êµ¬ë¶„í•  ë•Œ í™œìš©ë˜ëŠ” ì •ë³´ë¥¼ ê°–ê³  ìˆìŒì„ í™•ì¸í•˜ì˜€ë‹¤. ê·¸ë¦¬ê³  ì§ì ‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì¸ê°„í–‰ë™ì—°êµ¬ì™€ ë¹„êµí•´ë³¸ ê²°ê³¼, V1ì„ ì œì™¸í•œ PPA, RSC, LOCê°€ í•´ì„í•œ ì •ë³´ë¥¼ ì¸ê°„ì´ í™œìš©í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ë¥¼ í•œë‹¤ê³  íŒë‹¨í•˜ì˜€ë‹¤. íŠ¹íˆ, fMRI ì‹ í˜¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ˆì¸¡ë¶„ë¥˜í•œ ê²ƒì˜ ì˜¤ë‹µ íŒ¨í„´ì´ ì°¸ê°€ìë“¤ì˜ í–‰ë™ ì˜¤ë‹µíŒ¨í„´ê³¼ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ê²ƒìœ¼ë¡œ ì•ì„œ ì–¸ê¸‰í•œ ì„¸ ë‡Œ ì˜ì—­ì—ì„œ ë‚˜íƒ€ë‚¬ë‹¤. ë˜í•œ ëˆˆì—¬ê²¨ë³´ì•„ì•¼ í•  ê²°ê³¼ë¡œëŠ”, ê·¸ë¦¼ì„ ìƒí•˜ ë°˜ì „í•˜ì—¬ ì œì‹œí•˜ì˜€ì„ ë•Œ PPA ì‹ í˜¸ë¥¼ í†µí•œ ì˜ˆì¸¡ê³¼ í–‰ë™ì—°êµ¬ ëª¨ë‘ì—ì„œ ì •í™•ë„ê°€ ë–¨ì–´ì¡Œë‹¤ëŠ” ì ì´ë‹¤. ì¢…í•©ì ì¸ ê²°ë¡ ìœ¼ë¡œ, PPA, RSC, LOCë¥¼ í¬í•¨í•œ ë‡Œì˜ì—­ë“¤ì´ ì¼ì¢…ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ í˜•ì„±í•˜ì—¬ ì •ë³´ë¥¼ ëª¨ì•„ ìì—°ì¥ë©´ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ì‹œí–‰í•œë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.\ní•´ë‹¹ ë…¼ë¬¸ì€ ìì—°ì¥ë©´ì„ í•´ì„í•˜ëŠ” ë°ì— ìˆì–´ì„œ MVPAë¥¼ í™œìš©í•˜ì—¬ ì—¬ëŸ¬ ë‡Œ ì˜ì—­ ê°„ì˜ ì—°ê´€ì„± ìˆëŠ” íŒ¨í„´ì„ ë°í˜”ë‹¤ëŠ” ë°ì— ì°¨ë³„ì ì¸ ì˜ì˜ê°€ ìˆë‹¤ê³  í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, fMRI ì‹ í˜¸ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ˆì¸¡í•œ ê²ƒê³¼ ì‹¤ì œ í–‰ë™ë¶„ì„ì„ ë¹„êµí•˜ë©´ì„œ ë‹¨ìˆœíˆ ì •ë³´ê°€ ë‡Œ ì˜ì—­ì— ìˆë‹¤ëŠ” ê²ƒê³¼ ê·¸ê²ƒì„ í™œìš©í•˜ëŠ” ê²ƒì˜ ì°¨ì´ë¥¼ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì˜€ë‹¤ëŠ” ì ì—ì„œ í•œì¸µ ë” ì² ì €í•œ ì—°êµ¬ì„¤ê³„ê°€ ì´ë£¨ì–´ì¡ŒìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë‚˜ì•„ê°€, ë‡Œê°€ ì´ë¯¸ì§€ ê·¸ ìì²´ë¥¼ í•´ì„í•˜ëŠ”(decode) ê²ƒê³¼ í•´ë‹¹ ì´ë¯¸ì§€ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ í•´ì„í•˜ëŠ”(decode)í•˜ëŠ” ê²ƒì˜ ì°¨ì´ë¥¼ ì—­ì‹œ í™•ì‹¤íˆ í•˜ê³  ìˆë‹¤.\nê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì™„ë²½í•˜ê²Œ ì´í•´ê°€ ë˜ì§€ ì•ŠëŠ” ì ë“¤ì´ ìˆê¸´ í•˜ë‹¤. ë³¸ ì—°êµ¬ì˜ í•œê³„ì ì€, ë§ì€ ì—°êµ¬ì—ì„œ ì§ë©´í•  ìˆ˜ë°–ì— ì—†ëŠ” í•œê³„ì´ê¸°ëŠ” í•˜ì§€ë§Œ, íŒë‹¨ê¸°ì¤€ì— ëŒ€í•œ í†µê³„ì  ê·¼ê±°ê°€ ë‹¤ì†Œ ì„¤ë“ë ¥ì´ ë¶€ì¡±í•˜ë‹¤ëŠ” ì ì´ë‹¤. í–‰ë™ì—°êµ¬ì™€ fMRI ë¶„ì„ì„ í†µí•œ ì˜ˆì¸¡ì˜ ì‹¤íŒ¨ë¥¼ ë¹„êµí•  ë•Œ, frequent confusionê³¼ ì•„ë‹Œ ê²ƒì„ êµ¬ë¶„í•˜ëŠ” ê¸°ì¤€ì´ ë‹¤ì†Œ ëª¨í˜¸í•˜ë‹¤. ë˜í•œ, ê° ì˜ì—­ë³„ë¡œ í–‰ë™ë¶„ì„ê³¼ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ì˜€ì„ ë•Œ, ì´ìƒì¹˜ì²˜ëŸ¼ ë³´ì´ëŠ” ê²ƒë“¤ì— ì˜í•´ ìƒê´€ê³„ìˆ˜ê°€ ì™œê³¡ë˜ì—ˆì„ ê°€ëŠ¥ì„±ë„ ì¶©ë¶„íˆ ì¡´ì¬í•œë‹¤. ê·¸ë¦¬ê³  í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ëŠ” ì˜¤ë¡œì§€ ì„ í˜•ì  ì—°ê´€ì„±ë§Œì„ ì´ì•¼ê¸°í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë‡Œ ì˜ì—­ë¼ë¦¬ ë³µì¡í•œ ê´€ê³„ë¡œ ê´€ë ¨ì´ ìˆë‹¤ë©´ ì´ë¥¼ ë¶„ì„í•˜ëŠ” ë°ì— ìˆì–´ì„œëŠ” ìƒë‹¹íˆ ì œí•œì ì¸ í†µê³„ë°©ë²•ì„ ì‚¬ìš©í–ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.\nê¶ê¸ˆì¦   decoding accuracyì— ëŒ€í•´ tê²€ì •ì„ í•  ë•Œ, ê¸°ì¤€ì¹˜ë¡œì„œ 1/6ì´ ì ì ˆí•œê°€?! ë§Œì•½ ì—°êµ¬ìê°€ 20ê°œì˜ ì¹´í…Œê³ ë¦¬ë¥¼ í™œìš©í•˜ì˜€ë‹¤ë©´ 1/20ì´ ì ì ˆí•˜ë‹¤ê³  í•  ìˆ˜ ìˆì„ê¹Œ? ê·¸ë¦¬ê³  ë‹¨ìˆœíˆ p-valueë§Œ ë³¼ ê²ƒì´ ì•„ë‹ˆë¼ effect sizeë¥¼ ê³ ë ¤í•˜ì§€ ì•Šì•„ë„ ê´œì°®ì€ ê±¸ê¹Œ? ì™œëƒí•˜ë©´ ì´ë¯¸ì§€ ê°œìˆ˜ê°€ ë§ì•„ì§€ë©´ ë§ì•„ì§ˆìˆ˜ë¡ p-valueì€ ì ì  ì‘ê²Œ ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§€ê¸° ë•Œë¬¸ì´ë‹¤.\n  Figure 2ì—ì„œ ì˜¤ë‹µ ë¹„ìœ¨ì´ ë†’ì€ ê²ƒ(ë…¸ë€ìƒ‰)ì´ ëŒ€ê°ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¹­ì´ ë˜ì§€ ì•Šì•„ë„ ë¬¸ì œê°€ ì—†ëŠ”ê°€? industryë¥¼ ë³´ê³  buildingì´ë¼ê³  ìƒê°í–ˆìœ¼ë©´, buildingì„ ë³´ê³  industryë¼ê³  ìƒê°í–ˆì„ ë¹„ìœ¨ë„ ê°™ì´ ë†’ì•„ì•¼ í•˜ëŠ” ê²ƒ ì•„ë‹ê¹Œ? ì´ë¶€ë¶„ì—ì„œ ë†“ì¹œ ë…¼ë¦¬ëŠ” ì—†ì„ê¹Œ?\n  ì—°êµ¬ìëŠ” ëª¨ë“  ë‡Œ ì˜ì—­ì„ decoderë¼ê³  ë³´ì•˜ë‹¤. í•˜ì§€ë§Œ, ë‡Œ ì˜ì—­ì˜ ì…ì¥ì—ì„œ ë³´ë©´, íŠ¹ì • ì˜ì—­ì€ ë‹¤ë¥¸ ì˜ì—­ì˜ encoderë¡œì„œ ì—­í• ì„ í•  ìˆ˜ë„ ìˆì§€ ì•Šì„ê¹Œ? ë§Œì•½ ê·¸ë ‡ë‹¤ë©´ ì–´ë– í•œ ë°©ì‹ìœ¼ë¡œ ì—°êµ¬ë¥¼ ì„¤ê³„í•  ìˆ˜ ìˆì„ê¹Œ?\n ","description":"","id":73,"section":"blog","tags":["Psychology"],"title":"Natural Scene Categories Revealed in Distributed Patterns of Activity in the Human Brain","uri":"https://jiwooblog.netlify.app/blog/210312_natural_scene_categorization/"},{"content":"ë¹…ì½˜í…ŒìŠ¤íŠ¸ ì±”í”¼ì–¸ë¦¬ê·¸ ë°ì´í„°ë¶„ì„ ë¶„ì•¼\në°°ìš´ ì \n ìì—°ì–´ ì „ì²˜ë¦¬   ì •ê·œí‘œí˜„ì‹ ê¸°ì¡´ì— ì œì‹œëœ ì¹¼ëŸ¼ì˜ ìˆ˜ê°€ êµ‰ì¥íˆ ì ì—ˆë‹¤. ê·¸ì¤‘ì—ì„œ ê·¸ë‚˜ë§ˆ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ê²ƒì€ \u0026lsquo;ìƒí’ˆëª…\u0026rsquo; ì¹¼ëŸ¼ì´ì—ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ì˜ˆë¥¼ ë“¤ì–´, \u0026lsquo;NIKE ìŠ¤íŠ¸ë¼ì´í”„ ì…”ì¸ \u0026rsquo;ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë¸Œëœë“œê°€ ì¼ë°˜ì ìœ¼ë¡œ ì•ì— ë‚˜ì˜¤ê³  ë’¤ì— ë””í…Œì¼í•œ ìƒí’ˆ ë¶„ë¥˜ê°€ ë‚˜ì™”ë‹¤. í•˜ì§€ë§Œ ì‹ë£Œí’ˆê³¼ ê°™ì€ ê²½ìš°ì—ëŠ” ë¸Œëœë“œê°€ ì—†ëŠ” ê²ƒë“¤ì´ ë§ì•˜ê³ , ë„ì–´ì“°ê¸°ê°€ ì œëŒ€ë¡œ ë˜ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë„ ë§ì•˜ë‹¤. (ì•„ë§ˆë„ í˜„ì‹¤ ë°ì´í„°ëŠ” ì´ê²ƒë³´ë‹¤ë„ ë” ì •ëˆë˜ì§€ ì•Šì€ ê²½ìš°ê°€ ë§ì„ í„°ì´ë‹¤\u0026hellip;) ë˜í•œ ë¸Œëœë“œì˜ í‘œê¸° ìì²´ê°€ í†µì¼ë˜ì§€ ì•Šì€ ê²½ìš°ê°€ ìˆì—ˆë‹¤.(ex. ì¹´ì‚¬ë¯¸ì•„=ê¹Œì‚¬ë¯¸ì•„) NS Shop+ ê³µì‹í™ˆí˜ì´ì§€ì—ì„œ ë‚˜ëˆ ë†“ì€ ëŒ€ë¶„ë¥˜, ì¤‘ë¶„ë¥˜, ì†Œë¶„ë¥˜ ì²´ê³„ë¥¼ ì°¸ê³ í•´ì„œ ë‚˜ëˆ´ë‹¤. ë„ˆë¬´ ë§ì€ ìƒí’ˆëª…ì´ ìˆì—ˆê¸° ë•Œë¬¸ì—, ëŒ€ë¶„ë¥˜ 3ê°œì”© ë¬¶ì–´ì„œ ì—­í• ë¶„ë‹´ì„ í•´ì„œ ë‚˜ë¨¸ì§€ ë¶„ë¥˜ë¥¼ ì±„ì› ëŠ”ë°, ê·¸ëŸ¬ë‹¤ë³´ë‹ˆ ì‚¬ì†Œí•˜ê²Œ í†µì¼ë˜ì§€ ì•Šì€ ë¶„ë¥˜ê¸°ì¤€ì´ ìˆì–´ì„œ ì¶”í›„ ì•½ê°„ì˜ ì–´ë ¤ì›€ì„ ê²ªì—ˆë‹¤. ê¸°ì¤€ì„ ëª…í™•í•˜ê²Œ ì •í•´ë‘ê±°ë‚˜, ë§Œì•½ ê·¸ëŸ¬ì§€ ëª»í•  ê²½ìš° ìµœì†Œí•œì˜ ì‚¬ëŒì´ í•´ë‹¹ ì—…ë¬´ë¥¼ í–ˆìœ¼ë©´ ì–´ë• ì„ê¹Œë¼ëŠ” ìƒê°ì´ ë“ ë‹¤. ","description":"","id":74,"section":"blog","tags":["project"],"title":"ë¹…ì½˜í…ŒìŠ¤íŠ¸ NS Shop+ í™ˆì‡¼í•‘ ì‹¤ì  ì˜ˆì¸¡","uri":"https://jiwooblog.netlify.app/blog/bigcontest2020/"},{"content":"ì„œìš¸ì‹œ ìˆ˜ì†Œì°¨ ì¶©ì „ì†Œ ì…ì§€ ì¶”ì²œ\nì—°ì„¸ëŒ€í•™êµ ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ì…ë¬¸ ìˆ˜ì—…ì—ì„œ ì§„í–‰í•œ í”„ë¡œì íŠ¸\nëª©í‘œ ìµœê·¼ ì‹¬ê°í•´ì§„ ë¯¸ì„¸ë¨¼ì§€ ë“±ì˜ í™˜ê²½ ë¬¸ì œì— ëŒ€í•œ ëŒ€ì±…ìœ¼ë¡œ ìˆ˜ì†Œì°¨ì˜ ìƒì‚° ë° ë³´ê¸‰ ì´ìŠˆê°€ ì£¼ëª©ë°›ê³  ìˆë‹¤.\nì´ì™€ ê´€ë ¨í•˜ì—¬ ì„œìš¸ì‹œëŠ” í˜„ëŒ€ì°¨ê°€ ìˆ˜ì†Œì „ê¸°ì°¨ ë³´ê¸‰ í™œì„±í™”ë¥¼ ìœ„í•œ MOUë¥¼ ì²´ê²°í•˜ëŠ” ë“±ì˜ ë…¸ë ¥ì„ ê¸°ìš¸ì´ê³  ìˆë‹¤.\në‹¤ë§Œ, ìˆ˜ì†Œì°¨ ì¶©ì „ì†Œ ì¸í”„ë¼ í˜•ì„±ì´ ì•„ì§ ë¯¸í¡í•œ íƒ“ì— ë³´ê¸‰ì— ë‹¤ì†Œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” ì‹¤ì •ì´ë‹¤.\ní™˜ê²½ë¶€ì™€ êµ­í† êµí†µë¶€ ë“±ì˜ ê´€ë ¨ ë¶€ì²˜ì—ì„œëŠ” 2040ë…„ê¹Œì§€ ì´ 1200ê¸°ì˜ ì¶©ì „ì†Œë¥¼ ì„¤ì¹˜í•  ì˜ˆì •ì´ë‹¤.\nì´ì— ëŒ€í•´ ì§€ì—­, ì‚¬íšŒë³„ ë³€ìˆ˜ë“¤ì„ ê³ ë ¤í•˜ì—¬ ì„œìš¸ ì‹œë‚´ì˜ ì í•©í•œ ìˆ˜ì†Œì°¨ ì¶©ì „ì†Œ ì…ì§€ë¥¼ ì„ ì •í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.\nê²°ê³¼ë¬¼ ë¸”ë¡œê·¸\nëŒ€ì‰¬ë³´ë“œ\nì—­í•  ë§ˆì¹¨ ì§€ë‚œ 2019ë…„ ê²¨ìš¸ë°©í•™ ë•Œ ë¨¸ì‹ ëŸ¬ë‹ì„ ê³µë¶€í•´ë³´ê¸° ì‹œì‘í•´ì„œ, ì£¼ë¡œ ëª¨ë¸ë§ê³¼ ê´€ë ¨ëœ ì—­í• ì„ ë§ì´ ë§¡ì•˜ë‹¤.\në‹¤ì–‘í•œ ë°©ë²•ë¡ ì„ ì‹œë„í•˜ì˜€ëŠ”ë°, ì˜ë¯¸ í•´ì„ì„ ë„ì¶œí•˜ê¸° ìœ„í•´ Random Forestë¥¼ ì±„íƒí•˜ê²Œ ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ë°ì´í„°ìº í”„ë¥¼ í†µí•´ì„œ shiny dashboardë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ ê²ƒë“¤ì„ ê³µë¶€í•  ìˆ˜ ìˆì—ˆë‹¤.\në°°ìš´ ì   ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬   ê¸°ì¡´ì— ë°ì´í„°ê°€ ì£¼ì–´ì§€ëŠ” ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—, í•„ìš”í•œ ë°ì´í„°ë¥¼ ì§ì ‘ ì¼ì¼ì´ ì°¾ì•„ë‚˜ì„œëŠ” ë…¸ë ¥ì„ í–ˆë‹¤. ê·¸ ê³¼ì •ì—ì„œ ê±°ë¦¬ ë³€ìˆ˜ë¥¼ ì§ì ‘ ê³„ì‚°í•˜ì—¬ íŒŒìƒë³€ìˆ˜ë¥¼ ë§Œë“¤ì—ˆë‹¤. ì§€ì—­ ë‹¨ìœ„ë¥¼ ìµœëŒ€í•œ ë™ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ê³„ì‚°ì„ í–ˆë‹¤.  tidyverse   ì´ì „ì—ëŠ” tidyverse ë¬¸ë²•ì„ ì˜ ëª¨ë¥´ê³  ê¸°ë³¸ base ë¬¸ë²•ë§Œ ì¼ë‹¤. tidyverseì˜ í¸ë¦¬í•¨ì„ ì˜ ëª¨ë¥´ê³  pythonë§Œ ê²¨ìš¸ë°©í•™ë™ì•ˆ ì¼ì—ˆëŠ”ë°, Rì˜ %\u0026gt;% pipe lineê³¼ ggplotì˜ í¸ë¦¬í•¨ì„ ì•Œ ìˆ˜ ìˆì—ˆë‹¤.  ë‹¤ì–‘í•œ R í™œìš©ë²•   blogdown: Rë¡œ ë¸”ë¡œê·¸ ë§Œë“¤ê¸° shiny: Rë¡œ ëŒ€ì‰¬ë³´ë“œ ë§Œë“¤ê¸° xaringan: Rë¡œ í”„ë Œì  í…Œì´ì…˜ ìë£Œ ë§Œë“¤ê¸°  ê°œì„ í•  ì   ìˆ˜ì†Œì°¨ ë³´ìœ  ëŒ€ìˆ˜ ìì²´ê°€ ì• ì´ˆì— ì¶©ë¶„í•˜ì§€ ëª»í–ˆê¸° ë•Œë¬¸ì—, í¬ì•„ì†¡íšŒê·€ë¶„ì„ì„ í•œë²ˆ í•´ë´¤ìœ¼ë©´ ì–´ë–¨ê¹Œ í•˜ëŠ” ì•„ì‰¬ì›€ì´ ìˆë‹¤. xaringan íŒ¨í‚¤ì§€ë¥¼ ë„ˆë¬´ ëŠ¦ê²Œ ì•Œê²Œ ë˜ì–´ì„œ, ìˆ™ë ¨ë„ê°€ ë†’ì§€ ëª»í–ˆë‹¤. (2021.03.14ì— ì•Œê²Œ ëœ ì •ë³´ë¡œëŠ”, ) ","description":"","id":75,"section":"blog","tags":["project"],"title":"ìˆ˜ì†Œì°¨ ì¶©ì „ì†Œ ì…ì§€ ì¶”ì²œ","uri":"https://jiwooblog.netlify.app/blog/rhino/"},{"content":"ë§ˆí¬ë‹¤ìš´ ê°€ì´ë“œë¼ì¸\nLorem est tota propiore conpellat pectoribus de\npectora summo. Redit teque digerit hominumque toris verebor lumina non cervice\nsubde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc\ncaluere tempus\nThis article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\n\rHeadings The following HTML \u0026lt;h1\u0026gt;â€”\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution  Tiam, ad mint andaepu dandae nostion secatur sequo quae.\nNote that you can use Markdown syntax within a blockquote.\n Blockquote with attribution  Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\nâ€” Rob Pike1\n Tables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23    Inline Markdown within tables    InlineÂ  MarkdownÂ  InÂ  Table     italics bold strikethroughÂ  code    Code Blocks Code block with backticks html\r\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   List Types Ordered List  First item Second item Third item  Unordered List  List item Another item And another item  Nested list  Item  First Sub-item Second Sub-item    Other Elements â€” abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015. \u0026#x21a9;\u0026#xfe0e;\n  ","description":"","id":76,"section":"blog","tags":["markdown"],"title":"Markdown Syntax Guide","uri":"https://jiwooblog.netlify.app/blog/markdown-syntax/"},{"content":"Youtube ë§í¬ ê±°ëŠ” ë²•\nHugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\n\rYoutube ë§í¬ëŠ” ì´ë ‡ê²Œ í•˜ê¸°!   ","description":"","id":77,"section":"blog","tags":["Youtube"],"title":"How to Link","uri":"https://jiwooblog.netlify.app/blog/rich-content/"},{"content":"ì´ê±´ ì •í™•íˆ ë¬´ì—‡ì¸ì§€ ëª¨ë¥´ê² ë‹¤..\nVagus elidunt \nThe Van de Graaf Canon\n","description":"","id":78,"section":"blog","tags":null,"title":"Placeholder Text","uri":"https://jiwooblog.netlify.app/blog/placeholder-text/"},{"content":"ì´ëª¨ì§€ ê´€ë ¨\nLorem est tota propiore conpellat pectoribus de pectora summo. Redit teque digerit hominumque toris verebor lumina non cervice\nsubde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc\ncaluere tempus\nEmoji can be enabled in a Hugo project in a number of ways.\n\rThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your siteâ€™s configuration and then you can type emoji shorthand codes directly in content files; e.g.\nğŸ™ˆ ğŸ™ˆ ğŸ™‰ ğŸ™‰ ğŸ™Š ğŸ™Š\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3  .emoji { font-family: Apple Color Emoji,Segoe UI Emoji,NotoColorEmoji,Segoe UI Symbol,Android Emoji,EmojiSymbols; }  ","description":"","id":79,"section":"blog","tags":["emoji"],"title":"Emoji Support","uri":"https://jiwooblog.netlify.app/blog/emoji-support/"}]